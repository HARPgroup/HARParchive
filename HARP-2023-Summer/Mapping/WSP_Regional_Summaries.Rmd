---
title: "WSP Local and Regional Summaries"
author: "DEQ"
date: "`r Sys.Date()`"
geometry: margin=1cm #margins for pdf
#overridden by output_format in render command 
output: 
   officedown::rdocx_document: 
    # reference_docx: 51049_wsp.docx
    toc: true
    number_sections: true
    page_margins:
      gutter: 0.0

#Here is the main editable part of the rmd, planners should adjust parameters as they see fit for their goals, see README documentation for more details on each parameter
#Can edit here or in a render command 
## More params used during development and testing for user-control -- will be consolidated  
params:

  origin: ["SoutheastVirginia"] #supply either a rivseg, locality, or region name ## JL7_7070_0001
  origin_type: ["region"] #basin, locality, or region
  featr_type: ["facility"] #source or facility

  featrs_file: "C:/Users/ejp42531/Documents/R Exports//SoutheastVirginia_featrs_sf.csv"
  featrs_file_map_bubble_column: ["wsp2020_2040_mgy"] #runid & metric
  featrs_file_table_column: ["Use_Type","runid_11_wd_mgd","runid_13_wd_mgd","wsp2020_2040_mgy"]

  rsegs_file: "C:/Users/ejp42531/Documents/R Exports/SoutheastVirginia_rsegs_sf.csv"
  rivseg_metric: ["l30_Qout", "l90_Qout"] #right now these arent exact column names in the resegs_file
  run_set: ['wsp_2020_2040'] # new method of specifying river metric maps and tables
  runid_list: ["runid_11", "runid_13", "runid_17", "runid_1000"] #list of runids used for facil and rseg data

  # aesthetic changes
  crs_default: 4326 #default coordinate system
  map_style: ["custom"] #determining map aesthetics like colors, fonts, font sizes
  bbox_type: ["custom"] #either 'auto' to force automatic for all, or 'custom'
  show_map: TRUE #either TRUE or FALSE
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#ensure all packages and dependencies are installed prior to running 
library(data.table)
library(hydrotools)
library(mgsub)
library(sp)
library(sf)
library(nhdplusTools)
library(png)
library(zoo)
library(flextable)
library(pandoc)
library(officedown)
library(officer)
#tinytex::install_tinytex() #need to run if you don't have tinytex
library(tinytex)


```

```{r UserInputs, echo=FALSE}
# reading in the user inputs from params
origin <- params$origin #supply either a rivseg, locality, or region name ## JL7_7070_0001
origin_type <- params$origin_type #basin, locality, or region
featr_type <- params$featr_type #source or facility

featrs_file <- params$featrs_file
featrs_file_map_bubble_column <- params$featrs_file_map_bubble_column
featrs_file_table_column <- params$featrs_file_table_column

rsegs_file <- params$rsegs_file
run_set <- params$run_set
rivseg_metric <- params$rivseg_metric

runid_list <- params$runid_list
crs_default <- params$crs_default
map_style <- params$map_style
bbox_type <- params$bbox_type
show_map <- params$show_map
    
```

```{r TOC, echo = FALSE}
## Need a seperate chunk for the table of contents, created with the block_toc() command
block_toc()

```

```{r Load Functions & Configs, echo=FALSE, warning=FALSE, results='hide', include=FALSE}
# For planners, updated when changes are merged to master
# Make sure github location in config file is properly set 
github_base_uri <- "https://raw.githubusercontent.com/HARPgroup"
github_uri <- paste0(github_base_uri, "/HARParchive/master")
if (!exists("HARParchive_location")){
  HARParchive_location <- "https://raw.githubusercontent.com/HARPgroup/HARParchive/master"
}
  
source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Functions/fns_spatial.R")) #load functions for dealing with spatial data
source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Functions/fns_mapgen.R")) #load mapping function
source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Functions/fn_tablegen.R")) #load table function
source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Functions/fn_filter_table.R")) #load table filtering function
source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Functions/fn_labelprep.R")) #load labeling function
source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Functions/fn_nhd_labs.R")) #load nhd label function
source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Config/mapstyle_config.R")) #load general mapping aesthetics 
#source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Config/rivsegmaps_config.R")) #load rivseg-specific mapping aesthetics
source(paste0(HARParchive_location,"/HARP-2023-Summer/Mapping/Functions/fn_get_memo_nhdplus.R")) #nhd caching

# legend_titling() --> Generate user-understandable legend titles
## Kept up here as a function so that it's easy to add if-statements when user-input options expand
legend_titling <- function(metric, runid_list){
  if (metric=="wd_mgd"){ #titles for wd_mgd
    name <- "Withdrawal"
    unit <- "(MGD)"
    legend_title <- runid_list
    year <- mgsub(runid_list, c("runid_11","runid_13"), c("2020","2040"))
    for (i in 1:length(runid_list)){
      legend_title[i] <- paste(year[i],name,unit,sep="\n")
    }
  } else if (metric=="fiveyr_avg_mgy"){ #this metric isn't associated w a runid
    name <- "5-yr Avg Use"
    unit <- "(MGY)"
    legend_title<- paste(name,unit,sep="\n")
  } else {
    legend_title<- paste(metric)
  }
  return(legend_title)
}

```

```{r data_configuration, echo=FALSE, warning=FALSE, results='hide'}
# reading in the user inputs from params
for(i in 1:length(params)){
  assign(names(params[i]), params[[i]])
}
generate_rmetrics = TRUE
run_config = NULL
if (!is.null(params$run_set)) {
  run_config <- run_sets[[run_set]]
} 
# *****************************************************
# Insure Backward Compatibility With rivseg_metric input
# *****************************************************
# need to load or create nested array riverseg_metrics
# this is deprecated and support will go away 
# because it involves guessing what the column names are
if (is.null(run_config)) {
  run_config = list(riverseg_metrics=list())
  n = 0
  for (j in rivseg_metric) {
    for (i in 2:length(runid_list)) {
      n = n + 1
      run_config$riverseg_metrics[[n]] = list(metric = j, column_name = paste("percentDiff", j,runid_list[1],runid_list[i],sep="_"))
    }
  }
} else {
  # we got a valid run_config so load riverseg_metrics AND generate rivseg_metric
  rivseg_metric = c()
  
  for (j in 1:length(run_config$riverseg_metrics)) {
    rivseg_metric[j] = run_config$riverseg_metrics[[j]]$metric
  }
}

```

```{r Load Data, echo=FALSE, warning=FALSE, results='hide'}
regions_file <- paste0(HARParchive_location, '/HARP-2023-Summer/Mapping/Data/regions_sf.csv')
counties_file <- paste0(HARParchive_location, '/HARP-2023-Summer/Mapping/Data/counties_sf.csv')
cities_file <- paste0(HARParchive_location, '/HARP-2023-Summer/Mapping/Data/cities.csv')
roads_file <- paste0(HARParchive_location, '/HARP-2023-Summer/Mapping/Data/roads_sf.csv')

facils <- sf::st_as_sf(read.csv(featrs_file), wkt = "WKT", crs=crs_default, remove=FALSE)
rsegs <- sf::st_as_sf(read.csv(rsegs_file), wkt = "WKT", crs=crs_default, remove=FALSE)
counties <- sf::st_as_sf(read.csv(counties_file), wkt = "WKT", crs=crs_default, remove=FALSE)
cities <- fread(cities_file) #no sf geom in cities file; st_read converts columns to character (need coords to be numeric)
roads <- sf::st_as_sf(read.csv(roads_file), wkt = "WKT", crs=crs_default, remove=FALSE)
regions <- sf::st_as_sf(read.csv(regions_file), wkt = "WKT", crs=crs_default, remove=FALSE)

```

```{r Bbox, echo=FALSE, message=FALSE, warning=FALSE}

if(bbox_type == "custom" & origin %in% names(custom_bboxes)){ #search for custom bbox in config
  #formatting custom border coordinates to bbox object:
  bbox <- SpatialPoints(custom_bboxes[origin])
  bbox <- st_bbox(bbox)
} else { #auto bbox. should always be around the basins intersecting region of interest
  sf_use_s2(FALSE) # switch off Spherical geometry
  bbox <- st_buffer(st_as_sfc(st_bbox(rsegs)), .02) #slightly past basin
  bbox <- st_bbox(bbox)
}

```


```{r Get NHD in Bbox, echo=FALSE, message=FALSE, warning=FALSE}

# NHD data within the bbox
if (show_map == TRUE) {
  st_crs(bbox) <- crs_default
  nhd  <- memo_plot_nhdplus(bbox = bbox, actually_plot = FALSE, flowline_only = FALSE)
  
  ## Sometimes returns a list of NULLS in te cache. If thats the case, then clear the cache
  if (is.null(nhd$flowline)) {
    forget(memo_plot_nhdplus)
    nhd  <- memo_plot_nhdplus(bbox = bbox, actually_plot = FALSE, flowline_only = FALSE)
  }
  
  nhdlabs <- fn_nhd_labs(nhd)
}
```

```{r Filter NHD, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
# Was trying to remove the need for the fn_nhd_labs() since that basically just filters the nhd data now, but ran into some errors...

if (show_map == TRUE) {
  # First organize flowline data with major rivers/streams
  #major rivs = orders 5 & 6; streams = order 4
  flow <- nhd$flowline[nhd$flowline$gnis_name!=' ' & #name!=blank & order 4, 5, or 6
                          (nhd$flowline$StreamOrde==6 | nhd$flowline$StreamOrde==5 | nhd$flowline$StreamOrde==4),]
  flow <- flow[order(-flow$StreamOrde, flow$gnis_name, -flow$LENGTHKM) & !duplicated(flow$gnis_name),] #no duplicate names; prioritize higher order names and then the longest segment of each duplicate
  flow$gnis_name <- mgsub(flow$gnis_name, # shorten long names
                          c('North Fork','South Fork','East Fork','West Fork','Middle Fork'), #pattern
                          c('NF','SF','EF','WF','MF')) #replacement
  flow$StreamOrde <- mgsub(flow$StreamOrde, c(4,5,6), c("stream","majorRiver","majorRiver"))
  colnames(flow) <- gsub("StreamOrde", "class", colnames(flow))
  
  # Now do the same for the water bodies
  wtbd <- rbind(nhd$network_wtbd, nhd$off_network_wtbd)
  statemt <- paste("SELECT *,
                    CASE WHEN lakevolume BETWEEN",quantile(wtbd$lakevolume, 0.0,T),"AND",quantile(wtbd$lakevolume, 0.5,T),
                      "THEN 'wtbd_sm'
                    WHEN lakevolume BETWEEN",quantile(wtbd$lakevolume, 0.5,T),"AND",quantile(wtbd$lakevolume, 0.75,T),
                      "THEN 'wtbd_med'
                    WHEN lakevolume >",quantile(wtbd$lakevolume, 0.75,T),
                      "THEN 'wtbd_lg'
                    ELSE 'unclassified'
                    END as class
                    FROM wtbd
                    WHERE (gnis_name != ' ' AND gnis_name != 'Noname' AND gnis_name IS NOT NULL)
                   ", sep=" ")
  wtbd <- fn_sqldf_sf(statemt, "wtbd")
  
  # enseure both datasets have same crs prior to rbind()
  st_crs(flow) <- crs_default
  st_crs(wtbd) <- crs_default 
  nhd2 <- rbind( flow[,c("gnis_name", "class", "geometry")], wtbd[,c("gnis_name", "class", "geometry")] )
}
```

```{r Prep Text Labels, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
if (show_map == TRUE) {
  rm(maplabs)
  maplabs <- fn_labelprep(data=list(counties, cities, roads, nhdlabs), classes=c("county","city","road","nhd"))
}
```

# How to use this document:

This document is a summary of information pulled from the 2020 State Water Resources Plan, and is provided to assist with the requirements of 9VAC25-780. Data and modeling results are displayed for river segments intersecting the Region and/or Local Government boundaries (“region”). Water withdrawn upstream of these boundaries impacts the local governments, and water withdrawn within each boundary impacts downstream users. The first map and corresponding table display facilities within each region. Subsequent maps and tables display modeling results for each river segment. Note that these results are based on existing use, permitted use, and projected growth information provided in original 2008-2011 submission of water supply plans, or the 2017-2018 5-year water supply plan update.

This document does not provide current reported water use data. Excel Workbook 70-80-100, provided separately, contains information on individual water sources and water use. The information contained in this summary may be helpful in developing a regional water supply plan, but is not required. 

To assist with 9VAC25-780-100 I 3, Water Availability: instream water availability changes inclusive of withdrawals and storage is provided. Additionally, the 2040 demand scenario under short-term drought (30 day low flow), long term drought (90 day low flow), and overall percent of flow change, are relevant for showing the simulated impacts of projected demands on in-stream water availability. The potential unmet demand tables also provide information on the impacts of scenarios such as future demand on water supply sources. 

To assist with 9VAC25-780-100 J, cumulative demand, use conflicts, or in-stream flow information: Table 1 shows the change in cumulative demand between 2020 and 2040 projections. The potential unmet demand table presents potential beneficial use conflicts, and overall change in flow shows simulated changes to in-stream flow. One way plan developers could use this information is to check if identified alternatives are located in a river segment with greater than 10% reductions in streamflow during the planning period, and then consider that alternative as potentially unavailable. 

To assist 9VAC25-780-125, risk identification: 

For 9VAC25-780-125 B 2, the projected lowest 90 day flow under the dry climate scenario may be used to evaluate how stream flows may be impacted by climate change.  

For 9VAC25-780-125 B 3, the lowest 30 day flow and lowest 90 day flow are provided under the 2040 projected demand scenario, and can be used to estimate short and long term drought respectively.  

For 9VAC25-780-125 B 5, the 7Q10 flow is provided. The 7Q10 describes a 7 day low flow condition that is expected to occur only one time in a 10-year period. The 7Q10 metric is used to establish point source discharge limits and is used to assess potential risks to assimilative capacity from water supply system changes. 

# Facilities within Regions and Local Government:

## Facility Map(s):

This map displays facilities located within river segments that intersect a local government or regional planning unit boundary.
If a local government or regional planning unit boundary intersects the groundwater management area, a map of critical cells is also included.


```{r Create Map 1, echo=FALSE, message=FALSE, warning=FALSE}
#----Map 1----
# Legend Bins

#create human-readable title based on origin & type
if (origin_type == "basin") {
  title_main <- (paste("Basin Upstream of", rsegs$name[rsegs$riverseg==origin] , origin, sep=" "))
} else if (origin_type == "locality") {
  origin_readable <- gsub("([a-z])([A-Z])","\\1 \\2", origin)
  title_main <- paste0(counties[["name"]][counties[["dh_fips"]]==origin]," Locality")
} else if (origin_type == "region") {
  origin_readable <- gsub("([a-z])([A-Z])","\\1 \\2", origin)
  title_main <- paste0( gsub("_", " ", origin_readable) , " Region")
  
} 

if (show_map == TRUE) {
  for (i in 1:length(featrs_file_map_bubble_column)) { #execute for each metric in featrs_file_map_bubble_column param 
    legend_title <- readable$human[grep(featrs_file_map_bubble_column[i], readable$computer)]

    #add column of NAs when no metric col exists, when no facilities with the desired metric exist in the extent
    if ((featrs_file_map_bubble_column[i] %in% colnames(facils)) == FALSE) {
      facils[featrs_file_map_bubble_column[i]] <- NA
      mapMessage <- TRUE #for returning message to user if map is empty
    } else { mapMessage <- FALSE  }
    #Ordering & numbering data by the metric to be mapped 
     facils <- fn_sqldf_sf(paste0( #ordering the data using sqldf 
     "SELECT facils.*  
     FROM facils
     ORDER BY", ' ', featrs_file_map_bubble_column[i], ' ', "DESC"), #ordering by the metric of interest, descending 
     "facils")
    facils$NUM <- seq(1, nrow(facils))
    
    metric_unit <- substr(featrs_file_map_bubble_column[i], nchar(featrs_file_map_bubble_column[i]) - 2, 
                          nchar(featrs_file_map_bubble_column[i]))  #get metric unit from last 3 characters of metric 
    if (metric_unit == "mgd") { #different ranges for mgd and mgy
      div <- wd_mgd
    } else if (metric_unit == "mgy") {
      div <- wd_mgy
    } else {
      div <- wd_mgy #default units of million gallons per day 
    }
    
    mp_layer_sql <- paste('SELECT *, ',featrs_file_map_bubble_column[i],' AS demand_metric
          FROM facils' , sep="") #Renaming metric of interest for generalized sorting into bins
    mp_layer <- fn_sqldf_sf(mp_layer_sql, "facils")
    bins = as.data.frame(div)
    bins$classid <- index(bins)
    names(bins) <- c("val", "bin")
  
    entity_classes <- fn_sqldf_sf( #sorting the data into bins based on their range 
        "select a.NUM, max(b.bin) as bin
        from mp_layer as a 
        left outer join bins as b 
        on (a.demand_metric >= b.val) 
        group by a.NUM" , "mp_layer")
    
    mp_layer <- fn_sqldf_sf( #joining the bins with the metric data 
        "select a.*, b.bin 
        from mp_layer as a 
        left outer join entity_classes as b 
        on a.NUM = b.NUM " , "mp_layer")
  
    mp_layer$bin[is.na(mp_layer$bin)] <- "X" # replacing NA values in bin column
    names(mp_layer)[names(mp_layer) == 'demand_metric'] <- featrs_file_map_bubble_column[i] #change column name back to the specific metric
    mp_layer <- mp_layer[, !duplicated(colnames(mp_layer))] #remove duplicated columns
    mp_layer <- fn_centroid_coords(mp_layer)
    
    rsegs <- fn_centroid_coords(data = rsegs, geom_col = "geometry", crs = crs_default)

    ## Create title for the map
    ##instead:
    #maplabel <- new_metric_name[grep(featrs_file_map_bubble_column[i], read_metric_name)]
    if(featrs_file_map_bubble_column[i] %in% readable$computer){
      maplabel <- readable$human[readable$computer==featrs_file_map_bubble_column[i]]
    }else {
      maplabel <- featrs_file_map_bubble_column[i]
    }

    #create map title by combining label and title
    #maptitle <- paste0(title_main, ", ", maplabel)
    map_style_set <- styles[[map_style]]
    
    map <- fn_mapgen(bbox, crs_default, metric_unit, mp_layer, featr_type, 
                     maptitle=title_main, mapnum=1, rseg_leg_title=NULL, map_server,
                     base_layer, 
                     maplabs, nhd, roads, rsegs, map_style_set, rivmap_ramp=NULL)
                    
    #assign map to environment
    assign(paste0('map', i), map, envir = globalenv())
  }

  ##### Mapping Errors:
    # Error in if (distance > 300) { : missing value where TRUE/FALSE needed
    # Solution: this indicates the bbox is not in the format needed by the function. 
      # Regenerate the bbox and make sure it is of class bbox and has names xmin, xmax, etc.
  
    # Error in rbind(deparse.level, ...) : numbers of columns of arguments do not match
    # Solution: maplabs object needs to be removed and re-generated
  #####

  # Save map as png
  map_name <- origin
  
  #add sources or facils to name based on type 
  if (featr_type == "source") {
    map_name <- paste0(map_name, '_sources')
  } else if (featr_type == "facility") {
    map_name <- paste0(map_name, '_facils')
  }
  
  # Saving map(s) as a png
  # export_path set in config for analysts, set in console if nonexistent to location where map will be exported 
  mapfilename <- character() #empty character var, not a list
  for (i in 1:length(featrs_file_map_bubble_column)) {
    mapfilename[i] <- paste(export_path, map_name, "_", featrs_file_map_bubble_column[i], ".png", sep="")
    mapf <- get(paste0('map',i))
    ggsave(
      filename = mapfilename[i],
      plot = mapf,
      width = 25,
      height = 20)
  } 
  facils_nogeom <- st_drop_geometry(facils)

} else { #if we don't want to show maps 
  #still need to sort & number data for table even if not mapping 
  #default when not mapping will be sorting table by first entry of table columns 
  facils_nogeom <- st_drop_geometry(facils)
  class(facils_nogeom[,featrs_file_table_column[1]]) <- "numeric"
  facils <- fn_sqldf_sf(paste0( #ordering the data using sqldf 
     "SELECT facils_nogeom.*  
     FROM facils_nogeom
     ORDER BY", ' ', featrs_file_table_column[1], ' ', "DESC")) #ordering by the metric of interest, descending 
  facils_nogeom$NUM <- seq(1, nrow(facils))
}

```

```{r View_Map_1, echo=FALSE, out.width = '100%', out.height='100%', message=TRUE,eval = show_map}
knitr::include_graphics(mapfilename) #display map(s) PNG -- not functional inside loop
# if (mapMessage) {
#   message("The metric requested does not exist for this map.")
#   message("Check your syntax/spelling. If correct, then this data has not been measured/modeled")
# }

messages <- data.frame(pertaining_to=character(0), message=character(0), 
                        var_name=character(0) )
if (mapMessage) {
  messages <- rbind(messages,
                    data.frame(pertaining_to= "Map 1",
                              message=paste0("The requested metric: ", featrs_file_map_bubble_column[i]," ; does not exist for this map.\nCheck your syntax/spelling. If correct, then this data has not been measured/modeled."),
                       var_name= "mapMessage"
                       )
                    )
}

```

```{r Create Table 1, echo=FALSE, message=FALSE, warning=FALSE}
#facils_nogeom created if show_map = FALSE
if (show_map == FALSE) {
  facils_table <- facils_nogeom
} else {
  facils_table <- st_drop_geometry(facils)
}

## Establishing status in the facility name field
#### Appending a symbol onto name if it is inactive/proposed
facils_table$facility[!is.na(facils_table$facility_status) &
                      facils_table$facility_status == "Out of Service/Temporarily Inactive"] <-
  paste0(facils_table$facility,"*")

facils_table$facility[!is.na(facils_table$facility_status) &
                      facils_table$facility_status == "Proposed"] <-
  paste0(facils_table$facility,"**")

#create initial table
table <- data.frame(
  Map_Number = facils_table$NUM,
  Facility =facils_table$facility,
  CEDS_Facility_Id = facils_table$CEDS_Facility_Id, 
  Locality = facils_table$Locality, 
  GW_Fraction = facils_table$gw_frac)

#for source type only add mp name and source type to table
if (featr_type=="source"){
  table$Source = facils_table$MP_Name  
  table$Source_Type = facils_table$Source_Type
}

#add rivseg names
table$`River Segment Name` <- facils_table$rseg_name

table$`River Segment ID`= facils_table$riverseg #add rivseg ID

table$`Total Permitted Capacity (MGY)` <- facils_table$Total_Permit_Limit_MGY #add permitted capacity to table 

for (i in 1:length(featrs_file_table_column)){
  #metric col of interest may not exist if none were found in extent: don't break if this is the case
  if (featrs_file_table_column[i] %in% colnames(facils_table)) {
  #adding requested columns to table
    table[,featrs_file_table_column[i]] <- round(as.numeric(facils_table[,featrs_file_table_column[i]]), digits = 2)
    
    ## For facils where GW_frac = 1, there is no modelling data. NAs are rewritten as something more meaningful
    #### Check if its  a modelling column
    if (grepl('runid_',featrs_file_table_column[i])) {
      ## Rewrite column when GWFrac = 1
      table[table$GW_Fraction == 1 & !is.na(table$GW_Fraction),featrs_file_table_column[i]] <- "No model"
      
    }
    
  }
}
## When a facility is only GW, it will not have a riverseg, so this is added
table$`River Segment ID`[table$GWFrac == 1 & !is.na(table$GWFrac)] <- "No model"
table$`River Segment Name`[table$GWFrac == 1 & !is.na(table$GWFrac)] <- "No model"

table <- table[,colSums(is.na(table))<nrow(table)] #remove columns with all NAs, added to df for mapping as placeholders 

#compare requested table columns with those that actually exist 
novals <- data.frame(metric=character())
for (i in 1:length(featrs_file_table_column)) {
  if (!featrs_file_table_column[i] %in% names(table)) {
    novals[i,] <- featrs_file_table_column[i]
  }
}
#for returning message if metric table columns were missing 
if (nrow(novals > 0)) {
  tableMessage <- TRUE
} else { tableMessage <- FALSE }

# Rename columns & create flextable
for (i in 1:length(featrs_file_table_column)) {
  for (x in 1:nrow(readable)){
    if (featrs_file_table_column[i]==readable$computer[x])
    {
      names(table)[names(table)==featrs_file_table_column[i]] <- readable$human[x]
    }
    else
    {
      next
    }
  }
}
names(table) <- mgsub(names(table), pattern="_", replacement=" ") #formatting for flextable headers, line breaks happen at spaces not underscores

ft1 <- fn_tablegen(table = table, 
                   columns = "all", alignment = "left", 
                   tabletitle = title_main, num = "1.1",
                   highlight_col = FALSE, highlight_limit = NULL) #execute flextable function
# ft1 <- add_header_lines(ft1, values= "Table 1.1") #add subtite
ft1 <- width(ft1, j= 'River Segment ID', width = 1) #making sure rseg ID isn't cut off in facil/source tables

```


```{r GW_Maps, echo = FALSE, message=FALSE, warning=FALSE, out.width = '100%', out.height='100%', results='asis', eval = show_map}

## Reading in the shapefiles from the onedrive
#### Also transforms them innto lat/lon
## Potomac
potomac <- read_sf(dsn = paste0(onedrive_location,'/OWS/GIS/Aquaveo GW Model/2020 State Plan/Potomac/Potomac_Critical_Cells_in_2040.shp'))
potomac <- st_transform(potomac,4326)
potomac <- st_set_crs(potomac,4326)

## Aquia
aquia <- read_sf(dsn = paste0(onedrive_location,'/OWS/GIS/Aquaveo GW Model/2020 State Plan/Aquia/AQAQ_Critical_Cells_in_2040.shp'))
aquia <- st_transform(aquia,4326)

## Piney Point
pineypoint <- read_sf(dsn = paste0(onedrive_location,'/OWS/GIS/Aquaveo GW Model/2020 State Plan/PineyPoint/PPAQ_Critical_Cells_in_2040.shp'))
pineypoint <- st_transform(pineypoint,4326)
pineypoint <- st_set_crs(pineypoint,4326)

# ## Yorktown-Eastover
yorktown <- read_sf(dsn = paste0(onedrive_location,'/OWS/GIS/Aquaveo GW Model/2020 State Plan/Yorktown-Eastover/YEAQ_Critical_Cells_in_2040.shp'))
yorktown <- st_transform(yorktown,4326)
yorktown <- st_set_crs(yorktown,4326)

## Reading in the GWMA layer
GWMA_wkt <- read.csv(paste(github_location,'/HARParchive/GIS_layers/GWMA_wkt.csv',sep=''))
## Only the coastal plain
GWMA_wkt <- GWMA_wkt[2,]
GWMA_wkt <- st_as_sf(GWMA_wkt, wkt = "Geometry", crs = st_crs(4326))

## Need to determine if the area intersects the aquifer to create the maps
#### Or at least the critical cell part
if (origin_type == 'region') {
  ## Gets the shape to use as a boundary
  origin_shape <- regions[regions$region == origin,]
} else if (origin_type == 'locality') {
  origin_shape <- regions[regions$region == counties$Region[counties$hydrocode == origin],]
}

## Checking for intersection
insidegwma <- st_intersection(origin_shape,GWMA_wkt )

## Checks if the region intersects the GWMA
#### Built in an exception for the Eastern Shore, since it only needs the Yorktown Eastover aquifer
if (origin_shape$region == "Eastern_Shore") {
  
  cat('\n## Groundwater Critical Cell Maps \n')

  ## Yorktown Eastover
  aquifer <- 'Yorktown Eastover'
  
  yorktowneastover_map <- fn_gw_mapgen(
    bbox, crs_default,  mp_layer, featr_type,
    maptitle=paste0(origin_readable," critical cells in ", aquifer),
    maplabs, nhd, roads, map_style_set, rivmap_ramp=NULL,
    aquifer_shp = yorktown, origin_shape = origin_shape)
  
  ## Save the file
  ggsave(filename = paste0(export_path,origin,'_Yorktown_Eastover.png'),
         plot = yorktowneastover_map,width=25,height=20)
  
  ## Includes the saved file
  cat(paste0('![](',export_path,origin,'_Yorktown_Eastover.png)'))
  
  
  cat("\n\n\\pagebreak\n")

  
} else if (nrow(insidegwma) > 0) {
  
  cat('\n## Groundwater Critical Cell Maps \n')
  
  ### Potomac
  aquifer <- 'Potomac'
  
  ## Calls fn_gw_mapgen. Basically a stripped version of fn_mapgen that adds in aquifer_shp
  potomac_map <- fn_gw_mapgen(bbox, crs_default,  mp_layer, featr_type, 
                              maptitle=paste0(origin_readable," Critical Cells in ", aquifer), 
                              maplabs, nhd, roads, map_style_set, rivmap_ramp=NULL,
                              aquifer_shp = potomac, origin_shape)
  
  ## Saves the file
  ggsave(filename = paste0(export_path,origin,'_',aquifer,'.png'),
         plot = potomac_map,width=25,height=20)
  
  ## Includes the saved file
  cat(paste0('![](',export_path,origin,'_',aquifer,'.png)'))
  
  ### Aquia
  aquifer <- 'Aquia'
  
  aquia_map <- fn_gw_mapgen(bbox, crs_default,  mp_layer, featr_type, 
                            maptitle=paste0(origin_readable," Critical Cells in ", aquifer), 
                            maplabs, nhd, roads, map_style_set, rivmap_ramp=NULL,
                            aquifer_shp = aquia, origin_shape)
  
  ggsave(filename = paste0(export_path,origin,'_Aquia.png'),
         plot = aquia_map,width=25,height=20)
  
  ## Includes the saved file
  cat(paste0('![](',export_path,origin,'_',aquifer,'.png)'))
  
  ### Piney Point 
  aquifer <- 'Piney Point'
  
  pineypoint_map <- fn_gw_mapgen(bbox, crs_default,  mp_layer, featr_type, 
                                 maptitle=paste0(origin_readable," Critical Cells in ", aquifer), 
                                 maplabs, nhd, roads, map_style_set, rivmap_ramp=NULL,
                                 aquifer_shp = pineypoint, origin_shape)
  
  ## Piney Point cant have a space in the filename
  ggsave(filename = paste0(export_path,origin,'_Piney_Point.png'),
         plot = pineypoint_map,width=25,height=20)
  
  ## Includes the saved file
  cat(paste0('![](',export_path,origin,'_Piney_Point.png)'))
  
# ## Yorktown Eastover
# 
#   aquifer <- 'Yorktwon Eastover'
# 
#   yorktowneastover_map <- fn_gw_mapgen(bbox, crs_default,  mp_layer, featr_type,
#                               maptitle=paste0(origin_readable," critical cells in ", aquifer),
#                               maplabs, nhd, roads, map_style_set, rivmap_ramp=NULL,
#                               aquifer_shp = yorktown)

  ## Adds a pagebreak IF there are GW maps

  cat("\n\n\\pagebreak\n")
  
  ## End of GW mapping section
}

```
## Facility Table (Table 1):

Table 1 accompanies the facility map(s) shown above. The "Map Number" in the table corresponds to the number within the bubbles in the map(s) above. Facilities that are geographically close together may partially or fully overlap each other on the map. Where this occurs, although not all Map Numbers will be visible on the map, the bubbles will be darker due to the overlap.

The table includes active, inactive, and proposed facilities. Abandoned facilities are not included. Inactive facilities are marked with an asterisk (\*), and proposed facilities are marked with a double asterisk (\*\*).


**Notes:**

 * Facilities constructed or otherwise made known to DEQ after the initial plan submission are not show in 2020 scenario.
 * If a facility/source is outside groundwater management area, then it is not subject to groundwater permitting.
 * When the groundwater fraction listed is 1.0, then the facility does not have surface water withdrawals, and does not have surface water modelling values, reflected as "no model".
 * Permit exemption status is based on those who identified as exempt during the 2009 Request for Information (RFI).
 * If a facility has sources in more than one river segment, there will be multiple rows in the table showing the same facility with different river segments. The map numbers corresponding to the same facility will overlap on the map. 
 * The 2020 Demand and 2040 Demand Scenario Withdrawals (MGD) columns below reflect modeled outputs, based on simulated conditions in the watershed.
 * The Water Supply Plan 2040 Demand (MGY) column reflects inputs provided in original 2008-2011 submission of water supply plans, or the 2017-2018 5-year water supply plan update. 

\pagebreak

```{r View Table 1, echo=FALSE, out.width='100%', message=TRUE}
# if (tableMessage == TRUE) {
#   message("Missing column indicates the metric requested does not exist for this table")
# }
block_section(prop_section(type = "continuous"))

if (tableMessage) {
 messages <- rbind(messages,
                      data.frame(pertaining_to= "Table 1",
                       message=paste0("Missing column(s): ",  paste(novals[,1], collapse=', '), " ; indicate the requested metric(s) do not exist for this table."), var_name= "tableMessage")
                      )
}

ft1 #display flextable

## This line tells it to stop formatting, but also defines what is being formatted? In this case, the page orientation. 
#### Officer seems confusing, but this works
block_section(
  prop_section(
    page_size = page_size(orient = "landscape"),
    type = "continuous"
  )
)
```

\pagebreak


# 2040 Modelled Demand Scenarios:

The following maps and table show modeling results for future 2040 demands. The 2040 scenario was developed to model cumulative impacts under future conditions for the year 2040. The primary inputs are estimates of future water demands using projections submitted through local and regional water supply plans, combined with current meteorological conditions. More details on the modeling inputs and scenarios have been published in "Chapter 4.2 - Cumulative Impact Analysis - Surface Water" of the [2020 State Water Resources Plan](https://www.deq.virginia.gov/home/showpublisheddocument/16134/637991887436000000). 

```{r Create Map 2, echo=FALSE, message=FALSE, warning=FALSE}
#----Map 2----

  map_objects = list()
  rivmapfilename <- character() #empty character var, not a list, to store map names
  for (i in 1:length(run_config$riverseg_metrics)){ #something going wrong in rsegs df within this loop 
     
     display_map <- run_config$riverseg_metrics[[i]]$show_map
     ## If display_map is NULL skip this next part (should never happen)
     if (is.null(display_map)) { display_map = FALSE}
     if (display_map == TRUE) {
      display_metric <- run_config$riverseg_metrics[[i]]$metric
      display_column <- run_config$riverseg_metrics[[i]]$column_name
      display_title <- run_config$riverseg_metrics[[i]]$run_label
      
      ## Adjusting title if the its a very tall map that causes it to get cut off
      if ((bbox[4] - bbox[2])/(bbox[3] - bbox[1]) > 1.1 & nchar(display_title) > 55) {
        ## How do i know when to put the new line?
        display_title <- gsub("[(]"," \n (",display_title)
      }
      
      ramp <- run_config$riverseg_metrics[[i]]$ramp
    
      rivmapmetric <- paste0(display_metric) #define title here for mapping so each map has diff metric title, pass into function
      
      if(display_metric %in% readable$computer){
        rivmaplabel <- readable$human[readable$computer==display_metric]
      }else {
        rivmaplabel <- rivmapmetric
      }
      
      rsegs <- rsegs[ , !names(rsegs) %in% c("pct_diff", "bin")]
      
      ## Removing values from rsegs ending in _0000 as they can often not represent real results
      rsegs[grepl("_0000$", rsegs$riverseg) , display_column] <- NA
      
      ##Work-around to problem above: change column name
      rseg_geom <- rsegs$geometry #save geometry before dropping
      rsegs <- st_drop_geometry(rsegs)
      bins = as.data.frame(rivmap_ramps[[ramp]][,"rivseg_pct_vect"]) #rivseg_pct_vect set in config
      bins$classid <- index(bins)
      names(bins) <- c("val", "bin")
      bins$val <- as.numeric(bins$val)
      #write.csv(bins, paste0(export_path,"47_bins_",rseg_leg_title,".csv"))
      
      rivseg_classes <- sqldf( #sorting the data into bins based on their range 
        paste0("select a.riverseg, 
        CASE 
          WHEN a.", display_column," >= bmax.maxval THEN bmax.maxbin
          WHEN a.", display_column," <= bmax.minval THEN bmax.minbin
          ELSE min(b.bin)
        END as bin
      from rsegs as a 
      left outer join bins as b 
        on (a.", display_column," <= b.val )
      left outer join (
        select max(val) as maxval, max(bin) as maxbin,
          min(val) as minval, min(bin) as minbin
        from bins
      ) as bmax 
        on (
          1 = 1 
        )
      group by a.riverseg" )
      )
      
      rsegs <- sqldf( #joining the bins with the metric data 
        "select a.*, b.bin 
      from rsegs as a 
      left outer join rivseg_classes as b 
      on a.riverseg = b.riverseg " , "rsegs") 
      
      
      rsegs_sf <- st_as_sf(rsegs, wkt = 'WKT') #this function removes WKT col, so create new df to prevent loop error
      st_crs(rsegs_sf) <- crs_default
      
      ##Mapping function
      map_rivseg <- fn_mapgen(bbox, crs_default, metric_unit, mp_layer, featr_type, 
                              maptitle = display_title, mapnum=2, rseg_leg_title=display_title, 
                              map_server, base_layer, maplabs, nhd, roads, 
                              rsegs=rsegs_sf, map_style_set,
                              rivmap_ramp=rivmap_ramps[[ramp]])
      map_objects[[i]] <- map_rivseg
      #assign map to environment
      assign(paste0('map_rivseg', i), map_rivseg, envir = globalenv())
      
      ## Save rivseg map
      rivmapfilename[i] <- paste(export_path, map_name, "_", display_column, ".png", sep="")
      ggsave(
        filename = rivmapfilename[i],
        plot = map_rivseg,
        width = 25,
        height = 20)
      
     }
     
  }
```



```{r Create Table 2 UPDATED, echo=FALSE, message=FALSE, warning=FALSE}

#NEW TABLE WITH RUNSET

rivTables <- list() #to store dataframes for each drought metric
rseg_no_geom <- st_drop_geometry(rsegs) #copy of rsegs 

  # base info
for (k in 1:length(run_config$riverseg_metrics)){
  data_set <- run_config$riverseg_metrics[[k]]$data_set
  table_cols <- unlist(run_config$riverseg_metrics[[k]]$tables_cols)
  display_column <- run_config$riverseg_metrics[[k]]$column_name
  
  # test for existence of data_set variable (i.e. data_set = "rseg_no_geom", or data_set = "facils_nogeom"
  if (exists(data_set) & is.null(run_config$riverseg_metrics[[k]]$hide_table)) {
    rseg_display <- get(data_set)
    
    ## If the dataset is rsegs, need to remove tidal / _0000 segments from the results, as they are often not "real"
    if (data_set == "rseg_no_geom") {
      rseg_display <- rseg_display[!grepl("_0000$", rseg_display$riverseg) , ]
    }
    
    display_metric <- run_config$riverseg_metrics[[k]]$metric
    display_title <- run_config$riverseg_metrics[[k]]$run_label
    
    #metrics, to be suppressed later?
    #rseg_display$Metric <- display_metric 

    #assemble our table, with the columns in order defined by table_cols
    # cols present
    cols_present <- table_cols[which(table_cols %in% names(rseg_display))]
    message_nonexisting_cols <- any(!table_cols %in% cols_present) 
    rseg_display <- rseg_display[cols_present] #need to make sure table_cols and column_name properly done in mapstyle_config or will get error here

    ## 08-13-24 Added Code: Rounding all numeric columns to 1 decimal point
    ## Only uses numeric columns as found by sapply (which returns a vector)
    rseg_display[,sapply(rseg_display, is.numeric)] <- round(rseg_display[,sapply(rseg_display, is.numeric)],1)
    
    #na messages 
    
    nacols <- colSums(is.na(rseg_display)) == nrow(rseg_display)
    tablemessage2 <- any(nacols) 
    
    rivTables[[k]] <- rseg_display
    
    #fill blanks with NA
    rivTables[[k]][rivTables[[k]] == ''] <- NA
    
    rivTables[[k]] <- fn_filter_table(table_data=rivTables[[k]], run_set_k=run_config$riverseg_metrics[[k]])
    
    #defining titles 
    rivtablemetric <- paste0(display_metric) #define title here for mapping so each map has diff metric title, pass into function
    

    rivtablenum <- k + 1 #for heading numbering, use 1 + rivtablenum since we already printed a table
  
    ft2 <- fn_tablegen(table = rivTables[[k]],
                       columns = cols_present, alignment = "left", 
                       tabletitle = display_title,
                       num=rivtablenum, highlight_col = display_column, 
                       highlight_limit = rivmap_ramps[[ramp]][1,"highlight_limit"]) #flextable function 
    
    new_cols <- colnames(rivTables[[k]])
    for (i in 1:length(colnames(rivTables[[k]]))) {
      if (colnames(rivTables[[k]])[i] %in% readable$computer) {
        new_cols[i] <- readable$human[readable$computer==colnames(rivTables[[k]])[i]]
      } else {
        next
      }
      }

    ref_table <- data.frame( #human readable column names
      key = colnames(rivTables[[k]]),
      label = new_cols
      )
    ft2 <- set_header_df(ft2, mapping = ref_table, key = "key")
    ft2 <- add_header_lines(ft2, values= display_title) #add subtite
    
    assign(paste0('table', k), ft2, envir = globalenv())
  
  } else {
    assign(paste0('table', k), NA, envir = globalenv())
  }
}
```



```{r View Rivseg Maps and Tables, out.width = '100%', out.height='100%', results='asis', echo=FALSE}
for (k in 1:length(run_config$riverseg_metrics)){
  
  ## Including a header for the section
  cat('\n## ',run_config$riverseg_metrics[[k]]$run_label,' \n')
  
  ## Including narrative IF there is a populated text file
  txtfile <- (paste0(HARParchive_location,"\\HARP-2023-Summer\\Section_Narratives\\",
                         run_config$riverseg_metrics[[k]]$run_label,".txt"))
  
  #### Checks if the text file exists AND if there is text in it (nchar > 0)
  if (file.exists(txtfile) & file.info(txtfile)$size > 0) {
    ## Seperating narrative from title
    cat("\n \n")
    
    ## Reads the text file as 1 character vector
    narrative <- readChar(txtfile, file.info(txtfile)$size)
    #### Replaces \r (carraige break) with \n (line break)
    narrative <- gsub('\r','\n',narrative)
    cat(narrative)
    
    ## Adding lines to seperate the table/map
    cat("\n \n")
    
  }
  
  #map
  show_map = run_config$riverseg_metrics[[k]]$show_map
  if (show_map == TRUE) {
    #fig_md = knitr::include_graphics(rivmapfilename)
    fig_md = paste(paste0("![](",rivmapfilename[k],")"),"\n")
  } else {
    fig_md = ''
  }
  
  #figure
  cat(fig_md)
   
  if(any(!is.na(get(paste0('table', k))))) {
    #table
    cat(knitr::knit_print(get(paste0('table', k))))
    cat("\n\n\\pagebreak\n")
  }
}

if(message_nonexisting_cols){
      messages <- rbind(messages,
                      data.frame(pertaining_to= "Table 2",
                       message=paste0("The requested columns: ", table_cols[!table_cols %in% cols_present]," ; could be found in the present data. Check mapstyle_config.R and Dataframe_Generator.R render"), var_name= "message_nonexisting_cols")
                      )
    }
    if(tablemessage2){
      messages <- rbind(messages,
                      data.frame(pertaining_to= "Table 2",
                       message=paste0("Column(s): ", paste(rownames(nacols)[nacols[1]==TRUE], collapse=", " )," ; in the table are completely NA values, likely meaning the requested metric is not modeled for this data, or that the segments are all tidal."), var_name= "tablemessage2")
                      )
    }
```

```{r Generate Errors Summary, echo=FALSE}
#if there are any mapping errors or other messages to the user, output a separate file containing them
# allmaps <- grep("gg", eapply(.GlobalEnv, class), value=TRUE)
# allmaps <- mget(names(allmaps), .GlobalEnv, mode = "list")
# #allmaps = map_objects
# maperrors <- data.frame(maptitle=character(0), errors=character(0), 
#                         mapnum=character(0), var_name=character(0) )
# for(i in 1:length(allmaps)){
#   if(!is.null(allmaps[[i]][["errors"]])){
#     if (is.null(allmaps[[i]][["mapnum"]])) {
#       allmaps[[i]][["mapnum"]] = 2
#     }
#     maperrors <- rbind(maperrors,
#                        data.frame(maptitle = allmaps[[i]][["labels"]][["title"]],
#                                   errors = allmaps[[i]][["errors"]],
#                                   mapnum = allmaps[[i]][["mapnum"]],
#                                   var_name = names(allmaps[i])
#                                   )
#                        )
#   }
# }
# 
# if(nrow(maperrors)==0){
#   maperrors <- rbind(maperrors, data.frame(maptitle="none", errors="none", 
#                         mapnum="none", var_name="none"))
# }
# tbl_maperrors <- mk_par(x = flextable(maperrors), j = c("maptitle","mapnum","var_name"),
#                         i = ~ duplicated(maperrors$var_name),
#                         value = as_paragraph('')
#                         )
# tbl_maperrors <- set_table_properties(tbl_maperrors, layout = "autofit")
# 
# 
# #other messages:
# if(nrow(messages)==0){
#   messages <- rbind(messages,
#                       data.frame(pertaining_to="none",
#                        message="none", var_name="none")
#                       )
# }
# tbl_usermessages <- flextable(messages)
# tbl_usermessages <- set_table_properties(tbl_usermessages, layout = "autofit")
# 
# #output to .html:
# emesg_file_path <- paste0(export_path, origin, "_ErrorsAndMessages.html")
# twrite_test <- try(
#   save_as_html("Messages to User:" = tbl_usermessages, "Errors With Mapping:" = tbl_maperrors,
#     path = emesg_file_path
#     )
# )
# if (class(twrite_test) == "try-error") {
#   message(paste("Notice: Problem writing ", emesg_file_path))
# }


```
