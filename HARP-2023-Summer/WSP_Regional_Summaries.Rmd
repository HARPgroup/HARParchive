---
title: "WSP Regional Summaries"
author: "HARP Analysts"
date: "`r Sys.Date()`"
geometry: margin=1cm #margins for pdf
output: pdf_document #overridden by output_format in render command 

#Here is the main editable part of the rmd, planners should adjust parameters as they see fit for their goals, see README documentation for more details on each parameter
#Can edit here or in a render command 
## More params used during development and testing for user-control -- will be consolidated  
params: 

  #facils_file: "C:/aa_HARP/aa_GitHub/Foundational_Data/example_files/JU4_7330_7000_facils_sf.csv"
  facils_file: "C:/HARP/Exports/PU6_3730_3750_mp_sf.csv"
  facils_file_map_bubble_column: ["wd_mgd"]
  facils_file_table_column: ["runid_11_wd_mgd","runid_13_wd_mgd","fiveyr_avg_mgy","wsp2020_2040_mgy"]

  rsegs_file: "C:/HARP/Exports/PU6_3730_3750_rsegs2_sf.csv"
  rivseg_metric: ["l30_Qout", "7q10"] #right now these arent exact column names in the resegs_file

  # list of runids for facil and rseg data
  runid_list: [ "runid_11", "runid_13" ]
  
  # specify the type of map by supplying either a rivseg, locality, or region

  rivseg: ["KU0_8980_0000"]
  locality: ["NA"]
  region: ["NA"]    
  map_type: ["basin"] #one of: basin, locality, or region 

  # default files for mapping base layers
  regions_file: "C:/aa_HARP/aa_GitHub/Foundational_Data/example_files/regions_sf.csv"
  counties_file: "C:/aa_HARP/aa_GitHub/Foundational_Data/example_files/counties_sf.csv"
  cities_file: "C:/aa_HARP/aa_GitHub/Foundational_Data/example_files/cities.csv"
  roads_file: "C:/aa_HARP/aa_GitHub/Foundational_Data/example_files/roads_sf.csv"

  # aesthetic changes
  crs_default: 4326 #default coordinate system 
  map_style: ["custom"] #determining map aesthetics like colors, fonts, font sizes
  bbox_type: ["auto"] #either 'auto' or 'vahydro'. vahydro map type only functional for segments 
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#ensure all packages and dependencies are installed prior to running 
library(data.table)
library(hydrotools)
library(mgsub)
library(sp)
library(sf)
library(nhdplusTools)
library(png)
library(flextable)
library(pandoc)
#tinytex::install_tinytex() #need to run if you don't have tinytex
library(tinytex)

#gather config info to log into vahydro  
basepath='/var/www/R'
source('/var/www/R/config.R')
ds <- RomDataSource$new(site, rest_uname)
ds$get_token(rest_pw)
```

```{r UserInputs, echo=FALSE}
# reading in the user inputs from params
for(i in 1:length(params)){
  assign(names(params[i]), params[[i]])
}
```

```{r Load Functions, echo=FALSE, warning=FALSE, results='hide'}
# For planners, updated when changes are merged to master
# Make sure github location in config file is properly set 
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_centroid_coords.R"),local = TRUE)
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_tablegen.R"),local = TRUE) #load table function
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_labelprep.R"),local = TRUE) #load labeling function
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_nhd_labs.R"),local = TRUE) #load nhd label function
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/rivsegmaps_config.R"),local = TRUE) #load rivseg-specific mapping aesthetics
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_spatial.R"),local = TRUE)


# the following will no longer needed, since the input dataframe will either be facility or MP-level data
#determining which type/level of map is being created (either 'source' or 'facility')
if (grepl('fac', facils_file)==TRUE) {
  type <- "facility"
}

if (grepl('mp', facils_file)==TRUE) {
  type <- "source"
}

```

```{r Load Dataframes Functions, echo=FALSE, warning=FALSE, results='hide'}

facils <- st_read(facils_file)
rsegs <- st_read(rsegs_file)
counties <- st_read(counties_file)
regions <- st_read(regions_file)
cities <- fread(cities_file) #no sf geom in cities file; st_read converts columns to character (need coords to be numeric)
roads <- st_read(roads_file)
regions <- st_read(regions_file)

st_crs(facils) <- crs_default
st_crs(rsegs) <- crs_default
st_crs(counties) <- crs_default
st_crs(roads) <- crs_default

# crs(rsegs)
# crs(facils)
# crs(counties)
# crs(roads)
```

```{r Bbox, echo=FALSE, message=FALSE, warning=FALSE}
if(bbox_type == "vahydro") { #retrieve bbox from vahydro property if desired
#note: only operational for river segments/basins
  for (i in 1:nrow(rsegs)){ #not sure why we're looping through these if we're only saving the last one
    bbox <- ds$get_prop(config=list( #get bbox properties
                        featureid= RomProperty$new(ds,list( #get extent property pid
                                      propname="extent",
                                      entity_type="dh_properties",
                                      featureid= RomProperty$new(ds,list( #get map property pid
                                                    varkey="map", 
                                                    entity_type="dh_feature",
                                                    featureid= rsegs$hydroid[i]
                                                    ),TRUE)$pid #map pid
                                      ),TRUE)$pid, #extent pid
                        entity_type='dh_properties'))
    bbox <- data.frame(X=extent[1:2,4], Y=extent[3:4,4])
    bbox <- st_buffer(st_as_sf(extent_df, coords=c("X","Y"), crs=crs_default), .05)
    bbox <- st_bbox(bbox)
  }
} else { #auto bbox. should always be around the basins intersecting region of interest
  sf_use_s2(FALSE) # switch off Spherical geometry
  bbox <- st_buffer(st_as_sfc(st_bbox(rsegs)), .02) #slightly past basin
  bbox <- st_bbox(bbox)
}
```

```{r Get NHD in Bbox, echo=FALSE, message=FALSE, warning=FALSE}
# source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_nhd_labs.R"),local = TRUE) #load nhd label function
# NHD data within the bbox
st_crs(bbox) <- crs_default
nhd  <- plot_nhdplus(bbox = bbox, actually_plot = FALSE)
nhdlabs <- fn_nhd_labs(data=nhd)
#st_write(nhdlabs, paste0(export_path,"29_nhdlabs_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
```

```{r Filter NHD, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
# Was trying to remove the need for the fn_nhd_labs() since that basically just filters the nhd data now, but ran into some errors...

# First organize flowline data with major rivers/streams
#major rivs = orders 5 & 6; streams = order 4
flow <- nhd$flowline[nhd$flowline$gnis_name!=' ' & #name!=blank & order 4, 5, or 6
                        (nhd$flowline$StreamOrde==6 | nhd$flowline$StreamOrde==5 | nhd$flowline$StreamOrde==4),]
flow <- flow[order(-flow$StreamOrde, flow$gnis_name, -flow$LENGTHKM) & !duplicated(flow$gnis_name),] #no duplicate names; prioritize higher order names and then the longest segment of each duplicate
flow$gnis_name <- mgsub(flow$gnis_name, # shorten long names
                        c('North Fork','South Fork','East Fork','West Fork','Middle Fork'), #pattern
                        c('NF','SF','EF','WF','MF')) #replacement
flow$StreamOrde <- mgsub(flow$StreamOrde, c(4,5,6), c("stream","majorRiver","majorRiver"))
colnames(flow) <- gsub("StreamOrde", "class", colnames(flow))
#st_write(flow, paste0(export_path,"30_flow_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

# Now do the same for the water bodies
wtbd <- rbind(nhd$network_wtbd, nhd$off_network_wtbd)
statemt <- paste("SELECT *,
                  CASE WHEN lakevolume BETWEEN",quantile(wtbd$lakevolume, 0.0,T),"AND",quantile(wtbd$lakevolume, 0.5,T),
                    "THEN 'wtbd_sm'
                  WHEN lakevolume BETWEEN",quantile(wtbd$lakevolume, 0.5,T),"AND",quantile(wtbd$lakevolume, 0.75,T),
                    "THEN 'wtbd_med'
                  WHEN lakevolume >",quantile(wtbd$lakevolume, 0.75,T),
                    "THEN 'wtbd_lg'
                  ELSE 'unclassified'
                  END as class
                  FROM wtbd
                  WHERE (gnis_name != ' ' AND gnis_name != 'Noname' AND gnis_name IS NOT NULL)
                 ", sep=" ")
wtbd <- sqldf_sf(statemt, "wtbd")
#st_write(wtbd, paste0(export_path,"31_wtbd_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

# enseure both datasets have same crs prior to rbind()
st_crs(flow) <- crs_default
st_crs(wtbd) <- crs_default 
nhd2 <- rbind( flow[,c("gnis_name", "class", "geometry")], wtbd[,c("gnis_name", "class", "geometry")] )
#st_write(nhd2, paste0(export_path,"32_nhd2_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
```

```{r Prep Text Labels, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
maplabs <- fn_labelprep(data=list(counties, cities, roads, nhdlabs), classes=c("county","city","road","nhd"))
```

## Map 1:
```{r Remainder of the RMD, echo=FALSE, message=FALSE, warning=FALSE}
#----Map 1----
# Legend Bins
facils <- facils[,colSums(is.na(facils))<nrow(facils)] #for extra long & lat columns full of NAs
#st_write(facils, paste0(export_path,"33_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

wd_mgd = c(0, 0.5, 1.0, 2, 10, 25, 100, 1000) #set ranges for bins day and year 
wd_mgy = c(0, 1, 5, 10, 50, 250, 1000, 10000)

for (i in 1:length(facils_file_map_bubble_column)) { #execute for each metric in facils_file_map_bubble_column param 
  #legend_title <- paste0(facils_file_map_bubble_column[i])
  legend_title <- legend_titling(facils_file_map_bubble_column[i], runid_list)
  
  #add column of NAs when no metric col exists, when no facilities with the desired metric exist in the extent
  if ((facils_file_map_bubble_column[i] %in% colnames(facils)) == FALSE) {
    facils[facils_file_map_bubble_column[i]] <- NA
    mapMessage <- TRUE #for returning message to user if map is empty
  } else { mapMessage <- FALSE  }
  #Ordering & numbering data by the metric to be mapped 
   facils <- sqldf_sf(paste0( #ordering the data using sqldf 
   "SELECT facils.*  
   FROM facils
   ORDER BY", ' ', facils_file_map_bubble_column[i], ' ', "DESC"), #ordering by the metric of interest, descending 
   "facils")
  facils$NUM <- seq(1, nrow(facils))
  #st_write(facils, paste0(export_path,"34_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
 if (i==1) { #data for table will be sorted by the first of facils_file_map_bubble_column
   #facils$within <- facils_within
 } 
  
  metric_unit <- substr(facils_file_map_bubble_column[i], nchar(facils_file_map_bubble_column[i]) - 2, nchar(facils_file_map_bubble_column[i]))  #get metric unit from last 3 characters of metric 
  if (metric_unit == "mgd") { #different ranges for mgd and mgy
  div <- wd_mgd
  } else if (metric_unit == "mgy") {
  div <- wd_mgy
  }
  
  mp_layer_sql <- paste('SELECT *, ',facils_file_map_bubble_column[i],' AS demand_metric
        FROM facils' , sep="") #Renaming metric of interest for generalized sorting into bins
  mp_layer <- sqldf_sf(mp_layer_sql, "facils")
  #st_write(mp_layer, paste0(export_path,"35_mp_layer_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  bins = as.data.frame(div)
  bins$classid <- index(bins)
  names(bins) <- c("val", "bin")
  #write.csv(bins, paste0(export_path,"36_bins.csv"))

  entity_classes <- sqldf_sf( #sorting the data into bins based on their range 
      "select a.NUM, max(b.bin) as bin
      from mp_layer as a 
      left outer join bins as b 
      on (a.demand_metric >= b.val) 
      group by a.NUM" , "mp_layer")
  #st_write(entity_classes, paste0(export_path,"37_entity_classes_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  
  mp_layer <- sqldf_sf( #joining the bins with the metric data 
      "select a.*, b.bin 
      from mp_layer as a 
      left outer join entity_classes as b 
      on a.NUM = b.NUM " , "mp_layer")

  mp_layer$bin[is.na(mp_layer$bin)] <- "X" # replacing NA values in bin column
  names(mp_layer)[names(mp_layer) == 'demand_metric'] <- facils_file_map_bubble_column[i] #change column name back to the specific metric
  mp_layer <- mp_layer[, !duplicated(colnames(mp_layer))] #remove duplicated columns
  mp_layer <- fn_centroid_coords(mp_layer)
  #st_write(mp_layer, paste0(export_path,"38_mp_layer_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  
  rsegs <- fn_centroid_coords(rsegs)
  #st_write(rsegs, paste0(export_path,"39_rsegs_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  
    title1 <- paste0(facils_file_map_bubble_column[i]) #define title here for mapping so each map has diff metric title, pass into function
  
  if (facils_file_map_bubble_column[i]=="fiveyr_avg_mgy"){
      title <- gsub("fiveyr_avg_mgy", "5 Year Avg (MGY)", title1)
  } else if (facils_file_map_bubble_column[i]=="wd_mgd"){
          title <- gsub("wd_mgd", "Withdraw (MGD)", title1)
  } else if (facils_file_map_bubble_column[i]=="gw_demand_mgd"){
  title <- gsub("gw_demand_mgd", 'Ground Water Demand (MGD)', title1)
  } else if (facils_file_map_bubble_column[i]=="ps_mgd"){
  title <- gsub("ps_mgd", "Point Source (MGD)", title1)
  } else {
    title <- title1
  }
  
   # "runid_11_wd_mgd","runid_13_wd_mgd","fiveyr_avg_mgy","wsp2020_2040_mgy" 
    
##Mapping function
  source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_mapgen2.R"),local = TRUE) #load mapping function

  # args/params have been kept separate during dev. so far, but will be consolidated & some removed once we're happy with maps 
  suppressWarnings(suppressMessages( 
    fn_mapgen2(mapnum = 1, type, map_type, styles[[map_style]], metric = facils_file_map_bubble_column[i], rivseg, bbox, rsegs, counties, roads, 
          nhd, maplabs, locality, region, mp_layer, metric_unit, title=title) ))
  
  #assign map to environment
  assign(paste0('map', i), map, envir = globalenv())
  }

## Mapping Errors:
  # Error in if (distance > 300) { : missing value where TRUE/FALSE needed
  # Solution: this indicates the bbox is not in the format needed by the function. Regenerate the bbox and make sure it is of class bbox and has names xmin, xmax, etc.

  # Error in rbind(deparse.level, ...) : numbers of columns of arguments do not match
  # Solution: maplabs object needs to be re-generated

# Save map as png
#name maps based on map type
if (map_type == "basin") {
  map_name <- rivseg
} else if (map_type == "locality") {
  map_name <- locality
} else if (map_type == "region") {
  map_name <- region
}
#add sources or facils to name based on type 
if (type == "source") {
  map_name <- paste0(map_name, '_sources')
} else if (type == "facility") {
  map_name <- paste0(map_name, '_facils')
}

# Saving map(s) as a png
# export_path set in config for analysts, set in console if nonexistent to location where map will be exported 
mapfilename <- character() #empty character var, not a list
for (i in 1:length(facils_file_map_bubble_column)) {
  mapfilename[i] <- paste(export_path, map_name, "_", facils_file_map_bubble_column[i], ".png", sep="")
  mapf <- get(paste0('map',i))
  ggsave(
    filename = mapfilename[i],
    plot = mapf,
    width = 25,
    height = 20)
 }
```
```{r Viewing Map(s) 1, echo=FALSE, out.width = '100%', out.height='100%', message=TRUE}
knitr::include_graphics(mapfilename) #display map PNG - for maps on top of each other
if (mapMessage == TRUE) {
  message("The metric requested does not exist for this map.")
  message("Check your syntax/spelling. If correct, then this data has not been measured/modeled")
}
```
```{r Continued..(table1), echo=FALSE, message=FALSE, warning=FALSE}
#create dataframe for human readable metric names- add here any new metric names being used and their readable version
  read_metric_name <- c('runid_0', 'runid_1','runid_3','runid_11','runid_12','runid_13','runid_14','runid_15','runid_16','runid_17','runid_18','runid_19','runid_20','runid_21','runid_22', 'fiveyr_avg_mgy', "wd_mgd", "gw_demand_mgd", "ps_mgd", "wsp2020_2040_mgy")
  new_metric_name <- c('Pre-Condition', 'Historical Condition', 'Permit Term Max', '2020 Demand Scenario', '2030 Demand Scenario', '2040 Demand Scenario', 'Median Climate Change Scenario (50/50)- 2020 Demand',
                    'Dry Climate Change Scenario (10/10) - 2020 Demand', 'Wet Climate Change Scenario (90/90) - 2020 Demand ', 'Dry Climate Change Scenario (10/20) - 2040 Demand ', '2020 Exempt User Runs', 'Median Climate Change Scenario (50/50)- 2040 Demand',  
                    'Wet Climate Change Scenario (90/90) - 2040 Demand', '2015 Demand 2010', '2015 Demand 2040', 'Five Year Avg Use(MGY)', 'Withdraws(MGD)', 'Ground Water Demand (MGD)', "Point Source (MGD)", "Water Supply Plan 2020-2040 MGY")
  metric_names <- data.frame(read_metric_name, new_metric_name)

names(facils)[names(facils) == 'propname'] <- 'Facility' #if propname column exists rename to Facility
#facils$within$hydroid <- as.numeric(gsub(",", "", facils$within$hydroid, fixed = TRUE))
#create initial table
table <- data.frame(
  Number= facils$NUM,
  Facility=facils$Facility,
  HydroID = facils$Facility_hydroid)

#for source type only add mp name and source type to table
if (type=="source"){
  table$Source = facils$MP_Name  
  table$Source_Type = facils$Source_Type
}

table$Locality = facils$Locality
#write.csv(table, paste0(export_path,"40_table.csv"))

#add rivseg names
for(i in 1:nrow(table)){ 
  loc_rivseg <- (rsegs[grep(facils$riverseg[i], rsegs$riverseg),]) #find rivseg in segs and compare to facils to add name
  if (nrow(loc_rivseg) != 0) {
    table$`River Segment Name`[i] <- loc_rivseg$name
  } else { # if no matching row was found for the riverseg ID, leave blank but don't break
    table$`River Segment Name`[i] <- ""
    }
}
#write.csv(table, paste0(export_path,"41_table.csv"))


table$`River Segment ID`= facils$riverseg #add rivseg ID

table$`Permitted Capacity` <- facils$vwp_max_mgy #add permitted capacity to table 
#write.csv(table, paste0(export_path,"42_table.csv"))


for (i in 1:length(facils_file_table_column)){
  #metric col of interest may not exist if none were found in extent: don't break if this is the case
  if (facils_file_table_column[i] %in% colnames(facils)) {
  #adding requested columns to table
    # table[,table_col[i]] <- round( st_drop_geometry(facils[,table_col[i]]), digits = 2) #round all values to 2 decimal place digits
    tmp_df <- st_drop_geometry(facils[,facils_file_table_column[i]])
    tmp_df <- as.data.frame(lapply(tmp_df,as.numeric))
    table[,facils_file_table_column[i]] <- round(tmp_df, digits = 2)
  }
}

table <- table[,colSums(is.na(table))<nrow(table)] #remove columns with all NAs, added to df for mapping as placeholders 
#write.csv(table, paste0(export_path,"43_table.csv"))


#compare requested table columns with those that actually exist 
novals <- data.frame(metric=character())
for (i in 1:length(facils_file_table_column)) {
  if (!facils_file_table_column[i] %in% names(table)) {
    novals[i,] <- facils_file_table_column[i]
  }
}
#for returning message if metric table columns were missing 
if (nrow(novals > 0)) {
  tableMessage <- TRUE
} else { tableMessage <- FALSE }

# Rename columns & create flextable
#names(table)[names(table) == 'Source_Type'] <- 'Source Type'

for (i in 1:length(facils_file_table_column)) {
  for (x in 1:nrow(metric_names)){
    if (facils_file_table_column[i]==metric_names$read_metric_name[x])
    {
      names(table)[names(table)==facils_file_table_column[i]] <- metric_names$new_metric_name[x]
    }
    else
    {
      next
    }
  }
}

#names(table)[names(table) == 'fiveyr_avg_mgy'] <- '5-yr Avg Use (mgy)'
names(table) <- mgsub(names(table), pattern="_", replacement=" ") #formatting for flextable headers, line breaks happen at spaces not underscores
#write.csv(table, paste0(export_path,"44_table.csv"))

ft1 <- fn_tablegen(type = "facility", table = table, columns = "all", alignment = "left", map_type,metric = rivseg_metric[i], rivseg, title=title ) #Execute flextable function, which saves the flextable as variable 'ft' for displaying later


```

## Table 1:
```{r Viewing Table 1, echo=FALSE, out.width='100%', message=TRUE}
if (tableMessage == TRUE) {
  message("Missing column indicates the metric requested does not exist for this table")
}
ft1 #display flextable
```

## Rseg Map(s):
```{r Continued..(map2), echo=FALSE, message=FALSE, warning=FALSE}
#----Map/Table2----
## Need to adapt this for multiple maps
#rivdiv <- c(-20,-10,-2,2,10,20,500) #% difference breaks for rivseg map - moved to config

for (i in 1:length(rivseg_metric)){
  rseg_leg_title <- legend_titling(rivseg_metric[i], runid_list)
  
  title1 <- paste0(rivseg_metric[i]) #define title here for mapping so each map has diff metric title, pass into function
  
  if (rivseg_metric[i]=="l30_Qout"){
      title <- gsub("l30_Qout", "Lowest 30 Day Flow", title1)
  } else if (rivseg_metric[i]=="l90_Qout"){
          title <- gsub("l90_Qout", "Lowest 90 Day Flow", title1)
  } else if (rivseg_metric[i]=="7q10"){
      title <- gsub("7q10", "Lowest 7 Day Flow", title1)
  } else {
    title <- title1
  }

  rsegs <- rsegs[ , !names(rsegs) %in% c("pct_diff", "bin")]
  #st_write(rsegs, paste0(export_path,"45_rsegs_sf_",rseg_leg_title,".csv"), layer_options = "GEOMETRY=AS_WKT")
  
  rseg_sql <- paste('SELECT *, ','percentDiff','_',rivseg_metric[i],' AS pct_diff
        FROM rsegs' , sep="") #Renaming metric of interest for generalized sorting into bins
  
  rsegs <- sqldf_sf(rseg_sql,"rsegs")
  #st_write(rsegs, paste0(export_path,"46_rsegs_sf_",rseg_leg_title,".csv"), layer_options = "GEOMETRY=AS_WKT")

  bins = as.data.frame(rivseg_pct_vect) #rivseg_pct_vect set in config
  bins$classid <- index(bins)
  names(bins) <- c("val", "bin")
  #write.csv(bins, paste0(export_path,"47_bins_",rseg_leg_title,".csv"))

  rivseg_classes <- sqldf_sf( #sorting the data into bins based on their range 
    "select a.riverseg, min(b.bin) as bin
    from rsegs as a 
    left outer join bins as b 
    on (a.pct_diff <= b.val) 
    group by a.riverseg" )
  #write.csv(rivseg_classes, paste0(export_path,"48_rivseg_classes_",rseg_leg_title,".csv"))

  rsegs <- sqldf_sf( #joining the bins with the metric data 
    "select a.*, b.bin 
    from rsegs as a 
    left outer join rivseg_classes as b 
    on a.riverseg = b.riverseg " , "rsegs")
  # st_write(rsegs, paste0(export_path,"49_rsegs_sf_",rseg_leg_title,".csv"), layer_options = "GEOMETRY=AS_WKT")
  

  ##Mapping function
  suppressWarnings(suppressMessages(
    fn_mapgen2(mapnum = 2,type, map_type, styles[[map_style]], metric = rivseg_metric[i], rivseg, bbox, rsegs, counties, roads, 
          nhd, maplabs, locality, region, mp_layer, metric_unit, title=title) ))
  
  #assign map to environment
  assign(paste0('map_rivseg', i), map, envir = globalenv())

}

## Save rivseg map
rivmapfilename <- character() #empty character var, not a list
for (i in 1:length(rivseg_metric)) {
  rivmapfilename[i] <- paste(export_path, map_name, "_", rivseg_metric[i], ".png", sep="")
  mapf <- get(paste0('map_rivseg',i))
  ggsave(
    filename = rivmapfilename[i],
    plot = mapf,
    width = 25,
    height = 20)
}
```
```{r Displaying Rivseg Map, out.width = '100%', out.height='100%', echo=FALSE}
knitr::include_graphics(rivmapfilename)
```
```{r Continued..(table2), echo=FALSE, message=FALSE, warning=FALSE}
#create metric type column

  
rivTables <- list() #to store dataframes for each drought metric
#ftable<- list()
for (k in 1:length(rivseg_metric)){ #loop thru metrics
  rivTables[[k]] <- data.frame(Name = rsegs$name) # add rivseg name
  rivTables[[k]][,paste0('Riverseg')] <- rsegs$riverseg # add rivseg number
  rivTables[[k]]$Metric <- rivseg_metric[k] #add metric
  #write.csv(rivTables[[k]], paste0(export_path,"50_rivTables_",rivseg_metric[k],".csv"))

   for (i in 1:nrow(rsegs)) {
        for (j in 1:length(runid_list)){ #add actual metric column data
          # rivTables[[k]][i,paste0(runid_list_riversegs[j])] = round(st_drop_geometry( rsegs[i,paste0(runid_list_riversegs[j],'_',rivseg_metric[k])] ), digits= 2)
          tmp_df <- st_drop_geometry(rsegs[i,paste0(runid_list[j],'_',rivseg_metric[k])])
          tmp_df <- as.data.frame(lapply(tmp_df,as.numeric))
          #rivTables[[k]][i,paste0(runid_list[j])] <- round(tmp_df, digits = 2)
          
          for (x in 1:nrow(metric_names)){
          if (runid_list[j]==metric_names$read_metric_name[x])
          {
            rivTables[[k]][i,paste0(metric_names$new_metric_name[x])] <- round(tmp_df, digits = 2)
            #names(rivTables[[k]])[names(rivTables[[k]]) == runid_list[j]] <- metric_names$new_metric_name[row]
            #names(rivTables[[k]]) <- mgsub(names(rivTables[[k]]), pattern= runid_list[j], replacement= metric_names$new_metric_name[x])
          }
          else
          {
            next
          }
        }
        }
   }
  #names(table)[names(table) == 'fiveyr_avg_mgy'] <- '5-yr Avg Use (mgy)'
#names(table) <- mgsub(names(table), pattern="_", replacement=" ")

  #write.csv(rivTables[[k]], paste0(export_path,"51_rivTables_",rivseg_metric[k],".csv"))
  #format table columns, add percent difference 
 # rivTables[[k]][,paste0('Difference')] = round( st_drop_geometry(rsegs[,paste0('diff','_',rivseg_metric[k])]) ,digits= 2)
  # rivTables[[k]][,paste0('pct_diff')]= round( st_drop_geometry(rsegs[,paste0('percentDiff','_',rivseg_metric[k])]) , digits= 2)
  tmp_df <- st_drop_geometry(rsegs[,paste0('percentDiff','_',rivseg_metric[k])])
  tmp_df <- as.data.frame(lapply(tmp_df,as.numeric))
  rivTables[[k]][,paste0('pct_diff')] <- round(tmp_df, digits = 2)
  
  
  #write.csv(rivTables[[k]], paste0(export_path,"52_rivTables_",rivseg_metric[k],".csv"))
  
  #order by lowest % difference from rivTables[[k]]
  rivdf <- rivTables[[k]] # for sqldf
  rivdf <- sqldf( "SELECT rivdf.*  
              FROM rivdf 
              ORDER BY pct_diff ASC") #ordering by the metric of interest, descending 
  
  names(rivdf)[names(rivdf) == 'pct_diff'] <- '% Difference'
  #write.csv(rivdf, paste0(export_path,"53_rivdf_",rivseg_metric[k],".csv"))
  
  #need to put NA values @ bottom of df
  nanum <- sum(is.na(rivdf$`% Difference`))
  narows <- head(rivdf, nanum)
  goodrows <- rivdf[(nanum+1):nrow(rivdf), ]
  rivdf <- rbind(goodrows, narows)
  #write.csv(rivdf, paste0(export_path,"54_rivdf_",rivseg_metric[k],".csv"))
  
  nacols <- data.frame(colSums(is.na(rivdf)) == nrow(rivdf)) #dataframe of which columns are all na or not
  for (i in 1:nrow(nacols)) {
    if (nacols$colSums.is.na.rivdf......nrow.rivdf.[i] == TRUE){ #if any column is all na, then return true
      tablemessage2 = TRUE
    }
    else { #if column is not all na, then return false
      tablemessage2 = FALSE
    }
  }
  
  
  title1 <- paste0(rivseg_metric[k]) #define title here for mapping so each map has diff metric title, pass into function
  
  if (rivseg_metric[k]=="l30_Qout"){
      title <- gsub("l30_Qout", "Lowest 30 Day Flow", title1)
  } else if (rivseg_metric[k]=="l90_Qout"){
          title <- gsub("l90_Qout", "Lowest 90 Day Flow", title1)
  } else if (rivseg_metric[k]=="7q10"){
      title <- gsub("7q10", "Lowest 7 Day Flow", title1)
  } else {
    title <- title1
  }
  
  
  ft2 <- fn_tablegen(type = "riverseg", table = rivdf, columns = "all", alignment = "left", map_type,  metric = rivseg_metric[k], rivseg, title=title) #Flextable function
  assign(paste0('table', k), ft2, envir = globalenv())
  print(get(paste0('table', k))) #doesn't work to display flextables in loop on rendering 
}
```

## Rseg Table(s):
```{r Viewing Rivseg Flextable, out.width = '100%', out.height='100%', results='asis', echo=FALSE}
#result = 'asis' necessary 
if (tablemessage2==TRUE) {
  message("A column in the table is completely NA values, 
          likely meaning the metric requested is not modeled for this data
          or the segments are all tidal")
}
for (k in 1:length(rivseg_metric)){
  cat(knitr::knit_print(get(paste0('table', k))))
}
#note: doesn't display readable flextable within Rstudio but does upon render
```
