---
title: "Mapping Workflow"
author: "HARP Analysts"
date: "`r Sys.Date()`"
geometry: margin=1cm #margins for pdf
output: pdf_document #overridden by output_format in render command 

#Here is the main editable part of the rmd, planners should adjust parameters as they see fit for their goals, see README documentation for more details on each parameter
#Can edit here or in a render command 
## More params used during development and testing for user-control -- will be consolidated  
params: 
#rivseg, locality, region based on desired location for planner, ensure syntax is correct
  rivseg: ["JU4_7330_7000"] #test rivsegs ["JL6_7320_7150","JL6_6890_6990","JL6_7430_7320","JA2_7410_7470", "JA4_7280_7340","JB3_6820_7053"] 
  locality: ["NA"]
  region: ["NA"]    

#determining which type/level of map is being created
  type: ["facility"] #either 'source' or 'facility'
  map_type: ["basin"] #should be one of: basin, locality, or region 

#determining map aesthetics like colors, fonts, font sizes
  map_style: ["custom"]
  
#determining what metric(s) will be pulled and mapped
  model_version: ["vahydro-1.0"] #which model metric to be pulled from vahydro
  runid_list_facilities: [ "runid_11", "runid_13" ] #the runids to be pulled & compared in map & table #1
  runid_list_riversegs: [ "runid_11", "runid_13" ] #the runids for riverseg drought metric % difference, map & table #2
  metric_mod: ["wd_mgd"] #for modeled metrics, ex: wd_mgd, ps_mgd, gw_demand_mgd
  metric_feat: ["wsp2020_2040_mgy"] #for non-modeled facility metrics, ex: wd_current_mgy, wsp2020_2020_mgy, wsp2020_2040_mgy 
  #fiveyr_avg_mgy is already part of data and is mappable without calling in either metric_mod or metric_feat
  rivseg_metric: ["l30_Qout", "7q10"] #drought metric to be used in river segment maps, options: 7q10, l30_Qout, l90_Qout
  map_by: ["fiveyr_avg_mgy"] #the metric(s) for mapping, which the bubbles & legend will be scaled to. Ex: runid_11_wd_mgd, fiveyr_avg_mgy
  
#asthetic changes  
  limit: ["basins"] #either 'basins' or 'boundary', depending if all sources/facils in intersecting basins should be in table, or only points within locality/region boundary. Won't apply to map type basin
  table_col: ["runid_11_wd_mgd","runid_13_wd_mgd","fiveyr_avg_mgy","wsp2020_2040_mgy"] ##specific metrics included in flextable
  bbox_type: ["auto"] #either 'auto' or 'vahydro'. vahydro map type only functional for segments 
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#ensure all packages and dependencies are installed prior to running 
library(data.table)
library(hydrotools)
library(mgsub)
library(sp)
library(sf)
library(nhdplusTools)
library(png)
library(flextable)
library(pandoc)
#tinytex::install_tinytex() #need to run if you don't have tinytex
library(tinytex)

#gather config info to log into vahydro  
basepath='/var/www/R'
source('/var/www/R/config.R')
ds <- RomDataSource$new(site, rest_uname)
ds$get_token(rest_pw)
```

```{r UserInputs, echo=FALSE}
# reading in the user inputs from params
for(i in 1:length(params)){
  assign(names(params[i]), params[[i]])
}
```
# CLEANUP Version
## Establish and Call Functions (Cleanup)
```{r Establish Developer Functions, echo=FALSE, warning=FALSE}
# For planners, updated when changes are merged to master
# Make sure github location in config file is properly set 
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_download_read.R"),local = TRUE)
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_process_geom.R"),local = TRUE) 
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_centroid_coords.R"),local = TRUE)

source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_mapgen_est.R"),local = TRUE) #load mapping function
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/mapstyle_config.R"),local = TRUE) #load mapping aesthetics
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/rivsegmaps_config.R"),local = TRUE) #load rivseg-specific mapping aesthetics
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_tablegen.R"),local = TRUE) #load table function
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_labelprep.R"),local = TRUE) #load labeling function
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_nhd_labs.R"),local = TRUE) #load nhd label function

# returns the name of the geometry column in the data:
geoCol <- function(data){
  colname <- grep("geo",colnames(data),value=TRUE)
  if(length(colname) > 1){
  colname <- grep("geom",colname,value=TRUE) #for the case of "dh_geofield.geom" "dh_geofield.geo_type" "dh_geofield.lat" "dh_geofield.lon", etc.
  }
  return(colname)
}

# allows the usage of SQLDF with sf data frames:
sqldf_sf <- function(statemt, geomback="NA"){
  #statement is any SQLDF string; reference the data frames per usual
  #geomback is the character name of the data.frame you are filtering, where, if applicable, the sf geometry column will need to be added back from
  dfs <- as.environment(as.list(.GlobalEnv, all.names=TRUE)) #make a copy of the global environment
  for(i in names(dfs)){
    if(class(dfs[[i]])=="sf"){ #drop the geometry on any sf objects so they can go through SQLDF
      dfs[[i]] <- sf::st_drop_geometry( dfs[[i]] )
    }
  }
  dfs[["result"]] <- sqldf(statemt, envir=dfs) #SQLDF the non-sf dataframes in the new environment (so that the global envir. retains the sf objects)
  if(geomback!="NA"){
    output <- merge(x=dfs[["result"]], y=.GlobalEnv[[geomback]], all.x=TRUE, all.y=FALSE) #match the newly filtered obs. to their geometries
    output <- st_as_sf(output, crs=4326) #convert back to sf
  } else {
    output <- dfs[["result"]]
  }
}

# legend_titling() --> Generate user-understandable legend titles
## Kept up here as a function so that it's easy to add if-statements when user-input options expand
legend_titling <- function(metric, runid_list){
  
  if (metric=="wd_mgd"){ #titles for wd_mgd
    name <- "Withdrawal"
    unit <- "(MGD)"
    legend_title <- runid_list
    year <- mgsub(runid_list, c("runid_11","runid_13"), c("2020","2040"))
    for (i in 1:length(runid_list)){
      legend_title[i] <- paste(year[i],name,unit,sep="\n")
    }
  } else if (metric=="fiveyr_avg_mgy"){ #this metric isn't associated w a runid
    name <- "5-yr Avg Use"
    unit <- "(MGY)"
    legend_title<- paste(name,unit,sep="\n")
  } else {
    legend_title<- paste(metric)
  }
  return(legend_title)
}

```

## Pull Data (Cleanup)
```{r Pull Data, echo=FALSE, message=FALSE, warning=FALSE}
#----Facility Data----
facils <- list() #create empty list to store dfs
# note: the variable "github_location" should be in config.local and provides easy access to these resources

# foundational MP(measuring pt)/sources data:
facils$foundatn_mp <- fread(paste0(github_location, "/Foundational_Data/2023/foundation_dataset_mgy_2018-2022_5ya.csv"))
write.csv(facils$foundatn_mp, paste0(export_path,"00_foundatn_mp.csv"))

if (type=="facility") { 
  #specified model metrics will be pulled @ the facility-level for every specified runid using om_vahydro_metric_grid()
  #create df of model run specifications for om_vahydro_metric_grid():
  df <- data.frame(runid=runid_list_facilities, model_version, metric=metric_mod) 
  write.csv(df, paste0(export_path,"01_df.csv"))
  #add column to df containing 'runlabel' which will become the metric column names in facils$model:
  for(i in 1:length(runid_list_facilities)){ 
    df$runlabel[i] <- paste0(runid_list_facilities[i], '_', metric_mod)
  }
  write.csv(df, paste0(export_path,"02_df.csv"))
  
  #pull facilities w/ metric of interest from vahydro:
  facils$model <- om_vahydro_metric_grid(
    metric=FALSE, runids=df, featureid='all', 
    entity_type='dh_feature', bundle='facility',
    ftype='all', model_version=model_version,
    base_url=paste(site,"/entity-model-prop-level-export",sep=''), #http://deq1.bse.vt.edu/d.dh
    ds=ds
    )
  write.csv(facils$model, paste0(export_path,"03_model.csv"))
  #pull facility-level geometry to join with model data:
  facils$fac_geo <- fread(paste0(github_location, "/Foundational_Data/2023/facilities_all_geom.csv"))
  write.csv(facils$fac_geo, paste0(export_path,"04_fac_geo.csv"))
} 
#----Watershed/Riverseg Data----
#rsegs <- ds$get('dh_feature', config=list(ftype='vahydro',bundle='watershed')) ## VAhydro gives errors
if(!exists("rsegs")){
  rsegs <- fn_download_read(url=paste(site,"/vahydro_riversegs_export",sep=""), filetype="csv", zip=FALSE) 
  # pulls csv with All vahydro watershed features
  # note: potential NULLs for newly carved data^
}
write.csv(rsegs, paste0(export_path,"05_rsegs.csv"))
#----County Data----
counties <- list()
counties$fips <- ds$get('dh_feature', config=list(bundle='usafips')) #pull all counties from VAhydro
counties$regions <- fread('https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/Regions_ProposedReg_053122.csv') #csv connects county names to their planning regions
write.csv(counties$fips, paste0(export_path,"06_fips.csv"))
write.csv(counties$regions, paste0(export_path,"07_regions.csv"))

#----Cities & Roads----
roads <- fn_download_read(
  url="https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/tl_2022_51_prisecroads.zip", 
  filetype="shp", zip=TRUE) # (shp) for US states & primary roads
st_write(roads, paste0(export_path,"08_roads_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

cities <- fread('https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/USA_Major_Cities_GIS.csv')
write.csv(cities, paste0(export_path,"09_cities.csv"))
```

## Filter/Process Data (Cleanup)
```{r Processing Counties & Regions, echo=FALSE, message=FALSE, warning=FALSE}
#----Counties----
counties$fips$name <- sub(" County", "", counties$fips$name) # fix any names followed by " County" to match the names in counties$regions
counties$fips <- with(counties, sqldf("SELECT a.*, b.VMDWA_Reg2 as Region
                                      FROM fips as a
                                      LEFT OUTER JOIN regions as b
                                      WHERE (a.name = b.County)
                                      ")) #add region column to county data; WHERE instead of ON means only counties in regional planning areas are kept
write.csv(counties$fips, paste0(export_path,"10_fips.csv"))

#remove counties outside of VA using the fips code; save over as "counties" to simplify data handling:
counties <- counties$fips[grep(51,counties$fips$dh_fips),]
counties <- st_as_sf(counties, wkt = geoCol(counties), crs=4326) #convert to sf based on geometry column found by geoCol() (developer-defined fn above)
# write.csv(counties, paste0(export_path,"11_counties.csv"))
st_write(counties, paste0(export_path,"11_counties_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

#----Regions----
regions_split <- split(counties, counties$Region) #creates a list containing a sf data frame per each region, which all contain the county polygons corresponding to that region
for(i in 1:length(regions_split)){ #merge counties into one polygon for each region
  if(i==1){
    regions <- st_union(regions_split[[i]])
  }
  if(i!=1){
    regions <- rbind( regions, st_union(regions_split[[i]]) )
  } #note: had to do this in IF statements instead of resetting regions_split[i] <- regions_split[[i]] because keeping it in list form causes st_union() to put geom into sfg format, which causes problems with st_filter() in the rsegs filtering chunk
}
regions <- st_as_sf(data.frame(region=names(regions_split),geo=regions,row.names=NULL), crs=4326)
# write.csv(regions, paste0(export_path,"12_regions.csv"))
st_write(regions, paste0(export_path,"12_regions_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
rm(regions_split)
```

```{r Merging Facility Data, echo=FALSE, message=FALSE, warning=FALSE}
if(type == "source"){
  facils <- with(facils, 
                 foundatn_mp[foundatn_mp$Latitude!="" & foundatn_mp$Longitude!="" 
                   & !is.na(foundatn_mp$Latitude) & !is.na(foundatn_mp$Longitude) ,] #omits facilities with blank or NA geometry
                 )
  facils <- st_as_sf(facils, coords=c("Longitude","Latitude"), crs=4326) #convert to sf
}
if(type == "facility"){
  #get facility-level fiveyr_avg_mgy from foundatn_mp by summing all mp values for each facility:
  facils$foundatn <- with(facils, sqldf("select foundatn_mp.*,
                    sum(fiveyr_avg_mgy) as sum
                    from foundatn_mp
                    group by Facility_hydroid")) #all source-related data now only applies to 1 source (random) within the facil 
  write.csv(facils$foundatn, paste0(export_path,"13_foundatn.csv"))
  
  #filter out WSP entries from facility-level metric data:
  facils$model <- with(facils, sqldf("SELECT * 
                                      FROM model 
                                      WHERE hydrocode not like 'wsp_%'"))
  write.csv(facils$model, paste0(export_path,"14_model.csv"))
  
  #merge/full join foundational & modeled facil data:
  facils$merge <- with(facils,merge(x=model, 
                                    y=foundatn[names(foundatn)!="Hydrocode"], #all but the Hydrocode column bc it's a duplicate. Needed for SQLDF
                                    by.x="featureid", by.y="Facility_hydroid", all=T)) 
  write.csv(facils$merge, paste0(export_path,"15_merge.csv"))
  
  #join facility geometry to merged data frame:
  statemt <- paste("SELECT 
                      a.Facility, a.featureid as Facility_hydroid, a.'Use Type', a.Locality, 
                      a.sum as fiveyr_avg_mgy, a.",df$runlabel[1],", a.",df$runlabel[2],",
                      b.",geoCol(facils$fac_geo), #robust for varying geometry column names
                      " FROM merge as a
                      LEFT OUTER JOIN fac_geo as b
                      ON (a.featureid = b.Facility_hydroid)", sep="")
  facils <- with(facils, sqldf(statemt)) #selects/renames desired columns from facils$merge, matches them with geometry from facils$fac_geo based on featureid ; saves over facils to simplify data access/storage
  facils <- facils[facils[,geoCol(facils)]!="" & !is.na(facils[,geoCol(facils)]),] #omits facilities with blank or NA geometry
  facils <- st_as_sf(facils, wkt = geoCol(facils), crs=4326) #convert to sf
  st_write(facils, paste0(export_path,"16_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
}
#connect facilities to the watersheds they are in:
rsegs$riverseg <- gsub(pattern="vahydrosw_wshed_", replacement="", rsegs$hydrocode) #prereq. for fn_extract_basin() & desired for facils/table riverseg column
rsegs <- rsegs[ rsegs[,geoCol(rsegs)]!="" & !is.na(rsegs[,geoCol(rsegs)]) ,] #finds geom column & omits rsegs with blank or NA geometry
rsegs <- st_as_sf(rsegs, wkt=geoCol(rsegs), crs=4326) #convert to sf
st_write(rsegs, paste0(export_path,"17_rsegs_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

sf_use_s2(FALSE) # switch off Spherical geometry ; some functions (eg. st_join, st_filter) give errors without this
facils <- st_join(facils, rsegs[ ,c("riverseg","hydroid",geoCol(rsegs)) ]) #pairs riverseg column from rsegs w/ facils based on geometry
st_write(facils, paste0(export_path,"18_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

#we add an riverseg column via goemetry in both source & facility cases b/c even when facilities come in with a riverseg column, many are blank
```

```{r Filter by Boundary Type, echo=FALSE, message=FALSE, warning=FALSE}
#----Rsegs----
if (map_type=="basin") { #finding upstream riversegs for basin maps 
  for(i in rivseg){
    if(i==rivseg[1]){
    basin <- fn_extract_basin(st_drop_geometry(rsegs), i) #fn_extract_basin runs sqldf which can't handle sf geometry
    }
    if(i!=rivseg[1]){
    basin <- rbind(basin, fn_extract_basin(st_drop_geometry(rsegs), i))
    }
  }
  write.csv(basin, paste0(export_path,"19_basin.csv"))
  
  rsegs <- st_as_sf( merge(x=basin,y=rsegs), crs=4326) #add the geometries back on
  rsegs <- unique(rsegs) #don't duplicate riversegs for overlapping basins
  st_write(rsegs, paste0(export_path,"20_rsegs_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  
  rm(basin)
} else if (map_type=="locality") { #for locality level
  rsegs <- st_filter(rsegs, counties[counties$name==locality, ]) #filter basins by locality (if REST is working)
} else if (map_type=="region") { #for region level
  region_OI <- regions[regions$region==region,] #extract region of interest for darker border around region 
  region_sp <- as_Spatial(region_OI, cast=FALSE)
  rsegs <- st_filter(rsegs, region_OI) #filter basins by the region given in params
}
#----Sources/Facils----
#Filtering data to only points within the extent of interest, either locality/region boundary or the basins/riversegs intersecting the extent
if (limit=="basins" | map_type=="basin") {
  facils <- st_filter(facils, rsegs)
  st_write(facils, paste0(export_path,"21_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
} else if (limit=="boundary"){
  if(map_type=="locality"){
    facils <- st_filter(facils, counties[counties$name==locality, ])
  } else if (map_type=="region") {
    facils <- st_filter(facils, region_OI)
  }
}
```

```{r Filter Cities & Roads, echo=FALSE, message=FALSE, warning=FALSE}
#----Cities----
statemt <- paste("SELECT cities.X, cities.Y, cities.NAME, cities.POPULATION,",
                 "CASE WHEN POPULATION BETWEEN",quantile(cities$POPULATION, 0.1),"AND", quantile(cities$POPULATION, 0.5),
                    "THEN 'smallTown' 
                  WHEN POPULATION BETWEEN",quantile(cities$POPULATION, 0.5),"AND",quantile(cities$POPULATION, 0.8),
                    "THEN 'town'
                  WHEN POPULATION BETWEEN",quantile(cities$POPULATION, 0.8),"AND",quantile(cities$POPULATION, 1.0),
                    "THEN 'city'
                  ELSE CLASS", #keeping value from original class column
                  "END as CLASS", #new class column being written
                  "FROM cities
                  WHERE NAME 
                  NOT IN (select counties.name from counties)", #remove city/town names that match their county/locality name
                  "AND (cities.ST == 'VA') ", #keep VA cities only
                 "ORDER BY POPULATION DESC", sep=" ") 
cities <- sqldf_sf(statemt)
write.csv(cities, paste0(export_path,"22_cities.csv"))

#----Roads----
roads <- subset(roads, MTFCC=="S1100" & (RTTYP=="I"|RTTYP=="U"|RTTYP=="S") #primary roads & interstate, US Hwy, or State Rte only
                & FULLNAME %in% grep("([0-9]+).$", roads$FULLNAME, value=TRUE)) #finds where last char is a number -> Omits names followed by Byp, Alt, etc.
roads$FULLNAME <- gsub(".* ", "", roads$FULLNAME) #removes text and spaces before route number
names(roads) <- gsub("RTTYP", "CLASS", names(roads)) #re-name class column -> needed for fn_labelprep()
st_write(roads, paste0(export_path,"23_roads_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
```

## Additional Pulling Post-Filtering (Cleanup)
```{r Pull Feature Metrics & Permitted Capacity, echo=FALSE, message=FALSE, warning=FALSE}
#----User-Input Non-Modeled Feature Metrics----
for (i in 1:nrow(facils)) {
  facils[i,metric_feat] <- RomProperty$new(ds,list(
                                featureid = facils$Facility_hydroid[i],
                                propname = metric_feat),
                              TRUE)$propvalue #pull feature & directly assign metric propvalue to facility i
}
st_write(facils, paste0(export_path,"24_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

#----Permitted Capacity----
fac_model_data <- data.frame()
for (i in unique(facils$hydroid) ){
  #i is a rseg hydroid corresponding to each facility, but it won't pull for the same hydroid twice b/c that is redundant and time-consuming
  model_props <- c("vwp_max_mgy","permit_status")
  fac_model_data <- rbind( fac_model_data , read.csv(paste(site,"/model-summary-users-export-all-cols/",
                                                gsub(" ","",toString( i )),"/",
                                                runid_list_facilities[1],"/", #perm.cap doesn't change w/ runid ?
                                                gsub(" ","",toString( metric_mod )),"/", #user's model run metric
                                                gsub(" ","",toString( model_props )),sep="")
                                                ))
}
write.csv(fac_model_data, paste0(export_path,"25_fac_model_data.csv"))

#statemt <- paste("SELECT a.*, b.permit_status, c.vwp_max_mgy
#                  FROM facils as a
#                  LEFT OUTER JOIN (
#                    SELECT facility_hydroid, model_prop_propcode as permit_status
#                    FROM fac_model_data
#                    WHERE (model_prop_propname == 'permit_status')
#                    ) as b
#                  ON (a.Facility_hydroid = b.facility_hydroid)
#                  LEFT OUTER JOIN (
#                    SELECT facility_hydroid, model_prop_propcode as vwp_max_mgy
#                    FROM fac_model_data
#                    WHERE (model_prop_propname == 'vwp_max_mgy')
#                    ) as c
#                  ON (a.Facility_hydroid = c.facility_hydroid)
#                 ")
#test <- sqldf_sf(statemt, geomback="facils")
#test <- unique(test) #remove duplicated rows 

statemt <- paste("SELECT a.*, z.vwp_max_mgy, z.permit_status
                  FROM facils as a
                  LEFT OUTER JOIN 
              (   SELECT c.facility_hydroid, b.permit_status,
                  CASE WHEN b.exempts == 'exempt'
                    THEN b.exempts
                  ELSE c.permcaps
                  END as vwp_max_mgy ", #when status is exempt, makes permitted capacity exempt too
                  "FROM
                 ( (SELECT facility_hydroid, model_prop_propcode as permit_status,
                      CASE WHEN model_prop_propcode == 'exempt'
                        THEN 'exempt'
                      ELSE 'switch'
                      END as exempts
                    FROM fac_model_data
                    WHERE (model_prop_propname == 'permit_status')
                    ) as b
                  LEFT OUTER JOIN (
                    SELECT facility_hydroid, model_prop_propcode,
                      CASE WHEN model_prop_propcode IS NULL OR model_prop_propcode == 0
                        THEN 'No Permit' ", #changes null/0 permit capacity to 'No Permit'
                      "ELSE model_prop_propcode
                      END as permcaps
                    FROM fac_model_data
                    WHERE (model_prop_propname == 'vwp_max_mgy')
                    ) as c
                  ON (b.facility_hydroid = c.facility_hydroid)
                 )
              ) as z
              ON (a.Facility_hydroid = z.facility_hydroid)
                 ", sep='')
facils <- sqldf_sf(statemt, geomback="facils")
facils <- unique(facils) #remove duplicated rows 
facils$vwp_max_mgy[is.na(facils$vwp_max_mgy)] <- "No Permit" #replace remaining NA w/ 'No Permit'; !! figure out why exactly NAs still exist
st_write(facils, paste0(export_path,"26_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

rm(fac_model_data)
```

```{r Pull Rseg Drought Metrics, echo=FALSE, message=FALSE, warning=FALSE}
for (k in 1:length(rivseg_metric)) {
  for (j in 1:length(runid_list_riversegs)) {
    for (i in 1:nrow(rsegs)) {
      riverseg <- RomFeature$new(ds,list( #get riverseg feature from vahydro
          hydrocode = paste('vahydrosw_wshed_',rsegs$riverseg[i],sep=''),
          ftype = 'vahydro',
          bundle = 'watershed'
        ),TRUE)
      
      if (!is.na(riverseg$hydroid)) { #only continue if rivseg feature was found
        model <- RomProperty$new(ds,list( #get vahydro-1.0 model feature from vahydro
            featureid = riverseg$hydroid,
            propcode = 'vahydro-1.0'
            ),TRUE)
        
        model_scenario <- RomProperty$new(ds,list( #get scenario/runid from vahydro
            varkey = "om_scenario",
            featureid = model$pid,
            propname = runid_list_riversegs[j]
          ),TRUE)
        
        if (!is.na(model_scenario$pid)) { #only continue if runid was found (scenario pid!=NA)
          rsegs[i, paste0(runid_list_riversegs[j],'_',rivseg_metric[k]) ] <- RomProperty$new(ds,list( #get metric from vahydro
                                                                                featureid = model_scenario$pid,
                                                                                entity_type = 'dh_properties',
                                                                                propname = rivseg_metric[k]
                                                                              ),TRUE)$propvalue #directly assign metric propvalue
        } else { #the scenario/runid wasn't found
          rsegs[i, paste0(runid_list_riversegs[j],'_',rivseg_metric[k]) ] <- NA
        }
      } else { #the rivseg feature wasn't found
        rsegs[i, paste0(runid_list_riversegs[j],'_',rivseg_metric[k]) ] <- NA
      }
    }
  }
}
st_write(rsegs, paste0(export_path,"27_rsegs_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
rm(riverseg)
rm(model)
rm(model_scenario)
```

## Calculations & Map Prep (Cleanup)
```{r Calculate Rseg Metric % Diff, echo=FALSE, message=FALSE, warning=FALSE}
for (k in 1:length(rivseg_metric)){
colname1 <- paste0(runid_list_riversegs[1],'_',rivseg_metric[k])
colname2 <- paste0(runid_list_riversegs[2],'_',rivseg_metric[k])

statemt <- paste("SELECT rsegs.*,
                  CASE WHEN (",colname2," - ",colname1,")==0
                    THEN 0 ", # 0/0 is NA so when difference is 0, %diff is 0
                  "ELSE ( (",colname2," - ",colname1,") / ",colname1," * 100) ", #calculate %diff as usual
                  "END as percentDiff_",rivseg_metric[k], #creates % diff. column
                 " FROM rsegs
                 ",sep="") #!! need a case for when colname1 is zero but colname2 isn't ?
rsegs <- sqldf_sf(statemt, geomback="rsegs")
}
st_write(rsegs, paste0(export_path,"28_rsegs_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
rm(colname1)
rm(colname2)
```

```{r Bbox, echo=FALSE, message=FALSE, warning=FALSE}
if(bbox_type == "vahydro") { #retrieve bbox from vahydro property if desired
#note: only operational for river segments/basins
  for (i in 1:nrow(rsegs)){ #not sure why we're looping through these if we're only saving the last one
    bbox <- ds$get_prop(config=list( #get bbox properties
                        featureid= RomProperty$new(ds,list( #get extent property pid
                                      propname="extent",
                                      entity_type="dh_properties",
                                      featureid= RomProperty$new(ds,list( #get map property pid
                                                    varkey="map", 
                                                    entity_type="dh_feature",
                                                    featureid= rsegs$hydroid[i]
                                                    ),TRUE)$pid #map pid
                                      ),TRUE)$pid, #extent pid
                        entity_type='dh_properties'))
    bbox <- data.frame(X=extent[1:2,4], Y=extent[3:4,4])
    bbox <- st_buffer(st_as_sf(extent_df, coords=c("X","Y"), crs=4326), .05)
    bbox <- st_bbox(bbox)
  }
} else { #auto bbox. should always be around the basins intersecting region of interest
  sf_use_s2(FALSE) # switch off Spherical geometry
  bbox <- st_buffer(st_as_sfc(st_bbox(rsegs)), .02) #slightly past basin
  bbox <- st_bbox(bbox)
}
```

```{r Get NHD in Bbox, echo=FALSE, message=FALSE, warning=FALSE}
# NHD data within the bbox
nhd  <- plot_nhdplus(bbox = bbox, actually_plot = FALSE)
nhdlabs <- fn_nhd_labs(data=nhd)
st_write(nhdlabs, paste0(export_path,"29_nhdlabs_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
```

```{r Filter NHD, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
# Was trying to remove the need for the fn_nhd_labs() since that basically just filters the nhd data now, but ran into some errors...

# First organize flowline data with major rivers/streams
#major rivs = orders 5 & 6; streams = order 4
flow <- nhd$flowline[nhd$flowline$gnis_name!=' ' & #name!=blank & order 4, 5, or 6
                        (nhd$flowline$StreamOrde==6 | nhd$flowline$StreamOrde==5 | nhd$flowline$StreamOrde==4),]
flow <- flow[order(-flow$StreamOrde, flow$gnis_name, -flow$LENGTHKM) & !duplicated(flow$gnis_name),] #no duplicate names; prioritize higher order names and then the longest segment of each duplicate
flow$gnis_name <- mgsub(flow$gnis_name, # shorten long names
                        c('North Fork','South Fork','East Fork','West Fork','Middle Fork'), #pattern
                        c('NF','SF','EF','WF','MF')) #replacement
flow$StreamOrde <- mgsub(flow$StreamOrde, c(4,5,6), c("stream","majorRiver","majorRiver"))
colnames(flow) <- gsub("StreamOrde", "class", colnames(flow))
st_write(flow, paste0(export_path,"30_flow_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

# Now do the same for the water bodies
wtbd <- rbind(nhd$network_wtbd, nhd$off_network_wtbd)
statemt <- paste("SELECT *,
                  CASE WHEN lakevolume BETWEEN",quantile(wtbd$lakevolume, 0.0,T),"AND",quantile(wtbd$lakevolume, 0.5,T),
                    "THEN 'wtbd_sm'
                  WHEN lakevolume BETWEEN",quantile(wtbd$lakevolume, 0.5,T),"AND",quantile(wtbd$lakevolume, 0.75,T),
                    "THEN 'wtbd_med'
                  WHEN lakevolume >",quantile(wtbd$lakevolume, 0.75,T),
                    "THEN 'wtbd_lg'
                  ELSE 'unclassified'
                  END as class
                  FROM wtbd
                  WHERE (gnis_name != ' ' AND gnis_name != 'Noname' AND gnis_name IS NOT NULL)
                 ", sep=" ")
wtbd <- sqldf_sf(statemt, "wtbd")
st_write(wtbd, paste0(export_path,"31_wtbd_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

# enseure both datasets have same crs prior to rbind()
st_crs(flow) <- 4326
st_crs(wtbd) <- 4326 
nhd2 <- rbind( flow[,c("gnis_name", "class", "geometry")], wtbd[,c("gnis_name", "class", "geometry")] )
st_write(nhd2, paste0(export_path,"32_nhd2_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
```

```{r Prep Text Labels, echo=FALSE, message=FALSE, warning=FALSE}
maplabs <- fn_labelprep(data=list(counties, cities, roads, nhdlabs), classes=c("county","city","road","nhd"))
```

## Remaining RMD w/ fixed variable names
```{r Remainder of the RMD, echo=FALSE, message=FALSE, warning=FALSE}
#----Map 1----
# Legend Bins
facils <- facils[,colSums(is.na(facils))<nrow(facils)] #for extra long & lat columns full of NAs
st_write(facils, paste0(export_path,"33_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")

wd_mgd = c(0, 0.5, 1.0, 2, 10, 25, 100, 1000) #set ranges for bins day and year 
wd_mgy = c(0, 1, 5, 10, 50, 250, 1000, 10000)

for (i in 1:length(map_by)) { #execute for each metric in map_by param 
  #legend_title <- paste0(map_by[i])
  legend_title <- legend_titling(map_by[i], runid_list_facilities)
  
  #add column of NAs when no metric col exists, when no facilities with the desired metric exist in the extent
  if ((map_by[i] %in% colnames(facils)) == FALSE) {
    facils[map_by[i]] <- NA
    mapMessage <- TRUE #for returning message to user if map is empty
  } else { mapMessage <- FALSE  }
  #Ordering & numbering data by the metric to be mapped 
  facils <- sqldf_sf(paste0( #ordering the data using sqldf 
  "SELECT facils.*  
  FROM facils
  ORDER BY", ' ', map_by[i], ' ', "DESC"), #ordering by the metric of interest, descending 
  "facils")
  facils$NUM <- seq(1, nrow(facils))
  st_write(facils, paste0(export_path,"34_facils_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
 if (i==1) { #data for table will be sorted by the first of map_by
   #facils$within <- facils_within
 } 
  
  metric_unit <- substr(map_by[i], nchar(map_by[i]) - 2, nchar(map_by[i]))  #get metric unit from last 3 characters of metric 
  if (metric_unit == "mgd") { #different ranges for mgd and mgy
  div <- wd_mgd
  } else if (metric_unit == "mgy") {
  div <- wd_mgy
  }
  
  mp_layer_sql <- paste('SELECT *, ',map_by[i],' AS demand_metric
        FROM facils' , sep="") #Renaming metric of interest for generalized sorting into bins
  mp_layer <- sqldf_sf(mp_layer_sql, "facils")
  st_write(mp_layer, paste0(export_path,"35_mp_layer_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  bins = as.data.frame(div)
  bins$classid <- index(bins)
  names(bins) <- c("val", "bin")
  write.csv(bins, paste0(export_path,"36_bins.csv"))

  entity_classes <- sqldf_sf( #sorting the data into bins based on their range 
      "select a.NUM, max(b.bin) as bin
      from mp_layer as a 
      left outer join bins as b 
      on (a.demand_metric >= b.val) 
      group by a.NUM" , "mp_layer")
  st_write(entity_classes, paste0(export_path,"37_entity_classes_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  
  mp_layer <- sqldf_sf( #joining the bins with the metric data 
      "select a.*, b.bin 
      from mp_layer as a 
      left outer join entity_classes as b 
      on a.NUM = b.NUM " , "mp_layer")

  mp_layer$bin[is.na(mp_layer$bin)] <- "X" # replacing NA values in bin column
  names(mp_layer)[names(mp_layer) == 'demand_metric'] <- map_by[i] #change column name back to the specific metric
  mp_layer <- mp_layer[, !duplicated(colnames(mp_layer))] #remove duplicated columns
  mp_layer <- fn_centroid_coords(mp_layer)
  st_write(mp_layer, paste0(export_path,"38_mp_layer_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  
  rsegs <- fn_centroid_coords(rsegs)
  st_write(rsegs, paste0(export_path,"39_rsegs_sf.csv"), layer_options = "GEOMETRY=AS_WKT")
  
##Mapping function
  source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_mapgen2.R"),local = TRUE) #load mapping function

  # args/params have been kept separate during dev. so far, but will be consolidated & some removed once we're happy with maps 
  suppressWarnings(suppressMessages( 
    fn_mapgen2(mapnum = 1, type, map_type, styles[[map_style]], metric = map_by[i], rivseg, bbox, segs, counties, roads, 
          nhd, maplabs, locality, region, mp_layer, metric_unit, title="default") ))
  
  #assign map to environment
  assign(paste0('map', i), map, envir = globalenv())
  }

## Mapping Errors:
  # Error in if (distance > 300) { : missing value where TRUE/FALSE needed
  # Solution: this indicates the bbox is not in the format needed by the function. Regenerate the bbox and make sure it is of class bbox and has names xmin, xmax, etc.

  # Error in rbind(deparse.level, ...) : numbers of columns of arguments do not match
  # Solution: maplabs object needs to be re-generated

# Save map as png
#name maps based on map type
if (map_type == "basin") {
  map_name <- rivseg
} else if (map_type == "locality") {
  map_name <- locality
} else if (map_type == "region") {
  map_name <- region
}
#add sources or facils to name based on type 
if (type == "source") {
  map_name <- paste0(map_name, '_sources')
} else if (type == "facility") {
  map_name <- paste0(map_name, '_facils')
}

# Saving map(s) as a png
# export_path set in config for analysts, set in console if nonexistent to location where map will be exported 
mapfilename <- character() #empty character var, not a list
for (i in 1:length(map_by)) {
  mapfilename[i] <- paste(export_path, map_name, "_", map_by[i], ".png", sep="")
  mapf <- get(paste0('map',i))
  ggsave(
    filename = mapfilename[i],
    plot = mapf,
    width = 25,
    height = 20)
}
```
```{r Viewing Map(s) 1, echo=FALSE, out.width = '100%', out.height='100%', message=TRUE}
knitr::include_graphics(mapfilename) #display map PNG - for maps on top of each other
if (mapMessage == TRUE) {
  message("The metric requested does not exist for this map.")
  message("Check your syntax/spelling. If correct, then this data has not been measured/modeled")
}
```
```{r Continued..(table1), echo=FALSE, message=FALSE, warning=FALSE}
names(facils)[names(facils) == 'propname'] <- 'Facility' #if propname column exists rename to Facility
#facils$within$hydroid <- as.numeric(gsub(",", "", facils$within$hydroid, fixed = TRUE))
#create initial table
table <- data.frame(
  Number= facils$NUM,
  Facility=facils$Facility,
  HydroID = facils$hydroid)

#for source type only add mp name and source type to table
if (type=="source"){
  table$Source = facils$MP_Name  
  table$Source_Type = facils$Source_Type
}

table$Locality = facils$Locality
write.csv(table, paste0(export_path,"40_table.csv"))

#add rivseg names
for(i in 1:nrow(table)){ 
  loc_rivseg <- (rsegs[grep(facils$riverseg[i], rsegs$riverseg),]) #find rivseg in segs and compare to facils to add name
  if (nrow(loc_rivseg) != 0) {
    table$`River Segment Name`[i] <- loc_rivseg$name
  } else { # if no matching row was found for the riverseg ID, leave blank but don't break
    table$`River Segment Name`[i] <- ""
    }
}
write.csv(table, paste0(export_path,"41_table.csv"))


table$`River Segment ID`= facils$riverseg #add rivseg ID

table$`Permitted Capacity` <- facils$vwp_max_mgy #add permitted capacity to table 
write.csv(table, paste0(export_path,"42_table.csv"))


for (i in 1:length(table_col)){
  #metric col of interest may not exist if none were found in extent: don't break if this is the case 
  if (table_col[i] %in% colnames(facils)) {
  #adding requested columns to table 
    table[,table_col[i]] <- round( st_drop_geometry(facils[,table_col[i]]), digits = 2) #round all values to 2 decimal place digits
  }
}

table <- table[,colSums(is.na(table))<nrow(table)] #remove columns with all NAs, added to df for mapping as placeholders 
write.csv(table, paste0(export_path,"43_table.csv"))


#compare requested table columns with those that actually exist 
novals <- data.frame(metric=character())
for (i in 1:length(table_col)) {
  if (!table_col[i] %in% names(table)) {
    novals[i,] <- table_col[i]
  }
}
#for returning message if metric table columns were missing 
if (nrow(novals > 0)) {
  tableMessage <- TRUE
} else { tableMessage <- FALSE }

# Rename columns & create flextable
#names(table)[names(table) == 'Source_Type'] <- 'Source Type'
names(table)[names(table) == 'fiveyr_avg_mgy'] <- '5-yr Avg Use (mgy)'
names(table) <- mgsub(names(table), pattern="_", replacement=" ") #formatting for flextable headers, line breaks happen at spaces not underscores
write.csv(table, paste0(export_path,"44_table.csv"))

ft1 <- fn_tablegen(type = "facility", table = table, columns = "all", alignment = "left") #Execute flextable function, which saves the flextable as variable 'ft' for displaying later

```
```{r Viewing Table 1, echo=FALSE, out.width='100%', message=TRUE}
if (tableMessage == TRUE) {
  message("Missing column indicates the metric requested does not exist for this table")
}
ft1 #display flextable
```
```{r Continued..(map2), echo=FALSE, message=FALSE, warning=FALSE}
#----Map/Table2----
## Need to adapt this for multiple maps
#rivdiv <- c(-20,-10,-2,2,10,20,500) #% difference breaks for rivseg map - moved to config

for (i in 1:length(rivseg_metric)){
  rseg_leg_title <- legend_titling(rivseg_metric[i], runid_list_riversegs)
  
  title1 <- paste0(rivseg_metric[i]) #define title here for mapping so each map has diff metric title, pass into function
  
  if (rivseg_metric[i]=="l30_Qout"){
      title <- gsub("l30_Qout", "Lowest 30 Day Flow", title1)
  } else if (rivseg_metric[i]=="l90_Qout"){
          title <- gsub("l90_Qout", "Lowest 90 Day Flow", title1)
  } else if (rivseg_metric[i]=="7q10"){
      title <- gsub("7q10", "Lowest 7 Day Flow", title1)
  } else {
    title <- title1
  }

  rsegs <- rsegs[ , !names(rsegs) %in% c("pct_diff", "bin")]
  st_write(rsegs, paste0(export_path,"45_rsegs_sf_",rseg_leg_title,".csv"), layer_options = "GEOMETRY=AS_WKT")
  
  rseg_sql <- paste('SELECT *, ','percentDiff','_',rivseg_metric[i],' AS pct_diff
        FROM rsegs' , sep="") #Renaming metric of interest for generalized sorting into bins
  
  rsegs <- sqldf_sf(rseg_sql,"rsegs")
  st_write(rsegs, paste0(export_path,"46_rsegs_sf_",rseg_leg_title,".csv"), layer_options = "GEOMETRY=AS_WKT")

  bins = as.data.frame(rivseg_pct_vect) #rivseg_pct_vect set in config
  bins$classid <- index(bins)
  names(bins) <- c("val", "bin")
  write.csv(bins, paste0(export_path,"47_bins_",rseg_leg_title,".csv"))

  rivseg_classes <- sqldf_sf( #sorting the data into bins based on their range 
    "select a.riverseg, min(b.bin) as bin
    from rsegs as a 
    left outer join bins as b 
    on (a.pct_diff <= b.val) 
    group by a.riverseg" )
  write.csv(rivseg_classes, paste0(export_path,"48_rivseg_classes_",rseg_leg_title,".csv"))

  rsegs <- sqldf_sf( #joining the bins with the metric data 
    "select a.*, b.bin 
    from rsegs as a 
    left outer join rivseg_classes as b 
    on a.riverseg = b.riverseg " , "rsegs")
  st_write(rsegs, paste0(export_path,"49_rsegs_sf_",rseg_leg_title,".csv"), layer_options = "GEOMETRY=AS_WKT")

  ##Mapping function
  suppressWarnings(suppressMessages(
    fn_mapgen2(mapnum = 2,type, map_type, styles[[map_style]], metric = rivseg_metric[i], rivseg, bbox, rsegs, counties, roads, 
          nhd, maplabs, locality, region, mp_layer, metric_unit, title="default") ))
  
  #assign map to environment
  assign(paste0('map_rivseg', i), map, envir = globalenv())

}

#Save rivseg map
rivmapfilename <- character() #empty character var, not a list
for (i in 1:length(rivseg_metric)) {
  rivmapfilename[i] <- paste(export_path, map_name, "_", rivseg_metric[i], ".png", sep="")
  mapf <- get(paste0('map_rivseg',i))
  ggsave(
    filename = rivmapfilename[i],
    plot = mapf,
    width = 25,
    height = 20)
}
```
```{r Displaying Rivseg Map, out.width = '100%', out.height='100%', echo=FALSE}
knitr::include_graphics(rivmapfilename)
```
```{r Continued..(table2), echo=FALSE, message=FALSE, warning=FALSE}
#create metric type column
rivTables <- list() #to store dataframes for each drought metric
#ftable<- list()
for (k in 1:length(rivseg_metric)){ #loop thru metrics
  rivTables[[k]] <- data.frame(Name = rsegs$name) # add rivseg name
  rivTables[[k]][,paste0('Riverseg')] <- rsegs$riverseg # add rivseg number
  rivTables[[k]]$Metric <- rivseg_metric[k] #add metric
  write.csv(rivTables[[k]], paste0(export_path,"50_rivTables_",rivseg_metric[k],".csv"))
  
   for (i in 1:nrow(rsegs)) {
        for (j in 1:length(runid_list_riversegs)){ #add actual metric column data
          rivTables[[k]][i,paste0(runid_list_riversegs[j])] = round(
                st_drop_geometry( rsegs[i,paste0(runid_list_riversegs[j],'_',rivseg_metric[k])] ), digits= 2)
        }
   }
  write.csv(rivTables[[k]], paste0(export_path,"51_rivTables_",rivseg_metric[k],".csv"))
  #format table columns, add percent difference 
 # rivTables[[k]][,paste0('Difference')] = round( st_drop_geometry(rsegs[,paste0('diff','_',rivseg_metric[k])]) ,digits= 2)
  rivTables[[k]][,paste0('pct_diff')]= round( st_drop_geometry(rsegs[,paste0('percentDiff','_',rivseg_metric[k])]) , digits= 2)
  write.csv(rivTables[[k]], paste0(export_path,"52_rivTables_",rivseg_metric[k],".csv"))
  
  #order by lowest % difference from rivTables[[k]]
  rivdf <- rivTables[[k]] # for sqldf
  rivdf <- sqldf( "SELECT rivdf.*  
              FROM rivdf 
              ORDER BY pct_diff ASC") #ordering by the metric of interest, descending 
  
  names(rivdf)[names(rivdf) == 'pct_diff'] <- '% Difference'
  write.csv(rivdf, paste0(export_path,"53_rivdf_",rivseg_metric[k],".csv"))
  
  #need to put NA values @ bottom of df
  nanum <- sum(is.na(rivdf$`% Difference`))
  narows <- head(rivdf, nanum)
  goodrows <- rivdf[(nanum+1):nrow(rivdf), ]
  rivdf <- rbind(goodrows, narows)
  write.csv(rivdf, paste0(export_path,"54_rivdf_",rivseg_metric[k],".csv"))
  
  nacols <- data.frame(colSums(is.na(rivdf)) == nrow(rivdf)) #dataframe of which columns are all na or not
  for (i in 1:nrow(nacols)) {
    if (nacols$colSums.is.na.rivdf......nrow.rivdf.[i] == TRUE){ #if any column is all na, then return true
      tablemessage2 = TRUE
    }
    else { #if column is not all na, then return false
      tablemessage2 = FALSE
    }
  }
    
  
  ft2 <- fn_tablegen(type = "riverseg", table = rivdf, columns = "all", alignment = "left") #Flextable function
  
  assign(paste0('table', k), ft2, envir = globalenv())
  print(get(paste0('table', k))) #doesn't work to display flextables in loop on rendering 
}
```
```{r Viewing Rivseg Flextable, out.width = '100%', out.height='100%', results='asis', echo=FALSE}
#result = 'asis' necessary 
if (tablemessage2==TRUE) {
  message("A column in the table is completely NA values, 
          likely meaning the metric requested is not modeled for this data
          or the segments are all tidal")
}
for (k in 1:length(rivseg_metric)){
  cat(knitr::knit_print(get(paste0('table', k))))
}
#note: doesn't display readable flextable within Rstudio but does upon render
```

