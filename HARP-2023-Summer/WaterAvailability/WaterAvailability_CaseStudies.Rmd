---
date: "`r Sys.Date()`"
author: "Glenn Campagna"
title: "Water Availability Case Studies"
output: 
  officedown::rdocx_document:
    mapstyles:
      
      Normal: ['First Paragraph']
params: 
  outlet_list: ["PL0_5141_5140", "JU3_6900_6950", "JA5_7480_0001", "YP2_6390_6330", "OR3_7740_8271_carvins", "PU3_4451_4450"]
  demand_scenario: ["runid_11"] 
  baseline_scenario: ["runid_0"] 
  mif_coef: [0.9]
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.cap = TRUE)

library(data.table)
library(hydrotools)
library(sqldf)
library(flextable)
library(officedown)
library(officer)
library(jsonlite)
library(ggplot2)
library(IHA)
library(nhdplusTools)
library(arcpullr)

basepath='/var/www/R'
source('/var/www/R/config.R') 
ds <- RomDataSource$new(site, rest_uname)
ds$get_token(rest_pw)

github_base_uri <- "https://raw.githubusercontent.com/HARPgroup"
github_uri <- paste0(github_base_uri, "/HARParchive/master")
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fn_download_read.R"),local = TRUE)
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fns_spatial.R"),local = TRUE) #load functions for dealing with spatial data

options(scipen = 999) #disable scientific notation

#assign params
for(i in 1:length(params)){
  assign(names(params[i]), params[[i]])
}

#get numeric element of demand scenario runid to use in fn_get_runfile
runid_dem = as.numeric(gsub(".*?([0-9]+).*", "\\1", demand_scenario))   

#flextable default formatting
set_flextable_defaults(
  font.size = 8, background.color = "white", 
  na_str = "NA", nan_str = "NA", #padding = 1, 
  table.layout = 'fixed', tabcolsep = 1.5,
  fonts_ignore = T, big.mark = "", decimal.mark= ".") #fonts_ignore applies when knitting as pdf 

#document formatting (came with template)
fp <- fp_par(
  text.align = "center", 
  padding.bottom = 20, padding.top = 120, 
  border.bottom = fp_border())

ft <- fp_text(shading.color='#EFEFEF', bold = TRUE)
```


\newpage

## Table of contents

<!---BLOCK_TOC--->

## List of tables

<!---BLOCK_TOC{seq_id: 'tab'}--->

## List of figures

<!---BLOCK_TOC{seq_id: 'fig'}--->


\newpage

## Sections

<!---BLOCK_MULTICOL_START--->
Column1
`r run_columnbreak()` 
Column2
<!---BLOCK_MULTICOL_STOP{widths: [3,3], space: 0.2, sep: true}--->

# Water Availability Case Studies 


## Case Study Description 
### A case study is a descriptive example of a particular area (ex. a watershed/region) where water availability is calculated. For that example watershed, we can take a detailed look at the individual calculations and resulting values generated.


# Impoundments for case studies:
- Lake Manassas 
- Lake Moomaw
- Lake Chesdin 
- Lake Anna 
- Carvin's Cove 
- Jennings Randolph Lake 


```{r Pull Data, echo = FALSE, message=FALSE, warning=FALSE}
#Get all riversegments for reference
rsegs <- ds$auth_read(uri = paste0(site,"/vahydro_riversegs_nogeom_export")) 
                      
#Only care about the river segment ids, we won't need the rest of the file.
#We will only use those rsegs that follow the standard format vahydrosw_wshed_XXX_XXXX_XXXX_X
#First, find only those riversegments that begin with vahydrosw_wshed followed by
#"_somecharacters_4 digits_4 digits_anything else"
rsegs <- rsegs$hydrocode[grepl("^vahydrosw_wshed_.+_[0-9]{4}_[0-9]{4}.*$",rsegs$hydrocode)]
#Now, make a data frame of just the NHDPlus ID e.g. remove the vahydrosw_wshed_. We 
#have to create at least two columns in this dataset for use in fn_extract_basin()
rsegs <- data.frame(riverseg = gsub("vahydrosw_wshed_","",rsegs),
                    blankColumn = NA)

#Find all river segments that are not tidal outlets i.e. not JL7_0000_0000
rsegs_noTidalOutlet <- rsegs[grepl(".+_.*[1-9]+.*_.*",rsegs$riverseg),]

#Get storage metrics 
df_storage <- data.frame(
  'model_version' = c('vahydro-1.0', 'vahydro-1.0'),
  'runid' = c(demand_scenario, demand_scenario),
  'metric' = c('Smin_L30_mg', 'Smin_L90_mg'),
  'runlabel' = c('SminL30mg_vah','SminL90mg_vah')
)
storage_data <- om_vahydro_metric_grid(
  metric = metric, runids = df_storage, bundle = 'all', ftype = "all",
  base_url = paste(site,'entity-model-prop-level-export',sep="/"),
  ds = ds
)

#Get demand scenario metrics used in WA eqn
df_metrics <- data.frame(
  'model_version' = c('vahydro-1.0', 'vahydro-1.0', 'vahydro-1.0', 'vahydro-1.0'),
  'runid' = c(demand_scenario, demand_scenario, demand_scenario, demand_scenario),
  'metric' = c('wd_cumulative_mgd', 'ps_cumulative_mgd', 'l30_Qout', 'l90_Qout'),
  'runlabel' = c('wd_cumulative_mgd','ps_cumulative_mgd', 'l30_Qout_dem', 'l90_Qout_dem')
)
metric_data <- om_vahydro_metric_grid(
  metric = metric, runids = df_metrics, bundle = 'all', ftype = "all",
  base_url = paste(site,'entity-model-prop-level-export',sep="/"),
  ds = ds
)

#Get baseline scenario metrics for WA eqn
df_baseline <- data.frame(
  'model_version' = c('vahydro-1.0', 'vahydro-1.0'),
  'runid' = c(baseline_scenario, baseline_scenario),
  'metric' = c('l90_Qout', 'l30_Qout'),
  'runlabel' = c('l90_Qout_base', 'l30_Qout_base')
)
baseline_data <- om_vahydro_metric_grid(
  metric = metric, runids = df_baseline, bundle = 'all', ftype = "all",
  base_url = paste(site,'entity-model-prop-level-export',sep="/"),
  ds = ds
)

#Get riversegs with geometry for mapping 
rsegs_geom_data <- fn_download_read(url=paste(site,"/vahydro_riversegs_export",sep=""), filetype="csv", zip=FALSE)
rsegs_geom_data$riverseg <- gsub(pattern="vahydrosw_wshed_", replacement="", rsegs_geom_data$hydrocode)
rsegs_geom_data <- rsegs_geom_data[ rsegs_geom_data[,fn_geoCol(rsegs_geom_data)]!="" & !is.na(rsegs_geom_data[,fn_geoCol(rsegs_geom_data)]) ,] #finds geom column & omits rsegs with blank or NA geometry
```

```{r Get rid of waterSupplyElements from Storage data, echo=FALSE, message=FALSE, warning=FALSE}
nrow_all <- nrow(storage_data)

storage_data$object_class <- NA
storage_data$elid <- NA

for (i in 1:nrow(storage_data)) {
    #Get model
  model <- RomProperty$new(ds,list( 
    featureid = storage_data$featureid[i],
    propcode = 'vahydro-1.0',
    entity_type = 'dh_feature'
  ),TRUE)
  
  #Get object class
  object_class <- RomProperty$new(ds,list( #get vahydro-1.0 model feature from vahydro
    featureid = model$pid,
    propname = 'object_class'
  ),TRUE)
  storage_data$object_class[i] <- object_class$propcode

  #Get element id
  elid <- RomProperty$new(ds,list( 
    featureid = model$pid,
    propname = 'om_element_connection'
  ),TRUE)
  storage_data$elid[i] <- elid$propvalue
}

storage_data <- storage_data[!storage_data$object_class == "waterSupplyElement", ] #remove WSEs

nrow_noWSE <- nrow(storage_data)

nrow_diff <- nrow_all - nrow_noWSE

## Alternative model retrieval, takes much longer
  # #Get model info using ds$auth_read to authenticate and grab model info+data
  # obj_url <- paste(json_obj_url, model$pid, sep="/")
  # model_info <- ds$auth_read(obj_url,  "text/json", "")
  # model_info <- fromJSON(model_info)
  # elid <- model_info[[1]]$om_element_connection$value
  # object_class <- model_info[[1]]$object_class
  # storage_data$object_class[i] <- object_class

print(paste0(nrow_diff, ' waterSupplyElement objects removed from analysis'))
```

```{r Smin Calculations, include=FALSE, echo=FALSE}
storage_data$SminL30mg_nex <- NA #empty columns to hold near exact storage values
storage_data$SminL90mg_nex <- NA
storage_data$SminL30mg_apx <- NA
storage_data$SminL90mg_apx <- NA
storage_data$min_in_pd30 <- NA #empty columns to hold TRUE/FALSE
storage_data$min_in_pd90 <- NA 
storage_data$outside_pd30 <- NA #empty columns to hold numeric values
storage_data$outside_pd90 <- NA 

for (i in 1:nrow(storage_data)) {
  #Get runfile with timeseries data from VAhydro
  dat <- fn_get_runfile(storage_data$elid[i], runid_dem, site= omsite,  cached = TRUE) #get timeseries data (zoo)
  mode(dat) <- 'numeric'
  cols <- names(dat)
  
  #Trim runfile
  syear = as.integer(min(dat$year))
  eyear = as.integer(max(dat$year))
  if (syear < (eyear - 2)) {
    sdate <- as.POSIXct(paste0(syear,"-10-01"))
    edate <- as.POSIXct(paste0(eyear,"-09-30"))
  } else {
    sdate <- as.POSIXct(paste0(syear,"-02-01"))
    edate <- as.POSIXct(paste0(eyear,"-12-31"))
  }
  dat <- window(dat, start = sdate, end = edate);
  mode(dat) <- 'numeric' 
  
  ## Dsiabled -- Sees Lake Anna as without active impoundment 
  #Check if impoundment is active
    #2 ways this is done: im_off and imp_enabled 
    #imp_off used in waterSupplyModelNode and hydroImpoundment
    #imp_enabled used in waterSupplyElement
  imp_off = 0 #default to active impoundment
  # imp_enabled = TRUE

  if ("imp_off" %in% cols) {
      imp_off <- as.integer(median(dat$imp_off))
  }
  
  # if (imp_off == 1) { #check if imp_off exists, if not:
  #   if("impoundment" %in% cols) {
  #     imp_enabled = TRUE
  #     paste0('imp_enabled = ', imp_enabled, ' : Impoundment Enabled')
  #   }
  # } else if (imp_off == 0) {
  #   paste0('imp_off = ', imp_off, ' : Impoundment Enabled')
  # }
  # 
  # if (imp_enabled == FALSE & imp_off == 1) {
  #   paste0('imp_off = ', imp_off, ' and imp_enabled = ', imp_enabled, ' : Impoundment Disabled')
  # }
  
#### Only do Storage calculation if impoundment is active
  if (imp_off == 0) {
 
    #Different names for storage and Q values based on object_class:
    if (storage_data$object_class[i] == "hydroImpoundment") { #from hydroImpoundment.R: colname = "Storage"
      #storage col already named "Storage"
      Qcol <- "Qin" #from hydroImpoundment.R: flows <- zoo(dat$Qin, order.by = index(dat));
    } else if (storage_data$object_class[i] == "waterSupplyModelNode") {
      dat$Storage <- dat$impoundment_Storage #from waterSupplyModelNode.R: colname = "impoundment_Storage"  
      Qcol <- "Qout" #from waterSupplyModelNode.R: flows <- zoo(as.numeric(as.character( dat$Qout )), order.by = index(dat));
      
   # } else if (object_class == "waterSupplyElement") { #disabled waterSupplyElements, too much variation
    #   
    #   # Storage col could be a couple different names 
    #   if("local_impoundment_Storage" %in% cols) {
    #     storagecol <- "local_impoundment_Storage"
    #   }
    #   if("impoundment_Storage" %in% cols) {
    #     storagecol <- "impoundment_Storage"
    #   }
    #   dat$Storage <- dat[,storagecol]
    #   if ('Qintake' %in% cols) {
    #     Qcol <- "Qintake" 
    #   } else { #from waterSupplyElement.R: flows <- zoo(as.numeric(as.character( dat$Qintake )), order.by = index(dat));
    #     Qcol <- "Qin" #no Qintake in at least 1 case, use Qin instead
    #   }
      
    } else { #object_class is something else
      dat$Storage <- dat$impoundment_Storage
      Qcol <- "Qout" #Qout is the default
    }
     
    #find l30 and l90 years based on Qcol
    flows <- zoo(dat[,Qcol], order.by = index(dat)); 
    loflows <- group2(flows, year = 'calendar') #vahydro Smin metrics used calendar year method 
    
    l90 <- loflows["90 Day Min"];
    ndx <- which.min(as.numeric(l90[,"90 Day Min"]));
    l90_Qout <- round(loflows[ndx,]$`90 Day Min`,6);
    l90_year <- loflows[ndx,]$`year`;
    l90yr_start <- as.POSIXct(paste0(l90_year,"-01-01")) #start of l90 year
    l90yr_end <- as.POSIXct(paste0(l90_year,"-12-31")) #end of l90 year
    datpd_90yr <- window( #data for the l90 year
      dat,
      start = l90yr_start,
      end = l90yr_end
    )
    
    l30 <- loflows["30 Day Min"];
    ndx <- which.min(as.numeric(l30[,"30 Day Min"]));
    l30_Qout <- round(loflows[ndx,]$`30 Day Min`,6);
    l30_year <- loflows[ndx,]$`year`;
    l30yr_start <- as.POSIXct(paste0(l30_year,"-01-01"))
    l30yr_end <- as.POSIXct(paste0(l30_year,"-12-31"))
    datpd_30yr <- window(
      dat,
      start = l30yr_start,
      end = l30yr_end
    )
  
    #data for the low flow years
    l30yr_df <- as.data.frame(datpd_30yr)
    l90yr_df <- as.data.frame(datpd_90yr)
    
    #zoo of Qcol for each l30 and l90 years
    l30yr_flowz <- window(flows, start = l30yr_start, end = l30yr_end)
    l90yr_flowz <- window(flows, start = l90yr_start, end = l90yr_end)
    
    #zoo to data frame
    l30yr_flows <- data.frame(Q = l30yr_flowz)
    l90yr_flows <- data.frame(Q = l90yr_flowz)
    
    #use rolling mean to identify each low-flow period
    rollmean30 = rollmean(l30yr_flows, k=30, fill=NA, align='left') #results in matrix/array
    rollmean90 = rollmean(l90yr_flows, k=90, fill=NA, align='left')
    
    l30yr_flows$rollmean30 <- rollmean30[,1]
    l90yr_flows$rollmean90 <- rollmean90[,1]
    
    #start row numbers for low flow periods
    rownum_start30 <- which.min(l30yr_flows$rollmean30) #min rolling mean since we used a left alignment
    rownum_start90 <- which.min(l90yr_flows$rollmean90) 
    
    #end row numbers for low flow periods
    rownum_end30 <- rownum_start30 + 29
    rownum_end90 <- rownum_start90 + 89
    
    #start  and end dates for low flow periods
    l30pd_start <- as.POSIXct(row.names(l30yr_flows[rownum_start30, ]))
    l90pd_start <- as.POSIXct(row.names(l90yr_flows[rownum_start90, ]))
    l30pd_end <- as.POSIXct(row.names(l30yr_df[rownum_end30, ]))
    l90pd_end <- as.POSIXct(row.names(l90yr_df[rownum_end90, ]))
    
    #end rownum cant be greater than length of data 
    # if (rownum_end90 > nrow(l90yr_df)) {
    #   rownum_end90 = nrow(l90yr_df)
    # }
    # if (rownum_end30 > nrow(l30yr_df)) {
    #   rownum_end30 = nrow(l30yr_df)
    # }
    
    #zoos for the drought periods 
    l30pd_flowz <- window(dat, start = l30pd_start, end = l30pd_end)
    l90pd_flowz <- window(dat, start = l90pd_start, end = l90pd_end)
    
    #data for low flow periods
    l30pd_df <- as.data.frame(l30pd_flowz)
    l90pd_df <- as.data.frame(l90pd_flowz)
    
    #Near-Exact Smin 
      #Lowest storage within the low flow periods 
      #Storage needs to be converted from acre-feet to million gallons
    storage_data$SminL30mg_nex[i] <- round((min(l30pd_df$Storage) / 3.069), digits = 3)
    storage_data$SminL90mg_nex[i] <- round((min(l90pd_df$Storage) / 3.069), digits = 3)
    
    #Approximate Smin 
      #Lowest storage within the low flow years 
      #Storage needs to be converted from acre-feet to million gallons
    storage_data$SminL30mg_apx[i] <- round((min(l30yr_df$Storage) / 3.069), digits = 3)
    storage_data$SminL90mg_apx[i] <- round((min(l90yr_df$Storage) / 3.069), digits = 3)
    
    #get row numbers where near-exact Smin happens within low flow period 
    rownum_nex30 <- which.min(l30pd_df$Storage) 
    rownum_nex90 <- which.min(l90pd_df$Storage)

    #get row numbers where near-exact Smin happens within low flow year 
    rownum_nex30yr <- rownum_start30 + rownum_nex30 - 1
    rownum_nex90yr <- rownum_start90 + rownum_nex90 - 1

    #get row numbers where approx Smin happens within low flow year 
    rownum_apx30 <- which.min(l30yr_df$Storage) 
    rownum_apx90 <- which.min(l90yr_df$Storage)
    
    #test if values occur in the same place
    match30 <- (as.numeric(rownum_nex30yr) == as.numeric(rownum_apx30))
    match90 <- (as.numeric(rownum_nex90yr) == as.numeric(rownum_apx90))
    
    #add TRUE/FALSE to dataframe
    storage_data$min_in_pd30[i] <- paste0(match30)
    storage_data$min_in_pd90[i] <- paste0(match90)
    
    # If approx. and near-exact values are different: 
    # How far outside the low-flow period does the approximate value occur?
      ## Negative: near-exact Smin happens AFTER the approx. Smin 
      ## Positive: near-exact Smin happens BEFORE the approx. Smin 
    if (storage_data$min_in_pd30[i] == FALSE) {
      storage_data$outside_pd30[i] = rownum_apx30 - rownum_nex30yr
    }
    if (storage_data$min_in_pd90[i] == FALSE) {
      storage_data$outside_pd90[i] = rownum_apx90 - rownum_nex90yr
    }
    
  }
}

#when a min value is repeated, ex. 100s across all storage vals, our method is flawed
  #this causes FALSEs and # of days to show up where we should have TRUE and 0 days 
#COB: This is interesting. In theory, we could have an identical minimum value occur in 
  #two different parts of the year. It's pretty unlikely, but possible. Theoretically, we
  #could capture this by looking at the difference between e.g. rownum_nex90yr - rownum_apx90
  #We should see that this falls within 90 days, I think
storage_data[is.na(storage_data)] <- 0 #replace NA values with 0

for (i in 1:nrow(storage_data)) {
  if (storage_data$SminL30mg_apx[i] == storage_data$SminL30mg_nex[i]) {
    storage_data$min_in_pd30[i] <- TRUE
    storage_data$outside_pd30[i] <- 0  
  } 
      
  if (storage_data$SminL90mg_apx[i] == storage_data$SminL90mg_nex[i]) {
    storage_data$min_in_pd90[i] <- TRUE
    storage_data$outside_pd90[i] <- 0
  }
}

```

```{r Smin Method Comparison, echo=FALSE, message=FALSE, warning=FALSE}
#Compare approx and near exact Smin values. Approx should always be <= near exact 
storage_data$apx_lessthan_nex_30 <- storage_data$SminL30mg_apx <= storage_data$SminL30mg_nex
storage_data$apx_lessthan_nex_90 <- storage_data$SminL90mg_apx <= storage_data$SminL90mg_nex
  
```

```{r Sum Storage by Riverseg, echo=FALSE, message=FALSE, warning=FALSE}
#Approximate Smin Values 

#Sum approx SminL30 by riverseg
storage_byseg_30_apx <- sqldf("SELECT storage_data.riverseg, storage_data.SminL30mg_apx,
                       SUM(SminL30mg_apx) AS SminL30mg_apx_local
                       FROM storage_data
                       GROUP BY riverseg
                       ")

#Sum qpprox SminL90 by riverseg
storage_byseg_90_apx <- sqldf("SELECT storage_data.riverseg, storage_data.SminL90mg_apx,
                       SUM(SminL90mg_apx) AS SminL90mg_apx_local
                       FROM storage_data
                       GROUP BY riverseg
                       ")

#Join approx SminL30 and SminL90 summed storage
storage_byseg_apx <- sqldf("SELECT a.riverseg, a.SminL30mg_apx_local, b.SminL90mg_apx_local
                              FROM storage_byseg_30_apx AS a
                              LEFT OUTER JOIN storage_byseg_90_apx AS b
                              WHERE (a. riverseg = b.riverseg) ")


#Near-exact Smin Values 

#Sum near-exact SminL30 by riverseg
storage_byseg_30_nex <- sqldf("SELECT storage_data.riverseg, storage_data.SminL30mg_nex,
                       SUM(SminL30mg_nex) AS SminL30mg_nex_local
                       FROM storage_data
                       GROUP BY riverseg
                       ")

# #Sum near-exact SminL90 by riverseg
storage_byseg_90_nex <- sqldf("SELECT storage_data.riverseg, storage_data.SminL90mg_nex,
                       SUM(SminL90mg_nex) AS SminL90mg_nex_local
                       FROM storage_data
                       GROUP BY riverseg
                       ")

#Join near-exact SminL30 and SminL90 summed storage
storage_byseg_nex <- sqldf("SELECT a.riverseg, a.SminL30mg_nex_local, b.SminL90mg_nex_local
                              FROM storage_byseg_30_nex AS a
                              LEFT OUTER JOIN storage_byseg_90_nex AS b
                              WHERE (a. riverseg = b.riverseg) ")

#Join Approx and Near-exact Smin values by riverseg
storage_byseg <- sqldf("SELECT a.*,  b.SminL30mg_nex_local, b.SminL90mg_nex_local
                              FROM storage_byseg_apx AS a
                              LEFT OUTER JOIN storage_byseg_nex AS b
                              WHERE (a. riverseg = b.riverseg) ")
```

```{r Join Storage + Metric + Baseline Data, echo=FALSE, message=FALSE, warning=FALSE}
#Storage data by riverseg in storage_byseg 
#Metric data by riverseg in metric_data 

#Join storage data onto demand scenario metric data 
metric_data <- sqldf('SELECT a.*, b.SminL30mg_apx_local, b.SminL90mg_apx_local, b.SminL30mg_nex_local, b.SminL90mg_nex_local
                   FROM metric_data as a
                   LEFT OUTER JOIN storage_byseg as b
                   ON (a.riverseg = b.riverseg)')

#Join baseline scenario data onto demand scenario & storage data 
metric_data <- sqldf('SELECT a.*, b.l30_Qout_base, b.l90_Qout_base
                   FROM metric_data as a
                   LEFT JOIN baseline_data as b
                   ON (a.riverseg = b.riverseg)')

#Join cumulative demand to storage data for inclusion in tables 
storage_data <- sqldf('SELECT a.*, b.wd_cumulative_mgd
                   FROM storage_data as a
                   LEFT OUTER JOIN metric_data as b
                   ON (a.riverseg = b.riverseg)')

```

```{r Link Upstream Impoundments, echo = FALSE, message=FALSE, warning=FALSE}
#Empty columns that will hold storage
metric_data$SminL30mg_apx_ups <- NA 
metric_data$SminL90mg_apx_ups <- NA 
metric_data$SminL30mg_nex_ups <- NA 
metric_data$SminL90mg_nex_ups <- NA 

metric_data$SminL30mg_apx_total <- NA 
metric_data$SminL90mg_apx_total <- NA 
metric_data$SminL30mg_nex_total <- NA 
metric_data$SminL90mg_nex_total <- NA 

#Replace NA data with 0s. We need to do this prior to calculating upstream
#storage since any value minus NA is NA in R, which would mess with our
#calculation of cumulative storage below
metric_data[is.na(metric_data)] <- 0 #replace NA values with 0

#For each modeled watershed, find the upstream storage associated with it:
for (i in 1:nrow(metric_data)) {
  #Easy print message to check progress
  print(paste0("Running seg number ",i,": ",metric_data$riverseg[i]))
  ups_imp <- data.frame()
  #We want to find upstream segments for each riverseg but we are not interested
  #in tidal basins or tidally influenced rivers.
  if(!grepl("0000_0000",metric_data$riverseg[i])){
     #Get upstream segments only for riverseg[i] in metric_data
     ups_imp <- fn_extract_basin(rsegs,metric_data$riverseg[i])
  }else{
    #Skip tiday, bay, and SR ends segments
    print(paste0("Skipping segment ",metric_data$riverseg[i]," as it is tidal or  end segment"))
  }
  
  #If upstream segments were returned, find associated storage from storage_byseg
  if (nrow(ups_imp) > 0) {
    ups_impsegs <- data.frame(rivseg = ups_imp$riverseg)
    ups_df <- sqldf("select a.*
                    from storage_byseg as a
                    where riverseg in (select rivseg from ups_impsegs)") #get the upstream impoundments 
    metric_data$SminL30mg_apx_ups[i] <- sum(ups_df$SminL30mg_apx_local) - metric_data$SminL30mg_apx_local[i]
    metric_data$SminL90mg_apx_ups[i] <- sum(ups_df$SminL90mg_apx_local) - metric_data$SminL90mg_apx_local[i]
    metric_data$SminL30mg_nex_ups[i] <- sum(ups_df$SminL30mg_nex_local) - metric_data$SminL30mg_nex_local[i]
    metric_data$SminL90mg_nex_ups[i] <- sum(ups_df$SminL90mg_nex_local) - metric_data$SminL90mg_nex_local[i]
  }
  #add upstream and local storage to get total storage, which will be used in WA equation 
  metric_data$SminL30mg_apx_total[i] <- metric_data$SminL30mg_apx_local[i] + metric_data$SminL30mg_apx_ups[i]
  metric_data$SminL90mg_apx_total[i] <- metric_data$SminL90mg_apx_local[i] + metric_data$SminL90mg_apx_ups[i]
  metric_data$SminL30mg_nex_total[i] <- metric_data$SminL30mg_nex_local[i] + metric_data$SminL30mg_nex_ups[i]
  metric_data$SminL90mg_nex_total[i] <- metric_data$SminL90mg_nex_local[i] + metric_data$SminL90mg_nex_ups[i]
}
```

```{r Calculate Water Availability, echo = FALSE, message=FALSE, warning=FALSE}

## Reminder: Perform unit conversions when plugging values into WA equation 
# mgd = cfs / 1.547


#4 total WA values: L30 and L90 for each approx and near exact storage 
metric_data$WA_mgd_30_apx = round((metric_data$l30_Qout_dem / 1.547) - 
  mif_coef*(metric_data$l30_Qout_base / 1.547) + 
  (metric_data$SminL30mg_apx_total / 30), digits = 3)

metric_data$WA_mgd_90_apx = round((metric_data$l90_Qout_dem / 1.547) - 
  mif_coef*(metric_data$l90_Qout_base / 1.547) + 
  (metric_data$SminL30mg_apx_total / 90), digits = 3)

metric_data$WA_mgd_30_nex = round((metric_data$l30_Qout_dem / 1.547) - 
  mif_coef*(metric_data$l30_Qout_base / 1.547) + 
  (metric_data$SminL30mg_nex_total / 30), digits = 3)

metric_data$WA_mgd_90_nex = round((metric_data$l90_Qout_dem / 1.547) - 
  mif_coef*(metric_data$l90_Qout_base / 1.547) + 
  (metric_data$SminL90mg_nex_total / 90), digits = 3)


```

```{r Add Qavailable to DataFrame, echo = FALSE}
#add Qavailable for each L30 and L90 to the metric dataframe 
# Qavailable = Qdemand - MIF*Qbaseline
metric_data$Qavailable_30_cfs <- round((metric_data$l30_Qout_dem - mif_coef*metric_data$l30_Qout_base), digits = 3)
metric_data$Qavailable_90_cfs <- round((metric_data$l90_Qout_dem - mif_coef*metric_data$l90_Qout_base), digits = 3)


```

```{r Smin Comparison Check, echo=FALSE, message=FALSE}
#for highlighting rows which current Smin comparison method is flawed 
#highlight when TRUE and/or 0 accompanies values that are not equal 
storage_data$unequal_30 <- NA
storage_data$unequal_90 <- NA

for (i in 1:nrow(storage_data)) {
  if (storage_data$SminL30mg_apx[i] != storage_data$SminL30mg_nex[i]) { #if values don't match
    if (storage_data$min_in_pd30[i] == TRUE) { #but we're saying the values occur at the same time 
      storage_data$unequal_30[i] <- TRUE
    }
    if (storage_data$outside_pd30[i] == 0) {
      storage_data$unequal_30[i] <- TRUE
    } 
  }
  
  if (storage_data$SminL90mg_apx[i] != storage_data$SminL90mg_nex[i]) { #if values don't match
    if (storage_data$min_in_pd90[i] == TRUE) { #but we're saying the values occur at the same time 
      storage_data$unequal_90[i] <- TRUE
    }
    if (storage_data$outside_pd90[i] == 0) {
      storage_data$unequal_90[i] <- TRUE
    } 
  } 
}

```


```{r Processing for Case Study Wsheds, echo=FALSE}
caseStudies_df <- data.frame()

for (i in 1:length(outlet_list)) {
  caseStudyRow <- storage_data[grep(outlet_list[i], storage_data$riverseg), ]
  caseStudies_df <- rbind(caseStudies_df, caseStudyRow)
}

#add special case for Carvins Cove 
  #carvins is a headwater, so we need to pull upstream segments from one seg downstream from carvins 

#get upstream segments
for (i in 1:nrow(caseStudies_df)) { 
  if (!caseStudies_df$riverseg[i] %in% c("OR3_7740_8271_carvins")) { #don't do normal upstream process for carvins cove 
    ups_segs <- fn_extract_basin(metric_data, caseStudies_df$riverseg[i])
  if (nrow(ups_segs) > 0) {
  }
  
  } else { #carvins special case
    ds_seg_carv <- fn_downstream(caseStudies_df$riverseg[i], metric_data$riverseg) #get 1 segment downstream from carvins 
    ups_segs <- fn_extract_basin(metric_data, ds_seg_carv) #get upstream segments from that downstream seg 
  }
  ups_segs <- rbind(ups_segs[nrow(ups_segs),],ups_segs[1:(nrow(ups_segs)-1),]) #move last row to top (outlet) to have df ordered downstream to upstream 
  ups_segs <- ups_segs[nrow(ups_segs):1,]#reverse order to get upstream to downstream
  ups_segs <- ups_segs[!duplicated(ups_segs), ] #remove duplicate rows
  assign(paste0('ups_df_', i), ups_segs)
}

#get downstream segments
ds_df <- data.frame() 

#get 3 segments downstream of each case study segment
for (i in 1:nrow(caseStudies_df)) { 
  ds_seg1 <- fn_downstream(caseStudies_df$riverseg[i], metric_data$riverseg)
  ds_segs <- c(ds_seg1)
  if (ds_seg1 != 'NA') {
    ds_seg2 <- fn_downstream(ds_seg1, metric_data$riverseg)
    ds_segs <- c(ds_seg1, ds_seg2)
  }
  if (ds_seg2 != 'NA') {
    ds_seg3 <- fn_downstream(ds_seg2, metric_data$riverseg)
    ds_segs <- c(ds_seg1, ds_seg2, ds_seg3)
  }
  ds_df <- metric_data[metric_data$riverseg %in% ds_segs,]
  ds_df <- ds_df[!duplicated(ds_df), ]
  
  #order df 
  ds_df$riverseg <- factor(ds_df$riverseg, levels=ds_segs) 
  ds_df <- ds_df[order(ds_df$riverseg),]
  
  #remove last row for Lake Manassas to end above Occoquan reservoir
  if (caseStudies_df$riverseg[i] == "PL0_5141_5140") {
    ds_df <- ds_df[1:(nrow(ds_df)-1),] #remove last row 
  }
  
  #remove last 2 rows for Carvins Cove to end just below Roanoke
  if (caseStudies_df$riverseg[i] == "OR3_7740_8271_carvins") {
    ds_df <- ds_df[1:(nrow(ds_df)-2),] #remove last row 
  }
  
  assign(paste0('ds_df_', i), ds_df)
}

#combine upstream and downstream dataframes
for (i in 1:nrow(caseStudies_df)) { 
  assign(paste0('ups_ds_df_', i), rbind(get(paste0('ups_df_', i)), get(paste0('ds_df_', i))))
}
```

<!---BLOCK_LANDSCAPE_START--->

# Water Availability Equation:
## WA_cpl = Qdemand_cpl - MIF*Qbase_cpl + Smin_cpl/CPL
### Where CPL = critical period length 


# Table 1:Water Availability Equation Breakdown

```{r Table 1, echo=FALSE, message=FALSE, warning=FALSE, out.width='100%'}
title_table_WA <- paste0('TABLE 1: WATER AVAILABILITY EQN BREAKDOWN. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

#select all segments that have storage locally or upstream (total storage)
#ensure we check both SminL30 and 90
df_WA <- sqldf("SELECT a.* 
               FROM metric_data as a 
               WHERE Sminl30mg_apx_total IS NOT 0
               OR Sminl90mg_apx_total IS NOT 0")

df_WA$WA_apx_sum <- df_WA$WA_mgd_30_apx + df_WA$WA_mgd_90_apx #sum WA for ordering purposes 

df_WA <- sqldf("SELECT a.* FROM df_WA as a 
                       ORDER BY (a.WA_apx_sum)") #order df with lowest WA at the top 

table_WA <- data.frame(Propname = df_WA$propname,
                     Riverseg = df_WA$riverseg,
                     wd_cu_mgd = round(df_WA$wd_cumulative_mgd, digits = 3),
                     ps_cu_mgd = round(df_WA$ps_cumulative_mgd, digits = 3),
                     l30_Qout = round(df_WA$l30_Qout_dem, digits = 3),
                     l30_Qout_base = round(df_WA$l30_Qout_base, digits = 3),
                     l30_Qout_mif = round((df_WA$l30_Qout_base*mif_coef), digits = 3),
                     Qavailable_30_cfs = df_WA$Qavailable_30_cfs,
                     l90_Qout = round(df_WA$l90_Qout_dem, digits = 3),
                     l90_Qout_base = round(df_WA$l90_Qout_base, digits = 3),
                     l90_Qout_mif = round((df_WA$l90_Qout_base*mif_coef), digits = 3),
                     Qavailable_90_cfs = df_WA$Qavailable_90_cfs,
                     SminL30mg_apx_total = df_WA$SminL30mg_apx_total,
                     SminL30mg_nex_total = df_WA$SminL30mg_nex_total,
                     SminL90mg_apx_total = df_WA$SminL90mg_apx_total,
                     SminL90mg_nex_total = df_WA$SminL90mg_nex_total,
                     WA_mgd_30_apx = df_WA$WA_mgd_30_apx,
                     WA_mgd_30_nex = df_WA$WA_mgd_30_nex,
                     WA_mgd_90_apx = df_WA$WA_mgd_90_apx,
                     WA_mgd_90_nex = df_WA$WA_mgd_90_nex)

ftable_WA <- flextable(table_WA) #create flextable
ftable_WA <- add_header_lines(ftable_WA, values= title_table_WA) #add title 

ftable_WA
```


# Table 2: Smin Method Comparison

```{r Table 2, echo=FALSE, message=FALSE, warning=FALSE, out.width='100%'}
title_table_Storage <- paste0('TABLE 2: SMIN METHOD COMPARISON. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

#sort table by the sum of 2 values
storage_data[is.na(storage_data)] <- 0 #replace NA values with 0
storage_data$outside_sum <- abs(storage_data$outside_pd30) + abs(storage_data$outside_pd90)
storage_data <- sqldf("SELECT a.* FROM storage_data as a 
                       ORDER BY (a.outside_sum) desc")

table_Storage <- data.frame(Propname = storage_data$propname,
                     Riverseg = storage_data$riverseg,
                     SminL30mg_apx = storage_data$SminL30mg_apx,
                     SminL30mg_nex = storage_data$SminL30mg_nex,
                     SminL90mg_apx = storage_data$SminL90mg_apx,
                     SminL90mg_nex = storage_data$SminL90mg_nex,
                     min_in_pd30 = storage_data$min_in_pd30,
                     min_in_pd90 = storage_data$min_in_pd90,
                     outside_pd30 = storage_data$outside_pd30,
                     outside_pd90 = storage_data$outside_pd90)

ftable_Storage <- flextable(table_Storage) #create flextable
ftable_Storage <- add_header_lines(ftable_Storage, values= title_table_Storage) #add title 

#to highlight when method is flawed
rownums30 <- which(storage_data$unequal_30 == TRUE, arr.ind = TRUE) #get rows
rownums90 <- which(storage_data$unequal_90 == TRUE, arr.ind = TRUE) 
rownums <- c(rownums30, rownums90)

ftable_Storage <- flextable::bg(ftable_Storage, i = rownums , bg = "yellow") #add row highlight

ftable_Storage
```

# Table 3: Smin Method Discrepancies

```{r Table 3, echo=FALSE, message=FALSE, warning=FALSE, out.width='100%'}
title_table_Smin <- paste0('TABLE 3: SMIN DISCREPANCIES. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

#add % differences
storage_data$pctDiff30 <- round((100.0 * (storage_data$SminL30mg_apx - storage_data$SminL30mg_nex) / storage_data$SminL30mg_nex), digits = 2)
storage_data$pctDiff90 <- round((100.0 * (storage_data$SminL90mg_apx - storage_data$SminL90mg_nex) / storage_data$SminL90mg_nex), digits = 2)

table_Smin <- data.frame(Propname = storage_data$propname,
                     Riverseg = storage_data$riverseg,
                     SminL30mg_apx = storage_data$SminL30mg_apx,
                     SminL30mg_nex = storage_data$SminL30mg_nex,
                     SminL90mg_apx = storage_data$SminL90mg_apx,
                     SminL90mg_nex = storage_data$SminL90mg_nex,
                     apx_lessthan_nex_30 = storage_data$apx_lessthan_nex_30,
                     apx_lessthan_nex_90 = storage_data$apx_lessthan_nex_90,
                     pctDiff30 = storage_data$pctDiff30,
                     pctDiff90 = storage_data$pctDiff90)

#order table with rows of interest at the top 
table_Smin <- sqldf("SELECT a.* FROM table_Smin as a 
                       ORDER BY (a.apx_lessthan_nex_30)") 

table_Smin <- sqldf("SELECT a.* FROM table_Smin as a 
                       ORDER BY (a.apx_lessthan_nex_90)") 


ftable_Smin <- flextable(table_Smin) #create flextable

#to highlight when approx is not <= near-exact
rownums30 <- which(table_Smin$apx_lessthan_nex_30 == FALSE, arr.ind = TRUE) #get rows
rownums90 <- which(table_Smin$apx_lessthan_nex_90 == FALSE, arr.ind = TRUE)
rownums <- c(rownums30, rownums90)

ftable_Smin <- flextable::bg(ftable_Smin, i = rownums , bg = "yellow") #add row highlight
ftable_Smin <- add_header_lines(ftable_Smin, values= title_table_Smin) #add title 

ftable_Smin
```

# Table 4: Smins that Need to be Updated

```{r Table 4, echo=FALSE, message=FALSE, warning=FALSE, out.width='100%'}

title_table_update <- paste0('TABLE 4: SMINS NEEDING UPDATE. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

#select rows where vahydro and calculated approx Smins are different 
df_update <- sqldf("SELECT a.* 
                    FROM storage_data as a 
                    WHERE Sminl30mg_apx IS NOT Sminl30mg_vah
                    OR Sminl90mg_apx IS NOT Sminl90mg_vah")

table_update <- data.frame(Propname = df_update$propname,
                     Riverseg = df_update$riverseg,
                     SminL30mg_vah = df_update$SminL30mg_vah,
                     SminL30mg_apx = df_update$SminL30mg_apx,
                     SminL90mg_vah= df_update$SminL90mg_vah,
                     SminL90mg_apx = df_update$SminL90mg_apx)

ftable_update <- flextable(table_update) #create flextable
ftable_update <- add_header_lines(ftable_update, values= title_table_update) #add title 

ftable_update
```

# Table 5: Case Studies 

```{r Table 5, echo=FALSE, message=FALSE, warning=FALSE, out.width='100%'}
title_table_caseStudies <- paste0('TABLE 5: CASE STUDIES. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

table_caseStudies <- data.frame(Propname = caseStudies_df$propname,
                     Riverseg = caseStudies_df$riverseg,
                     SminL30mg_apx = caseStudies_df$SminL30mg_apx,
                     SminL30mg_nex = caseStudies_df$SminL30mg_nex,
                     SminL90mg_apx = caseStudies_df$SminL90mg_apx,
                     SminL90mg_nex = caseStudies_df$SminL90mg_nex,
                     outside_pd30 = caseStudies_df$outside_pd30,
                     outside_pd90 = caseStudies_df$outside_pd90)

ftable_caseStudies <- flextable(table_caseStudies) #create flextable
ftable_caseStudies <- add_header_lines(ftable_caseStudies, values= title_table_caseStudies) #add title 

ftable_caseStudies
```

# Table(s) 6: Case Study Watersheds

```{r Table 6, echo=FALSE, message=FALSE, warning=FALSE, out.width='100%'}
#separate flextables for each case study with case study rseg in header 
for (i in 1:nrow(caseStudies_df)) { 
  title_table_caseStudyWshed <- paste0('TABLE 6: CASE STUDY WATERSHEDS. Demand: ', 
                                       demand_scenario, ', Baseline: ', baseline_scenario, 
                                       ', MIF: ', mif_coef, ', Case Study: ', outlet_list)
  csws_df <- get(paste0('ups_ds_df_', i))
  csws_df <- csws_df[!duplicated(csws_df), ]#remove duplicate rows
  table_caseStudyWshed <-   data.frame(Propname = csws_df$propname,
                      Riverseg = csws_df$riverseg,
                      wd_cu_mgd = round(csws_df$wd_cumulative_mgd, digits = 3),
                      ps_cu_mgd = round(csws_df$ps_cumulative_mgd, digits = 3),
                      l30_Qout = round(csws_df$l30_Qout_dem, digits = 3),
                      l30_Qout_base = round(csws_df$l30_Qout_base, digits = 3),
                      l30_Qout_mif = round((csws_df$l30_Qout_base*mif_coef), digits = 3),
                      Qavailable_30_cfs = csws_df$Qavailable_30_cfs,
                      l90_Qout = round(csws_df$l90_Qout_dem, digits = 3),
                      l90_Qout_base = round(csws_df$l90_Qout_base, digits = 3),
                      l90_Qout_mif = round((csws_df$l90_Qout_base*mif_coef), digits = 3),
                      Qavailable_90_cfs = csws_df$Qavailable_90_cfs,
                      SminL30mg_local = csws_df$SminL30mg_apx_local,
                      SminL30mg_upstream = csws_df$SminL30mg_apx_ups,
                      SminL30mg_total = csws_df$SminL30mg_apx_total,
                      SminL90mg_local = csws_df$SminL90mg_apx_local,
                      SminL90mg_upstream = csws_df$SminL90mg_apx_ups,
                      SminL90mg_total = csws_df$SminL90mg_apx_total,
                      WA_mgd_30 = csws_df$WA_mgd_30_apx,
                      WA_mgd_90 = csws_df$WA_mgd_90_apx)
  
  ftable_csws <- flextable(table_caseStudyWshed)
  ftable_csws <- add_header_lines(ftable_csws, values= title_table_caseStudyWshed) #add title 
  assign(paste0('ftable_caseStudyWshed_', caseStudies_df$riverseg[i]), ftable_csws)
  print(get(paste0('ftable_caseStudyWshed_', caseStudies_df$riverseg[i])))
  write.csv(table_caseStudyWshed, paste0(export_path, 
                                         'CaseStudies_table6.', i, '_CaseStudyWshed_', 
                                         table_caseStudies$Riverseg[i], '_', 
                                         demand_scenario, '_', baseline_scenario, 
                                         '_', mif_coef, '.csv')) #write table
  flextable::save_as_image(ftable_csws, path = paste0(export_path, 
                                                      'CaseStudies_table6.', i, '_CaseStudyWsheds_',
                                                      table_caseStudies$Riverseg[i], '_',
                                                      demand_scenario, '_', baseline_scenario,
                                                      '_', mif_coef, '.png')) #save image of flextable
}


```

# Plot 1: Demand Flow vs Available Flow for L30

```{r Create Plot(s) 1, echo=FALSE}
#plot30_filename <- character()

for (i in 1:nrow(caseStudies_df)) {
  
  #get case study name for titling 
  caseStudyName <- gsub('[0-9]+', '', caseStudies_df$propname[i])
  caseStudyName <- gsub('[[:punct:] ]+', ' ', caseStudyName)
  caseStudyName <- gsub('Impoundment', '', caseStudyName)
  
  #l30 graph
  plot30 <- ggplot(data = get(paste0('ups_ds_df_',i)), aes(x=riverseg)) +
    geom_bar(aes(y=l30_Qout_dem, fill = 'blue'), stat = 'identity') +
    geom_bar(aes(y=Qavailable_30_cfs, fill = 'green'), stat = 'identity') +
    theme(axis.text.x = element_text(size = 10, angle = 45, vjust = 1.0, hjust=1)) + #rotate x-axis labels
    theme(axis.title.x=element_blank()) +
    ylab('cfs') + 
    scale_fill_manual(name = "Legend", 
                      label = c("L30", "Qavailable"), 
                      values = c("blue","green")) +
    ggtitle(paste0('Qdemand vs Qavailable (L30) for ', caseStudies_df$riverseg[i], ': ', caseStudyName),
            subtitle = 'Qavailable = Qdemand - MIF*Qbaseline') 

  plot30
  
  assign(paste0('plot30_', i), plot30, envir = globalenv())
  
    # plot30_filename[i] <- paste0(export_path, 'WAcaseStudies_plot1.30_',i, '.png')
    # ggsave(
    #   filename = plot30_filename[i],
    #   plot = plot30,
    #   width = 25,
    #   height = 20)
}

# knitr::include_graphics(plot30_filename)
plot30_1
plot30_2
plot30_3
plot30_4
plot30_5
plot30_6
```


```{r Mapping}
#map case study watersheds
for (i in 1:nrow(caseStudies_df)) {

  rsegs_df <- get(paste0('ups_ds_df_', i))
  
  #join rseg geometry data 
  
  if(!"geom" %in% colnames(rsegs_df)) { #check for geom column first 
    rsegs_df <- sqldf('SELECT a.*, b.geom
                       FROM rsegs_df as a
                       LEFT JOIN rsegs_geom_data as b
                       ON (a.riverseg = b.riverseg)')
  }

  rsegs_df <- sf::st_as_sf(rsegs_df, wkt=fn_geoCol(rsegs_df), crs=4326) #convert to sf
  
  #create bbox
  sf_use_s2(FALSE) # switch off Spherical geometry
  bbox <- st_buffer(st_as_sfc(st_bbox(rsegs_df)), .02) #slightly past basin
  bbox <- st_bbox(bbox)
  
  #nhd <- nhdplusTools::plot_nhdplus(bbox = bbox, actually_plot = FALSE)
  
  map <- ggplot(rsegs_df) + geom_sf(mapping = aes(fill = WA_mgd_30_apx)) +
    scale_fill_gradient(low = "red", high = "green")
  # + geom_sf(data = nhd$flowline, inherit.aes = FALSE)

  assign(paste0('map', i), map, envir = globalenv())
}

plot(map1)
plot(map2)
plot(map3)
plot(map4)
plot(map5)
plot(map6)
```







<!---BLOCK_LANDSCAPE_STOP--->

```{r Write Tables as CSVs, echo=FALSE}

write.csv(table_WA, paste0(export_path, 'CaseStudies_table1_WaterAvailabilityEqn_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 

write.csv(table_Storage, paste0(export_path, 'CaseStudies_table2_SminCompare_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 

write.csv(table_Smin, paste0(export_path, 'CaseStudies_table3_SminError_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 

write.csv(table_update, paste0(export_path, 'CaseStudies_table4_SminUpdate_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 

write.csv(table_caseStudies, paste0(export_path, 'CaseStudies_table5_CaseStudies_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 

```

```{r Save Tables as Images, echo=FALSE}
flextable::save_as_image(ftable_WA, path = paste0(export_path, 'CaseStudies_table1_WaterAvailabilityEqn_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table1

flextable::save_as_image(ftable_Storage, path = paste0(export_path, 'CaseStudies_table2_SminCompare_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table2

flextable::save_as_image(ftable_Smin, path = paste0(export_path, 'CaseStudies_table3_SminError_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table3

flextable::save_as_image(ftable_update, path = paste0(export_path, 'CaseStudies_table4_SminUpdate_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table4

flextable::save_as_image(ftable_caseStudies, path = paste0(export_path, 'CaseStudies_table5_CaseStudies_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table5
```

```{r tab.cap="", tab.id=""}

```


