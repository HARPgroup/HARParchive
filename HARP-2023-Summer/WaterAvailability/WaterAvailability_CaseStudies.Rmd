---
date: "`r Sys.Date()`"
author: "Glenn Campagna"
title: "Water Availability Case Studies"
output: 
  officedown::rdocx_document:
    mapstyles:
      
      Normal: ['First Paragraph']
params: 
  caseStudy_list: ["PL0_5141_5140", "JU3_6900_6950", "JA5_7480_0001", "YP2_6390_6330", "OR3_7740_8271_carvins", "PU3_4451_4450", "NR6_8500_7820"]
  outlet_list: ["PL3_5360_5250", "JU4_7000_7300", "JA5_7480_0001", "YP3_6670_6720", "OR3_7740_8271", "PU4_3970_3890", "NR6_8050_8051"]
  demand_scenario: ["runid_11"] 
  baseline_scenario: ["runid_0"] 
  mif_coef: [0.9]
  write_Qavailable: FALSE
  write_tables: ["local", "github"]
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.cap = TRUE) #set chunk options

library(data.table)
library(hydrotools)
library(sqldf)
library(flextable)
library(officedown)
library(officer)
library(jsonlite)
library(ggplot2)
library(IHA)
library(nhdplusTools)
library(arcpullr)
library(ggrepel)

basepath='/var/www/R'
source('/var/www/R/config.R') 
ds <- RomDataSource$new(site, rest_uname)
ds$get_token(rest_pw)

github_base_uri <- "https://raw.githubusercontent.com/HARPgroup"
github_uri <- paste0(github_base_uri, "/HARParchive/master")
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fn_download_read.R"),local = TRUE)
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fns_spatial.R"),local = TRUE) #load functions for dealing with spatial data
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fn_mapgen.R")) #load mapping function
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fn_labelprep.R")) #load labeling function
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fn_nhd_labs.R")) #load nhd label function
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Config/mapstyle_config.R")) #load general mapping aesthetics 
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fn_get_memo_nhdplus.R")) #nhd caching

options(scipen = 999) #disable scientific notation

#assign params
for(i in 1:length(params)){
  assign(names(params[i]), params[[i]])
}

#get numeric element of demand scenario runid to use in fn_get_runfile
runid_dem = as.numeric(gsub(".*?([0-9]+).*", "\\1", demand_scenario))   

#flextable default formatting
set_flextable_defaults(
  font.size = 8, background.color = "white", 
  na_str = "NA", nan_str = "NA", #padding = 1, 
  table.layout = 'fixed', tabcolsep = 1.5,
  fonts_ignore = T, big.mark = "", decimal.mark= ".") #fonts_ignore applies when knitting as pdf 

#document formatting (came with template)
fp <- fp_par(
  text.align = "center", 
  padding.bottom = 20, padding.top = 120, 
  border.bottom = fp_border())

ft <- fp_text(shading.color='#EFEFEF', bold = TRUE)
```


\newpage

## Table of contents

<!---BLOCK_TOC--->

## List of tables

<!---BLOCK_TOC{seq_id: 'tab'}--->

## List of figures

<!---BLOCK_TOC{seq_id: 'fig'}--->


\newpage

## Sections

<!---BLOCK_MULTICOL_START--->
Column1
`r run_columnbreak()` 
Column2
<!---BLOCK_MULTICOL_STOP{widths: [3,3], space: 0.2, sep: true}--->

# Water Availability Case Studies 


```{r Pull Data}
#Get all riversegments for reference
rsegs <- ds$auth_read(uri = paste0(site,"/vahydro_riversegs_nogeom_export")) 
                      
#Only care about the river segment ids, we won't need the rest of the file.
#We will only use those rsegs that follow the standard format vahydrosw_wshed_XXX_XXXX_XXXX_X
#First, find only those riversegments that begin with vahydrosw_wshed followed by
#"_somecharacters_4 digits_4 digits_anything else"
rsegs <- rsegs$hydrocode[grepl("^vahydrosw_wshed_.+_[0-9]{4}_[0-9]{4}.*$",rsegs$hydrocode)]
#Now, make a data frame of just the NHDPlus ID e.g. remove the vahydrosw_wshed_. We 
#have to create at least two columns in this dataset for use in fn_extract_basin()
rsegs <- data.frame(riverseg = gsub("vahydrosw_wshed_","",rsegs),
                    blankColumn = NA)

#Find all river segments that are not tidal outlets i.e. not JL7_0000_0000
rsegs_noTidalOutlet <- rsegs[grepl(".+_.*[1-9]+.*_.*",rsegs$riverseg),]

#Get storage metrics 
df_storage <- data.frame(
  'model_version' = c('vahydro-1.0', 'vahydro-1.0'),
  'runid' = c(demand_scenario, demand_scenario),
  'metric' = c('Smin_L30_mg', 'Smin_L90_mg'),
  'runlabel' = c('SminL30mg_vah','SminL90mg_vah')
)
storage_data <- om_vahydro_metric_grid(
  metric = metric, runids = df_storage, bundle = 'all', ftype = "all",
  base_url = paste(site,'entity-model-prop-level-export',sep="/"),
  ds = ds
)

#Get demand scenario metrics used in WA eqn
df_metrics <- data.frame(
  'model_version' = c('vahydro-1.0', 'vahydro-1.0', 'vahydro-1.0', 'vahydro-1.0'),
  'runid' = c(demand_scenario, demand_scenario, demand_scenario, demand_scenario),
  'metric' = c('wd_cumulative_mgd', 'ps_cumulative_mgd', 'l30_Qout', 'l90_Qout'),
  'runlabel' = c('wd_cumulative_mgd','ps_cumulative_mgd', 'l30_Qout_dem', 'l90_Qout_dem')
)
metric_data <- om_vahydro_metric_grid(
  metric = metric, runids = df_metrics, bundle = 'all', ftype = "all",
  base_url = paste(site,'entity-model-prop-level-export',sep="/"),
  ds = ds
)

#Get baseline scenario metrics for WA eqn
df_baseline <- data.frame(
  'model_version' = c('vahydro-1.0', 'vahydro-1.0'),
  'runid' = c(baseline_scenario, baseline_scenario),
  'metric' = c('l90_Qout', 'l30_Qout'),
  'runlabel' = c('l90_Qout_base', 'l30_Qout_base')
)
baseline_data <- om_vahydro_metric_grid(
  metric = metric, runids = df_baseline, bundle = 'all', ftype = "all",
  base_url = paste(site,'entity-model-prop-level-export',sep="/"),
  ds = ds
)

#Get riversegs with geometry for mapping 
rsegs_geom_data <- fn_download_read(url=paste(site,"/vahydro_riversegs_export",sep=""), filetype="csv", zip=FALSE)
rsegs_geom_data$riverseg <- gsub(pattern="vahydrosw_wshed_", replacement="", rsegs_geom_data$hydrocode)
rsegs_geom_data <- rsegs_geom_data[ rsegs_geom_data[,fn_geoCol(rsegs_geom_data)]!="" & !is.na(rsegs_geom_data[,fn_geoCol(rsegs_geom_data)]) ,] #finds geom column & omits rsegs with blank or NA geometry
```

```{r Join Metric Data to Full Segment List}
metric_data <- merge(x = metric_data, y = rsegs, 
                           by.x="riverseg", by.y="riverseg", all=T) #results in 701 rows
#merge() used for full joins in Dataframe_Generator.Rmd
```

```{r Get Object Model, Class & Elid}
#nrow_all <- nrow(storage_data)

storage_data$object_class <- NA
storage_data$elid <- NA

for (i in 1:nrow(storage_data)) {
    #Get model
  model <- RomProperty$new(ds,list( 
    featureid = storage_data$featureid[i],
    propcode = 'vahydro-1.0',
    entity_type = 'dh_feature'
  ),TRUE)
  
  #Get object class
  object_class <- RomProperty$new(ds,list( #get vahydro-1.0 model feature from vahydro
    featureid = model$pid,
    propname = 'object_class'
  ),TRUE)
  storage_data$object_class[i] <- object_class$propcode

  #Get element id
  elid <- RomProperty$new(ds,list( 
    featureid = model$pid,
    propname = 'om_element_connection'
  ),TRUE)
  storage_data$elid[i] <- elid$propvalue
}

## Alternative model retrieval, takes much longer
  # #Get model info using ds$auth_read to authenticate and grab model info+data
  # obj_url <- paste(json_obj_url, model$pid, sep="/")
  # model_info <- ds$auth_read(obj_url,  "text/json", "")
  # model_info <- fromJSON(model_info)
  # elid <- model_info[[1]]$om_element_connection$value
  # object_class <- model_info[[1]]$object_class
  # storage_data$object_class[i] <- object_class

```

```{r Smin Calculations}
storage_data$SminL30mg_nex <- NA #empty columns to hold near exact storage values
storage_data$SminL90mg_nex <- NA
storage_data$SminL30mg_apx <- NA
storage_data$SminL90mg_apx <- NA
storage_data$min_in_pd30 <- NA #empty columns to hold TRUE/FALSE
storage_data$min_in_pd90 <- NA 
storage_data$outside_pd30 <- NA #empty columns to hold numeric values
storage_data$outside_pd90 <- NA 
storage_data$imp_off <- NA

for (i in 1:nrow(storage_data)) {
  #Get runfile with timeseries data from VAhydro
  dat <- fn_get_runfile(storage_data$elid[i], runid_dem, site= omsite,  cached = TRUE) #get timeseries data (zoo)
  mode(dat) <- 'numeric'
  cols <- names(dat)
  
  #Trim runfile
  syear = as.integer(min(dat$year))
  eyear = as.integer(max(dat$year))
  if (syear < (eyear - 2)) {
    sdate <- as.POSIXct(paste0(syear,"-10-01"))
    edate <- as.POSIXct(paste0(eyear,"-09-30"))
  } else {
    sdate <- as.POSIXct(paste0(syear,"-02-01"))
    edate <- as.POSIXct(paste0(eyear,"-12-31"))
  }
  dat <- window(dat, start = sdate, end = edate);
  mode(dat) <- 'numeric' 
  

  #Check if impoundment is active
    #2 ways this is done: im_off and imp_enabled 
    #imp_off used in waterSupplyModelNode and hydroImpoundment
    #imp_enabled used in waterSupplyElement
  
  #Separate tests for imp_off and imp_enabled 
  if (storage_data$object_class[i] == "hydroImpoundment" | storage_data$object_class[i] == "waterSupplyModelNode") {
    imp_off = 0 #default to active impoundment
    if ("imp_off" %in% cols) {
      imp_off <- as.integer(median(dat$imp_off))
    }
    storage_data$imp_off[i] <- imp_off
    #Message if impoundment is enabled or not 
    if (imp_off == 0) {
      paste0('imp_off = ', imp_off, ' : Impoundment Enabled')
    } else  if (imp_off == 1) {
      (paste0('imp_off = ', imp_off, ' : Impoundment Disabled'))
    }
    
  } else if (storage_data$object_class[i] == "waterSupplyElement") {
    # does this have an impoundment sub-comp and is imp_off = 0?
  # check for local_impoundment, and if so, rename to impoundment for processing
    if("local_impoundment" %in% cols) {
      dat$impoundment_use_remain_mg <- dat$local_impoundment_use_remain_mg
      dat$impoundment_max_usable <- dat$local_impoundment_max_usable
      dat$impoundment_Qin <- dat$local_impoundment_Qin
      dat$impoundment_Qout <- dat$local_impoundment_Qout
      dat$impoundment_demand <- dat$local_impoundment_demand
      dat$impoundment <- dat$local_impoundment
      cols <- names(dat)
    }
    imp_enabled = FALSE
    if("impoundment" %in% cols) {
      imp_enabled = TRUE
    }
    
    if (imp_enabled == TRUE) {
      storage_data$imp_off[i] <- 0 #Add imp_off val to dataframe based on imp_enabled 
      paste0('imp_enabled = ', imp_enabled, ' : Impoundment Enabled')
    } else if (imp_enabled == FALSE ) {
      storage_data$imp_off[i] <- 1 #Add imp_off val to dataframe based on imp_enabled 
      paste0('imp_enabled = ', imp_enabled, ' : Impoundment Disabled')
    }
  }
  
  #### Only do Storage calculation if impoundment is active
  if (storage_data$imp_off[i] == 0) {
 
    #Different names for storage and Q values based on object_class:
    if (storage_data$object_class[i] == "hydroImpoundment") { #from hydroImpoundment.R: colname = "Storage"
      #storage col already named "Storage"
      Qcol <- "Qin" #from hydroImpoundment.R: flows <- zoo(dat$Qin, order.by = index(dat));
    } else if (storage_data$object_class[i] == "waterSupplyModelNode") {
      dat$Storage <- dat$impoundment_Storage #from waterSupplyModelNode.R: colname = "impoundment_Storage"  
      Qcol <- "Qout" #from waterSupplyModelNode.R: flows <- zoo(as.numeric(as.character( dat$Qout )), order.by = index(dat));
      
   } else if (storage_data$object_class[i] == "waterSupplyElement") {

     # Storage col could be a couple different names
     if("local_impoundment_Storage" %in% cols) {
       storagecol <- "local_impoundment_Storage"
     }
     if("impoundment_Storage" %in% cols) {
       storagecol <- "impoundment_Storage"
     }
     dat$Storage <- dat[,storagecol]
     if ('Qintake' %in% cols) {
       Qcol <- "Qintake"
     } else { #from waterSupplyElement.R: flows <- zoo(as.numeric(as.character( dat$Qintake )), order.by = index(dat));
       Qcol <- "Qin" #no Qintake in at least 1 case, use Qin instead
     }
      
    } else { #object_class is something else
      dat$Storage <- dat$impoundment_Storage
      Qcol <- "Qout" #Qout is the default
    }
     
    #find l30 and l90 years based on Qcol
    flows <- zoo(dat[,Qcol], order.by = index(dat)); 
    loflows <- group2(flows, year = 'calendar') #vahydro Smin metrics used calendar year method 
    
    l90 <- loflows["90 Day Min"];
    ndx <- which.min(as.numeric(l90[,"90 Day Min"]));
    l90_Qout <- round(loflows[ndx,]$`90 Day Min`,6);
    l90_year <- loflows[ndx,]$`year`;
    l90yr_start <- as.POSIXct(paste0(l90_year,"-01-01")) #start of l90 year
    l90yr_end <- as.POSIXct(paste0(l90_year,"-12-31")) #end of l90 year
    datpd_90yr <- window( #data for the l90 year
      dat,
      start = l90yr_start,
      end = l90yr_end
    )
    
    l30 <- loflows["30 Day Min"];
    ndx <- which.min(as.numeric(l30[,"30 Day Min"]));
    l30_Qout <- round(loflows[ndx,]$`30 Day Min`,6);
    l30_year <- loflows[ndx,]$`year`;
    l30yr_start <- as.POSIXct(paste0(l30_year,"-01-01"))
    l30yr_end <- as.POSIXct(paste0(l30_year,"-12-31"))
    datpd_30yr <- window(
      dat,
      start = l30yr_start,
      end = l30yr_end
    )
  
    #data for the low flow years
    l30yr_df <- as.data.frame(datpd_30yr)
    l90yr_df <- as.data.frame(datpd_90yr)
    
    #zoo of Qcol for each l30 and l90 years
    l30yr_flowz <- window(flows, start = l30yr_start, end = l30yr_end)
    l90yr_flowz <- window(flows, start = l90yr_start, end = l90yr_end)
    
    #zoo to data frame
    l30yr_flows <- data.frame(Q = l30yr_flowz)
    l90yr_flows <- data.frame(Q = l90yr_flowz)
    
    #use rolling mean to identify each low-flow period
    rollmean30 = rollmean(l30yr_flows, k=30, fill=NA, align='left') #results in matrix/array
    rollmean90 = rollmean(l90yr_flows, k=90, fill=NA, align='left')
    
    l30yr_flows$rollmean30 <- rollmean30[,1]
    l90yr_flows$rollmean90 <- rollmean90[,1]
    
    #start row numbers for low flow periods
    rownum_start30 <- which.min(l30yr_flows$rollmean30) #min rolling mean since we used a left alignment
    rownum_start90 <- which.min(l90yr_flows$rollmean90) 
    
    #end row numbers for low flow periods
    rownum_end30 <- rownum_start30 + 29
    rownum_end90 <- rownum_start90 + 89
    
    #start  and end dates for low flow periods
    l30pd_start <- as.POSIXct(row.names(l30yr_flows[rownum_start30, ]))
    l90pd_start <- as.POSIXct(row.names(l90yr_flows[rownum_start90, ]))
    l30pd_end <- as.POSIXct(row.names(l30yr_df[rownum_end30, ]))
    l90pd_end <- as.POSIXct(row.names(l90yr_df[rownum_end90, ]))
    
    #zoos for the drought periods 
    l30pd_flowz <- window(dat, start = l30pd_start, end = l30pd_end)
    l90pd_flowz <- window(dat, start = l90pd_start, end = l90pd_end)
    
    #data for low flow periods
    l30pd_df <- as.data.frame(l30pd_flowz)
    l90pd_df <- as.data.frame(l90pd_flowz)
    
    #Near-Exact Smin 
      #Lowest storage within the low flow periods 
      #Storage needs to be converted from acre-feet to million gallons
    storage_data$SminL30mg_nex[i] <- round((min(l30pd_df$Storage) / 3.069), digits = 3)
    storage_data$SminL90mg_nex[i] <- round((min(l90pd_df$Storage) / 3.069), digits = 3)
    
    #Approximate Smin 
      #Lowest storage within the low flow years 
      #Storage needs to be converted from acre-feet to million gallons
    storage_data$SminL30mg_apx[i] <- round((min(l30yr_df$Storage) / 3.069), digits = 3)
    storage_data$SminL90mg_apx[i] <- round((min(l90yr_df$Storage) / 3.069), digits = 3)
    
    #get row numbers where near-exact Smin happens within low flow period 
    rownum_nex30 <- which.min(l30pd_df$Storage) 
    rownum_nex90 <- which.min(l90pd_df$Storage)

    #get row numbers where near-exact Smin happens within low flow year 
    rownum_nex30yr <- rownum_start30 + rownum_nex30 - 1
    rownum_nex90yr <- rownum_start90 + rownum_nex90 - 1

    #get row numbers where approx Smin happens within low flow year 
    rownum_apx30 <- which.min(l30yr_df$Storage) 
    rownum_apx90 <- which.min(l90yr_df$Storage)
    
    #test if values occur in the same place
    match30 <- (as.numeric(rownum_nex30yr) == as.numeric(rownum_apx30))
    match90 <- (as.numeric(rownum_nex90yr) == as.numeric(rownum_apx90))
    
    #add TRUE/FALSE to dataframe
    storage_data$min_in_pd30[i] <- paste0(match30)
    storage_data$min_in_pd90[i] <- paste0(match90)
    
    # If approx. and near-exact values are different: 
    # How far outside the low-flow period does the approximate value occur?
      ## Negative: near-exact Smin happens AFTER the approx. Smin 
      ## Positive: near-exact Smin happens BEFORE the approx. Smin 
    if (storage_data$min_in_pd30[i] == FALSE) {
      storage_data$outside_pd30[i] = rownum_apx30 - rownum_nex30yr
    }
    if (storage_data$min_in_pd90[i] == FALSE) {
      storage_data$outside_pd90[i] = rownum_apx90 - rownum_nex90yr
    }
    
  }
}

#when a min value is repeated, ex. 100s across all storage vals, our method is flawed
  #this causes FALSEs and # of days to show up where we should have TRUE and 0 days 
#COB: This is interesting. In theory, we could have an identical minimum value occur in 
  #two different parts of the year. It's pretty unlikely, but possible. Theoretically, we
  #could capture this by looking at the difference between e.g. rownum_nex90yr - rownum_apx90
  #We should see that this falls within 90 days, I think
storage_data[is.na(storage_data)] <- 0 #replace NA values with 0

for (i in 1:nrow(storage_data)) {
  if (storage_data$SminL30mg_apx[i] == storage_data$SminL30mg_nex[i]) {
    storage_data$min_in_pd30[i] <- TRUE
    storage_data$outside_pd30[i] <- 0  
  } 
      
  if (storage_data$SminL90mg_apx[i] == storage_data$SminL90mg_nex[i]) {
    storage_data$min_in_pd90[i] <- TRUE
    storage_data$outside_pd90[i] <- 0
  }
}

```

```{r Smin Method Comparison}
#Compare approx and near exact Smin values. Approx should always be <= near exact 
storage_data$apx_lessthan_nex_30 <- storage_data$SminL30mg_apx <= storage_data$SminL30mg_nex
storage_data$apx_lessthan_nex_90 <- storage_data$SminL90mg_apx <= storage_data$SminL90mg_nex
  
```

```{r Sum Storage by Riverseg}
#Approximate Smin Values 

#Sum approx SminL30 by riverseg
storage_byseg_30_apx <- sqldf("SELECT storage_data.riverseg, storage_data.SminL30mg_apx,
                       SUM(SminL30mg_apx) AS SminL30mg_apx_local
                       FROM storage_data
                       GROUP BY riverseg
                       ")

#Sum qpprox SminL90 by riverseg
storage_byseg_90_apx <- sqldf("SELECT storage_data.riverseg, storage_data.SminL90mg_apx,
                       SUM(SminL90mg_apx) AS SminL90mg_apx_local
                       FROM storage_data
                       GROUP BY riverseg
                       ")

#Join approx SminL30 and SminL90 summed storage
storage_byseg_apx <- sqldf("SELECT a.riverseg, a.SminL30mg_apx_local, b.SminL90mg_apx_local
                              FROM storage_byseg_30_apx AS a
                              LEFT OUTER JOIN storage_byseg_90_apx AS b
                              WHERE (a. riverseg = b.riverseg) ")


#Near-exact Smin Values 

#Sum near-exact SminL30 by riverseg
storage_byseg_30_nex <- sqldf("SELECT storage_data.riverseg, storage_data.SminL30mg_nex,
                       SUM(SminL30mg_nex) AS SminL30mg_nex_local
                       FROM storage_data
                       GROUP BY riverseg
                       ")

# #Sum near-exact SminL90 by riverseg
storage_byseg_90_nex <- sqldf("SELECT storage_data.riverseg, storage_data.SminL90mg_nex,
                       SUM(SminL90mg_nex) AS SminL90mg_nex_local
                       FROM storage_data
                       GROUP BY riverseg
                       ")

#Join near-exact SminL30 and SminL90 summed storage
storage_byseg_nex <- sqldf("SELECT a.riverseg, a.SminL30mg_nex_local, b.SminL90mg_nex_local
                              FROM storage_byseg_30_nex AS a
                              LEFT OUTER JOIN storage_byseg_90_nex AS b
                              WHERE (a. riverseg = b.riverseg) ")

#Join Approx and Near-exact Smin values by riverseg
storage_byseg <- sqldf("SELECT a.*,  b.SminL30mg_nex_local, b.SminL90mg_nex_local
                              FROM storage_byseg_apx AS a
                              LEFT OUTER JOIN storage_byseg_nex AS b
                              WHERE (a. riverseg = b.riverseg) ")
```

```{r Join Storage + Metric + Baseline Data}
#Storage data by riverseg in storage_byseg 
#Metric data by riverseg in metric_data 

#Join storage data onto demand scenario metric data 
metric_data <- sqldf('SELECT a.*, b.SminL30mg_apx_local, b.SminL90mg_apx_local, b.SminL30mg_nex_local, b.SminL90mg_nex_local
                   FROM metric_data as a
                   LEFT OUTER JOIN storage_byseg as b
                   ON (a.riverseg = b.riverseg)')

#Join baseline scenario data onto demand scenario & storage data 
metric_data <- sqldf('SELECT a.*, b.l30_Qout_base, b.l90_Qout_base
                   FROM metric_data as a
                   LEFT JOIN baseline_data as b
                   ON (a.riverseg = b.riverseg)')

#Join cumulative demand to storage data for inclusion in tables 
storage_data <- sqldf('SELECT a.*, b.wd_cumulative_mgd
                   FROM storage_data as a
                   LEFT OUTER JOIN metric_data as b
                   ON (a.riverseg = b.riverseg)')

```

```{r Link Upstream Storage}
#Empty columns that will hold storage
metric_data$SminL30mg_apx_ups <- NA 
metric_data$SminL90mg_apx_ups <- NA 
metric_data$SminL30mg_nex_ups <- NA 
metric_data$SminL90mg_nex_ups <- NA 

metric_data$SminL30mg_apx_total <- NA 
metric_data$SminL90mg_apx_total <- NA 
metric_data$SminL30mg_nex_total <- NA 
metric_data$SminL90mg_nex_total <- NA 

#Replace NA data with 0s. We need to do this prior to calculating upstream
#storage since any value minus NA is NA in R, which would mess with our
#calculation of cumulative storage below
metric_data[is.na(metric_data)] <- 0 #replace NA values with 0

#For each modeled watershed, find the upstream storage associated with it:
for (i in 1:nrow(metric_data)) {
  #Easy print message to check progress
  print(paste0("Running seg number ",i,": ",metric_data$riverseg[i]))
  ups_imp <- data.frame()
  #We want to find upstream segments for each riverseg but we are not interested
  #in tidal basins or tidally influenced rivers.
  if(!grepl("0000_0000",metric_data$riverseg[i])){
     #Get upstream segments only for riverseg[i] in metric_data
     ups_imp <- fn_extract_basin(metric_data,metric_data$riverseg[i])
  }else{
    #Skip tiday, bay, and SR ends segments
    print(paste0("Skipping segment ",metric_data$riverseg[i]," as it is tidal or  end segment"))
  }
  
  #If upstream segments were returned, find associated storage from storage_byseg
  if (nrow(ups_imp) > 0) {
    ups_impsegs <- data.frame(rivseg = ups_imp$riverseg)
    ups_df <- sqldf("select a.*
                    from storage_byseg as a
                    where riverseg in (select rivseg from ups_impsegs)") #get the upstream impoundments 
    metric_data$SminL30mg_apx_ups[i] <- sum(ups_df$SminL30mg_apx_local) - metric_data$SminL30mg_apx_local[i]
    metric_data$SminL90mg_apx_ups[i] <- sum(ups_df$SminL90mg_apx_local) - metric_data$SminL90mg_apx_local[i]
    metric_data$SminL30mg_nex_ups[i] <- sum(ups_df$SminL30mg_nex_local) - metric_data$SminL30mg_nex_local[i]
    metric_data$SminL90mg_nex_ups[i] <- sum(ups_df$SminL90mg_nex_local) - metric_data$SminL90mg_nex_local[i]
  }
  #add upstream and local storage to get total storage, which will be used in WA equation 
  metric_data$SminL30mg_apx_total[i] <- metric_data$SminL30mg_apx_local[i] + metric_data$SminL30mg_apx_ups[i]
  metric_data$SminL90mg_apx_total[i] <- metric_data$SminL90mg_apx_local[i] + metric_data$SminL90mg_apx_ups[i]
  metric_data$SminL30mg_nex_total[i] <- metric_data$SminL30mg_nex_local[i] + metric_data$SminL30mg_nex_ups[i]
  metric_data$SminL90mg_nex_total[i] <- metric_data$SminL90mg_nex_local[i] + metric_data$SminL90mg_nex_ups[i]
}
```

```{r Add Qavailable to DataFrame}
#add Qavailable for each L30 and L90 to the metric dataframe 
# First, need to evaluate the MIF
metric_data$l30_Qout_mif <- mif_coef*metric_data$l30_Qout_base
metric_data$l90_Qout_mif <- mif_coef*metric_data$l90_Qout_base
# Now, calculate Qavailable 
# Qavailable = Qdemand - MIF*Qbaseline
metric_data$Qavailable_30_cfs <- round((metric_data$l30_Qout_dem - metric_data$l30_Qout_mif), digits = 3)
metric_data$Qavailable_90_cfs <- round((metric_data$l90_Qout_dem - metric_data$l90_Qout_mif), digits = 3)
```

```{r Calculate Water Availability}
## Reminder: Perform unit conversions when plugging values into WA equation 
# mgd = cfs / 1.547

#4 total WA values: L30 and L90 for each approx and near exact storage 
metric_data$WA_mgd_30_apx = round((metric_data$l30_Qout_dem / 1.547) - 
  metric_data$Qavailable_30_cfs / 1.547 + 
  (metric_data$SminL30mg_apx_total / 30), digits = 3)

metric_data$WA_mgd_90_apx = round((metric_data$l90_Qout_dem / 1.547) - 
  metric_data$Qavailable_90_cfs / 1.547 + 
  (metric_data$SminL30mg_apx_total / 90), digits = 3)

metric_data$WA_mgd_30_nex = round((metric_data$l30_Qout_dem / 1.547) - 
  metric_data$Qavailable_30_cfs / 1.547 + 
  (metric_data$SminL30mg_nex_total / 30), digits = 3)

metric_data$WA_mgd_90_nex = round((metric_data$l90_Qout_dem / 1.547) - 
  metric_data$Qavailable_90_cfs / 1.547 + 
  (metric_data$SminL90mg_nex_total / 90), digits = 3)

# save all these values to REST
if (write_Qavailable == TRUE) {
  for (i in 1:nrow(metric_data)) {
    model_metrics <- metric_data[i,]
    pid = model_metrics$pid 
    # GETTING SCENARIO PROPERTY FROM VA HYDRO
    sceninfo <- list(
      varkey = 'om_scenario',
      propname = demand_scenario,
      featureid = pid,
      entity_type = "dh_properties",
      bundle = "dh_properties"
    )
    scenprop <- RomProperty$new( ds, sceninfo, TRUE)
    # Warn PROPERTY IF IT IS NOT YET CREATED
    if (is.na(scenprop$pid) | is.null(scenprop$pid) ) {
      message("Cannot find run data for ",model_metrics$propname, "scenario", demand_scenario )
    }
  
  # Post l30 available
  vahydro_post_metric_to_scenprop(scenprop$pid, 'om_class_Constant', NULL, 'Qavailable_30_mgd', model_metrics$Qavailable_30_cfs / 1.547, ds)
  vahydro_post_metric_to_scenprop(scenprop$pid, 'om_class_Constant', NULL, 'Qavailable_90_mgd', model_metrics$Qavailable_90_cfs / 1.547, ds)
  
  }
  
}

```

```{r Smin Comparison Check}
#for highlighting rows which current Smin comparison method is flawed 
#highlight when TRUE and/or 0 accompanies values that are not equal 
storage_data$unequal_30 <- NA
storage_data$unequal_90 <- NA

for (i in 1:nrow(storage_data)) {
  if (storage_data$SminL30mg_apx[i] != storage_data$SminL30mg_nex[i]) { #if values don't match
    if (storage_data$min_in_pd30[i] == TRUE) { #but we're saying the values occur at the same time 
      storage_data$unequal_30[i] <- TRUE
    }
    if (storage_data$outside_pd30[i] == 0) {
      storage_data$unequal_30[i] <- TRUE
    } 
  }
  
  if (storage_data$SminL90mg_apx[i] != storage_data$SminL90mg_nex[i]) { #if values don't match
    if (storage_data$min_in_pd90[i] == TRUE) { #but we're saying the values occur at the same time 
      storage_data$unequal_90[i] <- TRUE
    }
    if (storage_data$outside_pd90[i] == 0) {
      storage_data$unequal_90[i] <- TRUE
    } 
  } 
}

```

```{r Processing for Case Study Wsheds}
#Create datafrane with case study segments 
caseStudies_df <- data.frame()

for (i in 1:length(caseStudy_list)) {
  caseStudyRow <- storage_data[grep(caseStudy_list[i], storage_data$riverseg), ]
  caseStudies_df <- rbind(caseStudies_df, caseStudyRow)
}

#Create dataframes for case study watersheds (upstream from eaxh of outlet_list)
for (i in 1:length(outlet_list)) {
  ups_data <- fn_extract_basin(metric_data, outlet_list[i])
  assign(paste0('ups_ds_df_', i), ups_data)
}

```

<!---BLOCK_LANDSCAPE_START--->

# Water Availability Equation:
## Generalized form:

Generalized Equation: $WA_{CPL} = Q_{LCPLdem} - (PoF * Q_{LCPLbase}) + S_{minCPL}/CPL$ ; Where:
* $CPL$ = critical period length, such as 30 days, 90 days, 7 days, etc.
* $WA_{CPL}$ = mean rate of available water remaining during critical period
* $Q_{LCPLdem}$ = L90 simulated for a given demand scenario 
* $Q_{LCPLbase})$ = The L90 simulated in the zero demand scenario (with the same meteorology).
* $S_{minCPL}$ = minimum storage simulated during the L90 period in the demand scenario.
* $PoF$ = % of flow that must remain in stream
* Note: $(PoF * Q_{LCPLbase})$ could be rewritted as $Q_{mif}$, where $Q_{mif}$ = minimum instream flow (if mif is NOT a PoF, and is knowable in a single period mean numeric form)

## Abbreviated Form:
## WA_cpl = Qdemand_cpl - MIF*Qbase_cpl + Smin_cpl/CPL
### Where CPL = critical period length 


# Table 1: Water Availability Equation Breakdown

```{r Table 1, out.width='100%'}
title_table_WA <- paste0('TABLE 1: WATER AVAILABILITY EQN BREAKDOWN. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

#select all segments that have storage locally or upstream (total storage)
#ensure we check both SminL30 and 90
df_WA <- sqldf("SELECT a.* 
               FROM metric_data as a 
               WHERE Sminl30mg_apx_total IS NOT 0
               OR Sminl90mg_apx_total IS NOT 0")

df_WA$WA_apx_sum <- df_WA$WA_mgd_30_apx + df_WA$WA_mgd_90_apx #sum WA for ordering purposes 

df_WA <- sqldf("SELECT a.* FROM df_WA as a 
                       ORDER BY (a.WA_apx_sum)") #order df with lowest WA at the top 

table_WA <- data.frame(Propname = df_WA$propname,
                     Riverseg = df_WA$riverseg,
                     wd_cu_mgd = round(df_WA$wd_cumulative_mgd, digits = 2),
                     ps_cu_mgd = round(df_WA$ps_cumulative_mgd, digits = 2),
                     l30_Qout = round(df_WA$l30_Qout_dem, digits = 1),
                     l30_Qout_base = round(df_WA$l30_Qout_base, digits = 1),
                     l30_Qout_mif = round((df_WA$l30_Qout_mif), digits = 1),
                     Qavailable_30_cfs = df_WA$Qavailable_30_cfs,
                     l90_Qout = round(df_WA$l90_Qout_dem, digits = 1),
                     l90_Qout_base = round(df_WA$l90_Qout_base, digits = 1),
                     l90_Qout_mif = round((df_WA$l90_Qout_mif), digits = 1),
                     Qavailable_90_cfs = df_WA$Qavailable_90_cfs,
                     SminL30mg_apx_total = df_WA$SminL30mg_apx_total,
                     SminL30mg_nex_total = df_WA$SminL30mg_nex_total,
                     SminL90mg_apx_total = df_WA$SminL90mg_apx_total,
                     SminL90mg_nex_total = df_WA$SminL90mg_nex_total,
                     WA_mgd_30_apx = df_WA$WA_mgd_30_apx,
                     WA_mgd_30_nex = df_WA$WA_mgd_30_nex,
                     WA_mgd_90_apx = df_WA$WA_mgd_90_apx,
                     WA_mgd_90_nex = df_WA$WA_mgd_90_nex)

ftable_WA <- flextable(table_WA) #create flextable
ftable_WA <- add_header_lines(ftable_WA, values= title_table_WA) #add title 

ftable_WA
```


# Table 2: Smin Method Comparison

```{r Table 2, out.width='100%'}
title_table_Storage <- paste0('TABLE 2: SMIN METHOD COMPARISON. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

#sort table by the sum of 2 values
storage_data[is.na(storage_data)] <- 0 #replace NA values with 0
storage_data$outside_sum <- abs(storage_data$outside_pd30) + abs(storage_data$outside_pd90)
storage_data <- sqldf("SELECT a.* FROM storage_data as a 
                       ORDER BY (a.outside_sum) desc")

table_Storage <- data.frame(Propname = storage_data$propname,
                     Riverseg = storage_data$riverseg,
                     SminL30mg_apx = storage_data$SminL30mg_apx,
                     SminL30mg_nex = storage_data$SminL30mg_nex,
                     SminL90mg_apx = storage_data$SminL90mg_apx,
                     SminL90mg_nex = storage_data$SminL90mg_nex,
                     min_in_pd30 = storage_data$min_in_pd30,
                     min_in_pd90 = storage_data$min_in_pd90,
                     outside_pd30 = storage_data$outside_pd30,
                     outside_pd90 = storage_data$outside_pd90)

ftable_Storage <- flextable(table_Storage) #create flextable
ftable_Storage <- add_header_lines(ftable_Storage, values= title_table_Storage) #add title 

#to highlight when method is flawed
rownums30 <- which(storage_data$unequal_30 == TRUE, arr.ind = TRUE) #get rows
rownums90 <- which(storage_data$unequal_90 == TRUE, arr.ind = TRUE) 
rownums <- c(rownums30, rownums90)

ftable_Storage <- flextable::bg(ftable_Storage, i = rownums , bg = "yellow") #add row highlight

ftable_Storage
```

# Table 3: Smin Method Discrepancies

```{r Table 3, out.width='100%'}
title_table_Smin <- paste0('TABLE 3: SMIN DISCREPANCIES. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

#add % differences
storage_data$pctDiff30 <- round((100.0 * (storage_data$SminL30mg_apx - storage_data$SminL30mg_nex) / storage_data$SminL30mg_nex), digits = 2)
storage_data$pctDiff90 <- round((100.0 * (storage_data$SminL90mg_apx - storage_data$SminL90mg_nex) / storage_data$SminL90mg_nex), digits = 2)

table_Smin <- data.frame(Propname = storage_data$propname,
                     Riverseg = storage_data$riverseg,
                     SminL30mg_apx = storage_data$SminL30mg_apx,
                     SminL30mg_nex = storage_data$SminL30mg_nex,
                     SminL90mg_apx = storage_data$SminL90mg_apx,
                     SminL90mg_nex = storage_data$SminL90mg_nex,
                     apx_lessthan_nex_30 = storage_data$apx_lessthan_nex_30,
                     apx_lessthan_nex_90 = storage_data$apx_lessthan_nex_90,
                     pctDiff30 = storage_data$pctDiff30,
                     pctDiff90 = storage_data$pctDiff90)

#order table with rows of interest at the top 
table_Smin <- sqldf("SELECT a.* FROM table_Smin as a 
                       ORDER BY (a.apx_lessthan_nex_30)") 

table_Smin <- sqldf("SELECT a.* FROM table_Smin as a 
                       ORDER BY (a.apx_lessthan_nex_90)") 


ftable_Smin <- flextable(table_Smin) #create flextable

#to highlight when approx is not <= near-exact
rownums30 <- which(table_Smin$apx_lessthan_nex_30 == FALSE, arr.ind = TRUE) #get rows
rownums90 <- which(table_Smin$apx_lessthan_nex_90 == FALSE, arr.ind = TRUE)
rownums <- c(rownums30, rownums90)

ftable_Smin <- flextable::bg(ftable_Smin, i = rownums , bg = "yellow") #add row highlight
ftable_Smin <- add_header_lines(ftable_Smin, values= title_table_Smin) #add title 

ftable_Smin
```

# Table 4: Smins that Need to be Updated

```{r Table 4, out.width='100%'}

title_table_update <- paste0('TABLE 4: SMINS NEEDING UPDATE. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

#select rows where vahydro and calculated approx Smins are different 
df_update <- sqldf("SELECT a.* 
                    FROM storage_data as a 
                    WHERE Sminl30mg_apx IS NOT Sminl30mg_vah
                    OR Sminl90mg_apx IS NOT Sminl90mg_vah")

table_update <- data.frame(Propname = df_update$propname,
                     Riverseg = df_update$riverseg,
                     SminL30mg_vah = df_update$SminL30mg_vah,
                     SminL30mg_apx = df_update$SminL30mg_apx,
                     SminL90mg_vah= df_update$SminL90mg_vah,
                     SminL90mg_apx = df_update$SminL90mg_apx)

ftable_update <- flextable(table_update) #create flextable
ftable_update <- add_header_lines(ftable_update, values= title_table_update) #add title 

ftable_update
```

# Table 5: Case Studies 

```{r Table 5, out.width='100%'}
title_table_caseStudies <- paste0('TABLE 5: CASE STUDIES. Demand: ', demand_scenario, ', Baseline: ', baseline_scenario, ', MIF: ', mif_coef)

table_caseStudies <- data.frame(Propname = caseStudies_df$propname,
                     Riverseg = caseStudies_df$riverseg,
                     SminL30mg_apx = caseStudies_df$SminL30mg_apx,
                     SminL30mg_nex = caseStudies_df$SminL30mg_nex,
                     SminL90mg_apx = caseStudies_df$SminL90mg_apx,
                     SminL90mg_nex = caseStudies_df$SminL90mg_nex,
                     outside_pd30 = caseStudies_df$outside_pd30,
                     outside_pd90 = caseStudies_df$outside_pd90)

ftable_caseStudies <- flextable(table_caseStudies) #create flextable
ftable_caseStudies <- add_header_lines(ftable_caseStudies, values= title_table_caseStudies) #add title 

ftable_caseStudies
```

# Table(s) 6: Case Study Watersheds

```{r Table 6, out.width='100%'}
#separate flextables for each case study with case study rseg in header 
for (i in 1:length(caseStudy_list)) { 
  title_table_caseStudyWshed <- paste0('TABLE 6: CASE STUDY WATERSHEDS. Demand: ', 
                                       demand_scenario, ', Baseline: ', baseline_scenario, 
                                       ', MIF: ', mif_coef, ', Case Study: ', caseStudy_list)
  csws_df <- get(paste0('ups_ds_df_', i))
  csws_df <- csws_df[!duplicated(csws_df), ]#remove duplicate rows
  table_caseStudyWshed <-   data.frame(Propname = csws_df$propname,
                      Riverseg = csws_df$riverseg,
                      wd_cu_mgd = round(csws_df$wd_cumulative_mgd, digits = 3),
                      ps_cu_mgd = round(csws_df$ps_cumulative_mgd, digits = 3),
                      l30_Qout = round(csws_df$l30_Qout_dem, digits = 3),
                      l30_Qout_base = round(csws_df$l30_Qout_base, digits = 3),
                      l30_Qout_mif = round((csws_df$l30_Qout_mif), digits = 3),
                      Qavailable_30_cfs = csws_df$Qavailable_30_cfs,
                      l90_Qout = round(csws_df$l90_Qout_dem, digits = 3),
                      l90_Qout_base = round(csws_df$l90_Qout_base, digits = 3),
                      l90_Qout_mif = round((csws_df$l90_Qout_mif), digits = 3),
                      Qavailable_90_cfs = csws_df$Qavailable_90_cfs,
                      SminL30mg_local = csws_df$SminL30mg_apx_local,
                      SminL30mg_upstream = csws_df$SminL30mg_apx_ups,
                      SminL30mg_total = csws_df$SminL30mg_apx_total,
                      SminL90mg_local = csws_df$SminL90mg_apx_local,
                      SminL90mg_upstream = csws_df$SminL90mg_apx_ups,
                      SminL90mg_total = csws_df$SminL90mg_apx_total,
                      WA_mgd_30 = csws_df$WA_mgd_30_apx,
                      WA_mgd_90 = csws_df$WA_mgd_90_apx)
  
  ftable_csws <- flextable(table_caseStudyWshed)
  rownum_cs <- which(csws_df$riverseg == caseStudy_list[i]) #highlight case study row
  ftable_csws <- flextable::bg(ftable_csws, i = rownum_cs , bg = "yellow") 
  #ftable_csws <- add_header_lines(ftable_csws, values= title_table_caseStudyWshed) #add title 
  assign(paste0('ftable_caseStudyWshed_', caseStudy_list[i]), ftable_csws)
  print(get(paste0('ftable_caseStudyWshed_', caseStudy_list[i])))
  
  if ("local" %in% write_tables) {
    write.csv(table_caseStudyWshed, paste0(export_path, 
                                           'CaseStudies_table6.', i, '_CaseStudyWshed_', 
                                           table_caseStudies$Riverseg[i], '_', 
                                           demand_scenario, '_', baseline_scenario, 
                                           '_', mif_coef, '.csv')) #write table locally
  }
  
  if ("github" %in% write_tables) {
    write.csv(table_WA, paste0(github_location, '/HARParchive/HARP-2023-Summer/WaterAvailability/CaseStudiesTables/CSVs/CaseStudies_table6.', i, '_CaseStudyWshed_', 
                               table_caseStudies$Riverseg[i], '_', demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) #write table to GitHub
  }
  
  
  flextable::save_as_image(ftable_csws, path = paste0(export_path, 
                                                      'CaseStudies_table6.', i, '_CaseStudyWsheds_',
                                                      table_caseStudies$Riverseg[i], '_',
                                                      demand_scenario, '_', baseline_scenario,
                                                      '_', mif_coef, '.png')) #save image of flextable locally
}


```

# Plot 1: Demand Flow vs Available Flow 
## For L30

```{r Create Plot for L30}
#plot30_filename <- character()

for (i in 1:nrow(caseStudies_df)) {
  
  #get case study name for titling 
  caseStudyName <- gsub('[0-9]+', '', caseStudies_df$propname[i])
  caseStudyName <- gsub('[[:punct:] ]+', ' ', caseStudyName)
  caseStudyName <- gsub('Impoundment', '', caseStudyName)
  
  #l30 graph
  plot30 <- ggplot(data = get(paste0('ups_ds_df_',i)), aes(x=riverseg)) +
    geom_bar(aes(y=l30_Qout_dem, fill = 'blue'), stat = 'identity') +
    geom_bar(aes(y=Qavailable_30_cfs, fill = 'green'), stat = 'identity') +
    theme(axis.text.x = element_text(size = 10, angle = 45, vjust = 1.0, hjust=1)) + #rotate x-axis labels
    theme(axis.title.x=element_blank()) +
    ylab('cfs') + 
    scale_fill_manual(name = "Legend", 
                      label = c("L30", "Qavailable"), 
                      values = c("blue","green")) +
    ggtitle(paste0('Qdemand vs Qavailable (L30) for ', caseStudies_df$riverseg[i], ': ', caseStudyName),
            subtitle = 'Qavailable = Qdemand - MIF*Qbaseline') 

  #plot30
  
  assign(paste0('plot30_', i), plot30, envir = globalenv())
  
    # plot30_filename[i] <- paste0(export_path, 'WAcaseStudies_plot1.30_',i, '.png')
    # ggsave(
    #   filename = plot30_filename[i],
    #   plot = plot30,
    #   width = 25,
    #   height = 20)
}

# knitr::include_graphics(plot30_filename)
```

```{r View L30 Plot}
plot30_1
plot30_2
plot30_3
plot30_4
plot30_5
plot30_6
```


# Map 1: Water Availability Map
## WA for L30

```{r Mapping}
#create spatial object of all rivsersegs to be trimmed
rsegs_all_sf <- sf::st_as_sf(rsegs_geom_data, wkt='geom', crs=4326) #convert to sf

#map case study watersheds
WAmapfilename <- character()
for (i in 1:nrow(caseStudies_df)) {

  rsegs_df <- get(paste0('ups_ds_df_', i))
  
  #custom bins
  div <- c(0,10,50,100,500,1000,10000)
  
  bin_labs <- c(" <= 0", 
                 "0 to 10", 
                 "10 to 50",
                 "50 to 100",
                 "100 to 500",
                 "500 to 1000",
                 " > 1000")
  
  #binning based on water availability
  # binrange <- range(rsegs_df$WA_mgd_30_apx)
  # midbin <- mean(binrange)
  # thirdbin <- midbin + ((binrange[2] - midbin)/2)
  # firstbin <- midbin - ((binrange[2] - midbin)/2)
  
  bins_sql <-  paste("SELECT *,
	                  CASE WHEN WA_mgd_30_apx <= ",div[1]," THEN '1'
		                WHEN WA_mgd_30_apx >  ",div[1]," AND WA_mgd_30_apx <= ",div[2]," THEN '2'
		                WHEN WA_mgd_30_apx >  ",div[2]," AND WA_mgd_30_apx <= ",div[3]," THEN '3'
		                WHEN WA_mgd_30_apx >  ",div[3]," AND WA_mgd_30_apx <= ",div[4]," THEN '4'
		                WHEN WA_mgd_30_apx >  ",div[4]," AND WA_mgd_30_apx <= ",div[5]," THEN '5'
		                WHEN WA_mgd_30_apx >  ",div[5]," AND WA_mgd_30_apx <= ",div[6]," THEN '6'
		                WHEN WA_mgd_30_apx > ",div[6]," THEN '7'
		                ELSE 'X'
		                END AS bin
		                FROM rsegs_df",sep="")
  rsegs_df <-fn_sqldf_sf(bins_sql)  
  
  #join rseg geometry data 
  if(!"geom" %in% colnames(rsegs_df)) { #check for geom column first 
    rsegs_df <- sqldf('SELECT a.*, b.geom
                       FROM rsegs_df as a
                       LEFT JOIN rsegs_geom_data as b
                       ON (a.riverseg = b.riverseg)')
  }

  rsegs_df <- sf::st_as_sf(rsegs_df, wkt=fn_geoCol(rsegs_df), crs=4326) #convert to sf
  rsegs_df <- fn_centroid_coords(rsegs_df) #add centroid coordinates for labeling 
  
  #create bbox around rsegs of interest 
  sf_use_s2(FALSE) # switch off Spherical geometry
  bbox_sfc <- st_buffer(st_as_sfc(st_bbox(rsegs_df)), .02) #slightly past basin
  bbox <- st_bbox(bbox_sfc)
  bbox_points <- data.frame(long = c(bbox[1], bbox[3]), lat = c(bbox[2], bbox[4]))
  rsegs_bbox <- st_filter(rsegs_all_sf, bbox_sfc)
  
  map <- ggplot(rsegs_bbox) + geom_sf() + 
    geom_sf(data = rsegs_df, mapping = aes(fill = as.factor(bin))) +
    scale_fill_manual(values = c("firebrick2","darkorange",
                                 "white", "cadetblue1", "deepskyblue", "dodgerblue3", "blue"),
                      breaks = seq(1:7),
                      labels = bin_labs,
                      limits = as.factor(seq(1:7)),
                      name = "WA for L30 (mgd)") +
    # geom_sf(data = nhd$flowline, 
    #         inherit.aes=FALSE, color= "dodgerblue", 
    #         mapping=aes(lwd=nhd$flowline$StreamOrde), #line thickness based on stream order
    #         show.legend=FALSE) + 
    # scale_linewidth(range= c(0.1,0.5), guide = FALSE) +
    geom_text_repel(data = rsegs_df, aes(x=lng, y=lat, label = riverseg), size = 8) +
    ggtitle(paste0('Water Availability (L30) for ', caseStudies_df$riverseg[i])) +
    theme(plot.title = element_text(size = 30), legend.text = element_text(size = 18), legend.title = element_text(size = 22)) + 
    coord_sf(xlim = bbox_points$long, ylim = bbox_points$lat, expand = FALSE)
  plot(map)
  
  assign(paste0('map', i), map, envir = globalenv())
  
  #save image of map
  WAmapfilename[i] <- paste(export_path, "WAcaseStudiesMap_", caseStudies_df$riverseg[i], ".png", sep="")
  ggsave(
    filename = WAmapfilename[i],
    plot = map,
    width = 25,
    height = 20)
  
}

```

```{r View Maps}
plot(map1)
plot(map2)
plot(map3)
plot(map4)
plot(map5)
plot(map6)
```

```{r Basemap Data Retrieval & Processing for fn_mapgen(), eval=FALSE}
#move these to parameters when working 
map_style <- "custom"
crs_default <- 4326

#Pulling basemap data needed for function 
cnty_fips <- fread("https://raw.githubusercontent.com/HARPgroup/HARParchive/master/HARP-2023-Summer/Mapping/Data/counties_sf.csv")
cnty_regions <- fread('https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/Mapping/Data/Regions_ProposedReg_053122.csv')
roads <- fn_download_read(
    url="https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/Mapping/Data/tl_2022_51_prisecroads.zip", 
    filetype="shp", zip=TRUE) #.shp file for US states & primary roads
cities <- fread('https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/Mapping/Data/USA_Major_Cities_GIS.csv')

##Process basemap data
#counties
cnty_fips$name <- sub(" County", "", cnty_fips$name) # fix any names followed by " County" to match the names of counties in the regions df
colnames(cnty_fips)[colnames(cnty_fips) == 'Region'] <- 'us_region' # rename Region col in base set to prevent conflict
cnty_fips <- sqldf("SELECT a.*, b.VMDWA_Reg2 as Region
                FROM cnty_fips as a
                LEFT OUTER JOIN cnty_regions as b
                WHERE (a.name = b.County)
                ") #add region column to county data; WHERE instead of ON means only counties in regional planning areas are kept
counties <- cnty_fips[grep(51,cnty_fips$dh_fips),] #remove counties outside of VA using the fips code
counties <- sf::st_as_sf(counties, wkt = fn_geoCol(counties), crs=4326) #convert to sf based on geometry column found by fn_geoCol()
#cities
statemt <- paste("SELECT cities.X, cities.Y, cities.NAME, cities.POPULATION,",
                   "CASE WHEN POPULATION BETWEEN",quantile(cities$POPULATION, 0.1),"AND", quantile(cities$POPULATION, 0.5),
                   "THEN 'smallTown' 
                  WHEN POPULATION BETWEEN",quantile(cities$POPULATION, 0.5),"AND",quantile(cities$POPULATION, 0.8),
                   "THEN 'town'
                  WHEN POPULATION BETWEEN",quantile(cities$POPULATION, 0.8),"AND",quantile(cities$POPULATION, 1.0),
                   "THEN 'city'
                  ELSE CLASS", 
                   "END as CLASS",
                   "FROM cities
                  WHERE NAME 
                  NOT IN (select counties.name from counties)",
                   "AND (cities.ST == 'VA') ", 
                   "ORDER BY POPULATION DESC", sep=" ") 
cities <- fn_sqldf_sf(statemt)
#roads
roads <- subset(roads, MTFCC=="S1100" & (RTTYP=="I"|RTTYP=="U"|RTTYP=="S") #primary roads & interstate, US Hwy, or State Rte only
                  & FULLNAME %in% grep("([0-9]+).$", 
                  roads$FULLNAME, 
                  value=TRUE)) #finds where last char is a number (thus omitting names followed by Byp, Alt, etc.)
roads$FULLNAME <- gsub(".* ", "", roads$FULLNAME) #removes text and spaces before route number
names(roads) <- gsub("RTTYP", "CLASS", names(roads)) #re-name class column -> needed for fn_labelprep() in the RMD
#nhd 
nhd  <- memo_plot_nhdplus(bbox = bbox, actually_plot = FALSE)
#regions
regions_split <- split(counties, counties$Region) #creates a list containing a sf data frame per each region, which all contain the county polygons corresponding to that region
for(i in 1:length(regions_split)){ #merge counties into one polygon for each region
  if(i==1){
    regions <- st_union(regions_split[[i]])
  }
  if(i!=1){
    regions <- rbind( regions, st_union(regions_split[[i]]) )
  } #note: had to do this in IF statements instead of resetting regions_split[i] <- regions_split[[i]] because keeping it in list form causes st_union() to put geom into sfg format, which causes problems with st_filter() in the rsegs filtering chunk
}
regions <- sf::st_as_sf(data.frame(region=names(regions_split), geo=regions, row.names=NULL), crs=crs_default)
rm(regions_split)
#Make sure coord systems match 
st_crs(counties) <- crs_default
st_crs(roads) <- crs_default
```

```{r Configure fn_mapgen(), eval=FALSE}
rivseg_pct_vect <- c(-20,-10,-2,2,10,20,500) 
#^last value should be higher than any % difference value expected, since classification is done using <=
rivbreaks <- seq(1:length(rivseg_pct_vect))
rivmap_colors <- c("firebrick2","darkorange","#FFCC99",
                   "white","palegreen","limegreen","green4") #colors for fills 

rivseg_pct_vect <- c(0,10,50,100,500,1000,10000)
rseg_leg_title <- "Water Availability for L30 (mgd)"  
rivmap_labs <- c(" <= 0", 
                "0 to 10", 
                "10 to 50",
                "50 to 100",
                "100 to 500",
                "500 to 1000",
                " > 1000")
```

```{r Labeling for fn_mapgen(), eval=FALSE}
nhdlabs <- fn_nhd_labs(data=nhd)
rm(maplabs)
maplabs <- fn_labelprep(data=list(counties, cities, roads, nhdlabs), classes=c("county","city","road","nhd"))
```

```{r Mapping with fn_mapgen(), eval=FALSE}
#disabled with eval=FALSE until up and running 
source(paste0(github_uri,"/HARP-2023-Summer/Mapping/Functions/fn_mapgen.R")) #load mapping function

div <- rivseg_pct_vect
rsegs_all_sf <- sf::st_as_sf(rsegs_geom_data, wkt='geom', crs=4326) #convert to sf

for (i in 1:nrow(caseStudies_df)) {

  rsegs_df <- get(paste0('ups_ds_df_', i))
  
  #binning based on water availability
  # binrange <- range(rsegs_df$WA_mgd_30_apx)
  # midbin <- mean(binrange)
  # thirdbin <- midbin + ((binrange[2] - midbin)/2)
  # firstbin <- midbin - ((binrange[2] - midbin)/2)
  
  bins_sql <-  paste("SELECT *,
	                  CASE WHEN WA_mgd_30_apx <= ",div[1]," THEN '1'
		                WHEN WA_mgd_30_apx >  ",div[1]," AND WA_mgd_30_apx <= ",div[2]," THEN '2'
		                WHEN WA_mgd_30_apx >  ",div[2]," AND WA_mgd_30_apx <= ",div[3]," THEN '3'
		                WHEN WA_mgd_30_apx >  ",div[3]," AND WA_mgd_30_apx <= ",div[4]," THEN '4'
		                WHEN WA_mgd_30_apx >  ",div[4]," AND WA_mgd_30_apx <= ",div[5]," THEN '5'
		                WHEN WA_mgd_30_apx >  ",div[5]," AND WA_mgd_30_apx <= ",div[6]," THEN '6'
		                WHEN WA_mgd_30_apx > ",div[6]," THEN '7'
		                ELSE 'X'
		                END AS bin
		                FROM rsegs_df",sep="")
  rsegs_df <-fn_sqldf_sf(bins_sql)  
  
  #join rseg geometry data 
  if(!"geom" %in% colnames(rsegs_df)) { #check for geom column first 
    rsegs_df <- sqldf('SELECT a.*, b.geom
                       FROM rsegs_df as a
                       LEFT JOIN rsegs_geom_data as b
                       ON (a.riverseg = b.riverseg)')
  }

  rsegs_df <- sf::st_as_sf(rsegs_df, wkt=fn_geoCol(rsegs_df), crs=4326) #convert to sf
  rsegs_df <- fn_centroid_coords(rsegs_df) #add centroid coordinates for labeling 
  
  #create bbox around rsegs of interest 
  sf_use_s2(FALSE) # switch off Spherical geometry
  bbox_sfc <- st_buffer(st_as_sfc(st_bbox(rsegs_df)), .02) #slightly past basin
  bbox <- st_bbox(bbox_sfc)
  bbox_points <- data.frame(long = c(bbox[1], bbox[3]), lat = c(bbox[2], bbox[4]))
  nhd  <- memo_plot_nhdplus(bbox = bbox, actually_plot = FALSE)
  
  #mp_layer placeholder
  #cols required: lat, long, bin, NUM, 
  mp_layer <- data.frame(NUM = 0, lat = NA, long = NA, bin = "X")
  
  #segs dataframe needs cols "name" and "bundle"
  rsegs_df$name <- rsegs_df$riverseg
  rsegs_df$bundle <- "watershed"
  
  #fn_mapgen <- function(mapnum, featr_type, origin_type, style, metric, origin, bbox, segs, counties, roads,
  #                       nhd, maplabs, mp_layer, metric_unit, maptitle)
  
  #Unsure of: mapnum, featr_type, mp_layer 
  #mapnum: this is closest to map #2
  #featr_type: mapping facilities or sources is not of interest at the moment, but use facilities for placeholder for simplicity
  #mp_layer: ^
  
  map <- fn_mapgen(mapnum = 2, featr_type = "facility", origin_type = "basin",
                   style = styles[[map_style]], metric = "WA_mgd_30_apx", origin = caseStudies_df$riverseg[i],
                   bbox = bbox, segs = rsegs_df, counties = counties, roads = roads, nhd = nhd, maplabs = maplabs, 
                   mp_layer = mp_layer, metric_unit = "mgd", maptitle = "WA for L30")

}
#recent: Error in `scale_linewidth()`:`breaks` and `labels` have different lengths. line ~230


```

<!---BLOCK_LANDSCAPE_STOP--->

```{r Write CSVs Locally}
#Writing locally to location of export_path
if ("local" %in% write_tables) {
  write.csv(table_WA, paste0(export_path, 'CaseStudies_table1_WaterAvailabilityEqn_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 

  write.csv(table_Storage, paste0(export_path, 'CaseStudies_table2_SminCompare_', 
                             demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 
  
  write.csv(table_Smin, paste0(export_path, 'CaseStudies_table3_SminError_', 
                             demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 
  
  write.csv(table_update, paste0(export_path, 'CaseStudies_table4_SminUpdate_', 
                             demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 
  
  write.csv(table_caseStudies, paste0(export_path, 'CaseStudies_table5_CaseStudies_', 
                             demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 

  }

```

```{r Write CSVs to GitHub}
#Writng to github using github_location
if ("github" %in% write_tables) {
  write.csv(table_WA, paste0(github_location, '/HARParchive/HARP-2023-Summer/WaterAvailability/CaseStudiesTables/CSVs/CaseStudies_table1_WaterAvailabilityEqn_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 
  
  write.csv(table_WA, paste0(github_location, '/HARParchive/HARP-2023-Summer/WaterAvailability/CaseStudiesTables/CSVs/CaseStudies_table2_SminCompare_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 
  
  write.csv(table_WA, paste0(github_location, '/HARParchive/HARP-2023-Summer/WaterAvailability/CaseStudiesTables/CSVs/CaseStudies_table3_SminError_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 
  
  write.csv(table_WA, paste0(github_location, '/HARParchive/HARP-2023-Summer/WaterAvailability/CaseStudiesTables/CSVs/CaseStudies_table4_SminUpdate_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 
  
  write.csv(table_WA, paste0(github_location, '/HARParchive/HARP-2023-Summer/WaterAvailability/CaseStudiesTables/CSVs/CaseStudies_table5_CaseStudies_', 
                           demand_scenario, '_', baseline_scenario, '_', mif_coef, '.csv')) 
  
}


### need to implement this for case study watershed tables in the loop
```

```{r Save Tables as Images}
flextable::save_as_image(ftable_WA, path = paste0(export_path, 'CaseStudies_table1_WaterAvailabilityEqn_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table1

flextable::save_as_image(ftable_Storage, path = paste0(export_path, 'CaseStudies_table2_SminCompare_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table2

flextable::save_as_image(ftable_Smin, path = paste0(export_path, 'CaseStudies_table3_SminError_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table3

flextable::save_as_image(ftable_update, path = paste0(export_path, 'CaseStudies_table4_SminUpdate_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table4

flextable::save_as_image(ftable_caseStudies, path = paste0(export_path, 'CaseStudies_table5_CaseStudies_', 
                                                  demand_scenario, '_', baseline_scenario, '_', mif_coef, '.png')) #table5
```

```{r tab.cap="", tab.id=""}

```


