---
title: "Mapping Workflow"
author: "HARP Analysts"
date: "`r Sys.Date()`"
output: html_document
params:
  ## More params used during development and testing for user-control -- will be consolidated  
  rivseg: ["JL6_7430_7320"] #["JL6_7320_7150","JL6_6890_6990","JL6_7430_7320","JA2_7410_7470", "JA4_7280_7340","JB3_6820_7053"] 
  locality: ["Rappahannock"]
  region: ["Shenandoah_2"]    
  type: ["facility"] #either 'source' or 'facility', depending on level of map and table wanted 
  model_version: ["vahydro-1.0"]
  runid_list: [ "runid_11", "runid_13" ] # Use runid_11 and runid_13 in that order for 2020 vs 2040 table, Ignored if metric_type = "measured"
#  runid_data_colnames: [ "runid_11", "runid_13" ] # Use runid_11 and runid_13 in that order for 2020 vs 2040 table, Ignored if metric_type = "measured"
  metric: ["wd_mgd"] # 5-year avg metric called 'fiveyr_avg_mgy' , which is part of foundational data frame
  #metric_type: ["modeled"] #either 'modeled' or 'measured'. Measured metric(s) already in foundational data. Modeled pulls VAhydro 
  map_type: ["region"] #should be one of: basin, locality, or region ; depending on what map type is desired 
  map_by: ["fiveyr_avg_mgy","runid_11_wd_mgd"] #the metric(s) for mapping, which the bubbles & legend will be scaled to. Ex: runid_11_wd_mgd, fiveyr_avg_mgy
  limit: ["boundary"] #either 'basins' or 'boundary', depending if all sources/facils in intersecting basins should be in table, or only points within locality/region boundary. Won't apply to map type basin
  table_col: ["fiveyr_avg_mgy","runid_11_wd_mgd"]
  bbox_type: ["auto"] #either 'auto' or 'vahydro'. vahydro map type only functional for segments 
  ## To to map 5-yr avg use, type can be either facility or source, metric must be fiveyr_avg_mgy, metric type must be measured
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(hydrotools)
library(mgsub)
library(sp)
library(rgeos)
library(sf)
library(nhdplusTools)
library(ggmap)
library(raster)
library(ggplot2)
library(ggnewscale)   
library(ggsn)
library(ggspatial)
library(ggrepel)
library(grid)
library(png)
library(flextable)
library(geosphere)
#library(tidycensus)
basepath='/var/www/R'
source('/var/www/R/config.R')
ds <- RomDataSource$new(site, rest_uname)
ds$get_token(rest_pw)
```

```{r UserInputs, echo=FALSE}
rivseg <- params$rivseg #for mapping extent of basin(s)
locality <- params$locality #for mapping extent of a locality
region <- params$region #for mapping extent of a region 
type <- params$type #for map & table to indicate source-level or facility-level
model_version <- params$model_version
runid_list <- params$runid_list
metric <- params$metric
map_type <- params$map_type
map_by <- params$map_by
limit <- params$limit
table_col <- params$table_col
bbox_type <- params$bbox_type
```

# Get Functions 

```{r Dev Code-libs: Load Functions from Online, echo=FALSE}
## For planners, updated when changes are merged to master
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_mapgen_est.R"),local = FALSE) #load mapping function
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/mapstyle_config.R"),local = FALSE) #load mapping aesthetics
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_tablegen.R"),local = FALSE) #load table function
source(paste0(github_location,"/HARParchive/HARP-2023-Summer/fn_labelprep.R"),local = FALSE) #load labeling function
```

```{r Establish Functions, echo=FALSE}
# Read data that requires file download
download_read <- function(url, filetype, zip) {
  localpath <- tempdir()
  filename <- basename(url)
  filepath <- paste(localpath,"\\", filename, sep="")

  download.file(url, filepath)
  
  if(zip==TRUE){
   folder <- unzip(filepath, exdir=localpath)
   filepath <- grep(".*.csv.*", folder, value=TRUE)
  }
  if(filetype=="csv"){
    df <- read.csv(file=filepath, header=TRUE, sep=",")
  }
  if(filetype=="shp"){
    layer <- gsub("\\.zip", "", filename)
    df <- read_sf(dsn=localpath, layer=layer)
  } 
  if(filetype!="csv" & filetype!="shp"){
    message(paste("Error in download_read(): filetype must be 'csv' or 'shp'"))
  }
  return(df)
}
#- - - - - - - - - - -

# Convert any data frame w/ geometry stored as Well Known Text to "SpatialXxxDataFrame" (Xx_sp)
## Specify the data frame and the character name of the geometry column
process_geom <- function(data, geom_col) {
  for (i in 1:nrow(data)) {
    sp.i <- sp::addAttrToGeom(
      x=readWKT(data[i,geom_col]), 
      y=as.data.frame(as.list(subset(data[i,],select=-c(names(data)==geom_col)))),      
      match.ID=TRUE
    )
    if (i == 1) {
      # start with one 
      data_sp <- sp.i
    } else {
      # append
      data_sp <- rbind(data_sp, sp.i)
    }
  }
  return(data_sp)
}
#- - - - - - - - - - -

# Add centroid coords to a data frame
centroid_coords <- function(data, geom_col) {
  
  #NEW:
  if( length(grep("sfc", lapply(data, class)))==0 ){
    data <- process_geom(data, geom_col)
    data <- st_as_sf(data)
  } #.
  
  for (r in 1:nrow(data)) { #get centroid coord. for labeling
    centroid <- st_centroid(data[r, geom_col])
    centroid <- as.data.frame(st_coordinates(centroid))
    data$lng[r] <- centroid$X
    data$lat[r] <- centroid$Y
  }
  
  #NEW:
  #st_crs(data) <- 4326
  #.
  return(data)
}
#- - - - - - - - - - -

# Generate user-understandable legend titles
## Kept up here as a function so that it's easy to add if-statements when user-input options expand
legend_titling <- function(metric, runid_list){
  if(metric=="wd_mgd"){
    name <- "Withdrawal"
    unit <- "(MGD)"
    legend_title <- runid_list
    year <- mgsub(runid_list, c("runid_11","runid_13"), c("2020","2040"))
  for(i in 1:length(runid_list)){
    legend_title[i] <- paste(year[i],name,unit,sep="\n")
  }
  }
  if(metric=="fiveyr_avg_mgy"){ #this metric isn't associated w a runid
    name <- "5-yr Avg Use"
    unit <- "(MGY)"
    legend_title<- paste(name,unit,sep="\n")
  }
  return(legend_title)
}
```

# Get Foundational Data
```{r Pull Foundational Data w/ github_location, echo=FALSE}
facils <- list() #create empty list to store dfs
# the variable "github_location" should be in config.local and provides easy access to these resources
# Thus, no need to change code here, rather, the user changes their own config.
furl = paste0(github_location, "/Foundational_Data/2023/foundation_dataset_mgy_2018-2022_5ya.csv")
facils$foundatn <- fread(furl) # Foundational sources/MP data
facilities_df <- fread(paste0(github_location, "/Foundational_Data/2023/facilities_all_geom.csv"))
```

# Pull Data 
```{r PULL Data, echo=FALSE, message=FALSE, warning=FALSE}
#----From VAhydro----
#segs$all <- ds$get('dh_feature', config=list(ftype='vahydro',bundle='watershed')) ##gives errors
if (exists("segs")==FALSE) { segs <- list() }

if (!"all" %in% names(segs)) { #will execute loop when segs$all not yet pulled 
  segs$all <- download_read(url=paste(site,"/vahydro_riversegs_export",sep=""), filetype="csv", zip=FALSE) 
  # All vahydro watershed features
} 
# note: potential NULLs for newly carved data
counties <- list() # County Features data
counties$df <- ds$get('dh_feature', config=list(bundle='usafips'))

#----From Public Webpages----
#roads <- download_read(url="https://www2.census.gov/geo/tiger/TIGER2022/PRISECROADS/tl_2022_51_prisecroads.zip", 
#                          filetype="shp", zip=TRUE) # (shp) for US states & primary roads

# --From Github--
roads <- download_read(
  url="https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/tl_2022_51_prisecroads.zip", 
  filetype="shp", zip=TRUE) # (shp) for US states & primary roads
regions <- fread('https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/Regions_ProposedReg_053122.csv') #Retrieving regional planning groups 
cities <- fread('https://github.com/HARPgroup/HARParchive/raw/master/HARP-2023-Summer/USA_Major_Cities_GIS.csv') 
#rivr_maj <- read.csv("https://github.com/HARPgroup/HARParchive/raw/master/GIS_layers/MajorRivers.csv")
```

# Geom Processing
```{r Region Geom Processing, echo=FALSE}
## Processing and combining locality geometries into their regions 
## Columns from vahydro have different names as of 7/10:
names(counties$df)[names(counties$df) == 'dh_geofield.geom'] <- "dh_geofield"
counties_df <- counties$df # for sqldf


regions_geo <- sqldf( #adds geometries from counties df to the regions df
  "SELECT regions.*, counties_df.dh_geofield 
   FROM regions
   left outer join counties_df
   on (regions.county = counties_df.name)
   ")
rm(counties_df)
reg_split <- split(regions_geo, regions_geo$VMDWA_Reg2) #creates a new dataframe for each region containing the county names and geometries 

## Combining the polygon geometries in each region df into 1 polygon for the whole region 
region_geom_list <- list() #create empty list where regional geometries will be stored 
for (i in 1:length(reg_split)) {
  reg_df <- as.data.frame(reg_split[i])
  reg_df <- na.omit(reg_df) #remove rows with NA geometry so loop doesn't fail
  colnames(reg_df) <- c("county","region", "dh_geofield")
  reg_name <- as.character(reg_df[1,2])
  reg_sf <- st_as_sf(reg_df, wkt = "dh_geofield")
  reg_geom_whole <- st_union(reg_sf) #combining locality polygons in the same region into 1 polygon
  region_geom_list[i] <- reg_geom_whole #create list containing all region geoms
  names(region_geom_list)[i] <- as.character(reg_name) #naming according to the region name 
}
```

```{r Facility Geom Processing, echo=FALSE}
## Need to remove facilities without a geometry -- can't be mapped without coords
facilities_df <- facilities_df[-which(facilities_df$dh_geofield == ""), ] #removes approx 125 rows
facilities_sf <- st_as_sf(facilities_df, wkt = "dh_geofield")
coords <- st_coordinates(facilities_sf$dh_geofield)
colnames(coords) <- c("Longitude","Latitude")
facilities_df <- cbind(facilities_df, coords) #add coordinates to facilities df
```

# Process Data

```{r PROCESS Data, echo=FALSE, warning=FALSE, message=FALSE}
#----General data organization----
segs$all$riverseg <- str_replace(segs$all$hydrocode, 'vahydrosw_wshed_', '') #prerequisite for fn_extract_basin()

#modify colnames in foundational df
names(facils$foundatn)[names(facils$foundatn) == 'Source Type'] <- 'Source_Type'
names(facils$foundatn)[names(facils$foundatn) == 'MP Name'] <- 'MP_Name'
names(facils$foundatn)[names(facils$foundatn) == 'Use Type'] <- 'Use_Type'

#----Roads----
# Filter roads to only Interstate, US Hwy, State Rte:
#roads <- st_intersection(roads, roads$state) #only VA primary roads
roads <- subset(roads, MTFCC=="S1100") #primary roads only
## keep only interstate, US hwy, or state Rte:
roads <- subset(roads, RTTYP=="I" | FULLNAME %in% grep("US Hwy.*", roads$FULLNAME, value=TRUE) | RTTYP=="S")
## shorten names to number only; column RTTYP gives classification I, U, or S
roads$FULLNAME <- mgsub(roads$FULLNAME, pattern=c("\\I- ", "US Hwy ", "State Rte "), replacement=c("","",""))
## remove any road followed by Bus, Byp, Alt, etc. by removing any row whose name still has a space
roads <- subset(roads, !(FULLNAME %in% grep(".* .*", roads$FULLNAME, value=TRUE)))
roads <- centroid_coords(roads, "geometry") #add centroid coords

#-----Counties----
# Process counties polygons; text-> spatial -> simple features
counties$sp <- process_geom(counties$df, "dh_geofield")
counties$sf <- st_as_sf(counties$sp)
counties$sf <- centroid_coords(counties$sf, "geometry")
st_crs(counties$sf) <- 4326

#----Cities----
cities <- cities[cities$ST == 'VA',] #VA cities
# Remove city/town names that match their county/locality name
counties_df <- counties$df #needed for sqldf
cities <- sqldf("SELECT cities.* 
                FROM cities 
                WHERE NAME 
                NOT IN (select counties_df.name from counties_df) 
                ")
remove(counties_df) #no longer needed

#cities <- sqldf("SELECT * FROM cities WHERE CLASS is not 'Census Designated Place' ")
#cities <- sqldf("SELECT * FROM cities WHERE POPULATION> '400' ")
cities[cities == "Census Designated Place"] <- "town"# change census designated place to town for mapping
```

```{r, include=FALSE, echo=FALSE}
#Create facility-level foundational data by aggregating source-level data
# aggregate and sum using sqldf:
facils_foundatn <- facils$foundatn
facils_foundatn <- sqldf("select facils_foundatn.*,
                    sum(fiveyr_avg_mgy) as sum
                    from facils_foundatn
                    group by Facility_hydroid") #all source-related data now only applies to 1 source (random) within the facil (coords!)
facils_foundatn <- facils_foundatn[ , !names(facils_foundatn) == 'fiveyr_avg_mgy'] #rm original metric col, from 1 of the sources 
names(facils_foundatn)[names(facils_foundatn) == 'sum'] <- 'fiveyr_avg_mgy' #rename summed metric col
facils_foundatn <- data.frame(Facility_hydroid = facils_foundatn$Facility_hydroid,
                            Facility = facils_foundatn$Facility,
                            Use_Type = facils_foundatn$Use_Type, 
                            `FIPS Code` = facils_foundatn$`FIPS Code`,
                            Locality = facils_foundatn$Locality,
                            fiveyr_avg_mgy = facils_foundatn$fiveyr_avg_mgy)#select cols of interest, not including coordinates which are from sources 
#facils_foundatn <- facils_foundatn[, !duplicated(colnames(facils_foundatn))]
```

# Pull Metrics

```{r (New) Create df for Metric Pull, include=FALSE}
#df without metric_type
## To-do: make this usable with multiple metrics, a list of both modeled and foundational data 
df <- data.frame(runid=runid_list, model_version, metric=metric)
if (type == "facility") {
  if (metric != "fiveyr_avg_mgy"){
    for(i in 1:length(runid_list)){
      df$runlabel[i] <- paste0(runid_list[i], '_', metric)
    } 
  } else { #if 5-yr avg is metric of interest
    df$runlabel <- df$metric
  }
} else { #if type is source
  df$runlabel <- df$metric
}
```


```{r Facility-Level Metric Data, warning=FALSE, message=FALSE, echo=FALSE}
## Processing Facility-level metric & foundational data 
if (type == "facility") {
 if (metric != "fiveyr_avg_mgy") { 
  facil_featr <- om_vahydro_metric_grid( # pulling facilities and the metric of interest
    metric=FALSE, runids=df, featureid='all', 
    entity_type='dh_feature', bundle='facility',
    ftype='all', model_version = model_version,
    base_url = "http://deq1.bse.vt.edu/d.dh/entity-model-prop-level-export",
    ds = ds)
  facil_featr <- sqldf("SELECT * 
                      FROM facil_featr 
                      WHERE hydrocode not like 'wsp_%'")  # Filter out WSP entries
  
  #join facility-level foundational data with model data here: featureid = hydroid
#  facil_modf <- sqldf("SELECT a.*, b.fiveyr_avg_mgy
#                      FROM facil_featr as a
#                      LEFT OUTER JOIN facils_foundatn as b
#                      ON (a.featureid = b.Facility_hydroid)" )
  #result: same length as modeled data frame -> UNION needed for full - unsuccessful 
  
  #try merging instead of sqldf
  names(facils_foundatn)[names(facils_foundatn) == 'Facility_hydroid'] <- 'featureid'
  facil_merge <- merge(facils_foundatn, facil_featr, by = "featureid", all=T)
  facil_modf <- facil_merge[, c("featureid", "Facility", 
                      "Locality", "Use_Type", 
                      "fiveyr_avg_mgy", df$runlabel[1], 
                      df$runlabel[2])] ##don't need all columns
  names(facil_modf)[names(facil_modf) == 'featureid'] <- 'Facility_hydroid'
 #Get facility coordinates -- already in facilities df 
 facils$all <- sqldf("SELECT a.*, b.Longitude, b.Latitude, b. Locality
                      FROM facil_modf as a
                      LEFT OUTER JOIN facilities_df as b
                      ON (a.Facility_hydroid = b.Facility_hydroid)" )
 
 
 } else if (metric =="fiveyr_avg_mgy") {
   #Get facility coordinates
   facil_bind <- sqldf("SELECT a.*, b.Longitude, b.Latitude, b.Locality
                      FROM facils_foundatn as a
                      LEFT OUTER JOIN facilities_df as b
                      ON (a.Facility_hydroid = b.Facility_hydroid)" )
   
  facils$all <- facil_bind
 }
} else { #if type = source
  facils$all <- facils$foundatn
}
```

```{r Riverseg if Needed, echo=FALSE, warning=FALSE, message=FALSE}
## Adding riversegs to data frame when not present using a spatial join
# Note: this is not a totally robust method & will be changed before development is finished 
# first, check if riverseg exists. It will already be in table if model data was pulled & joined 
facils$all <- facils$all[!is.na(facils$all$Longitude),] #remove rows with missing coords for sf creation
facils$all <- facils$all[!is.na(facils$all$Latitude),]

 if (!"riverseg" %in% colnames(facils$all)) { # TRUE when riverseg column not present, will execute loop
  facils$all <- st_as_sf(facils$all, coords = c("Longitude","Latitude"))
  segs_all <- segs$all[-which(segs$all$geom == ""), ] #need to remove rows with empty geometries 
  #segs$sp <- process_geom(segs_all, "geom") #takes several seconds
  segs$sf <- st_as_sf(segs_all, wkt = "geom")
  rm(segs_all)
  #segs$sf <- st_as_sf(segs$sp)
  st_crs(segs$sf) <- 4326
  st_crs(facils$all) <- 4326
  # do spatial join to determine which seg each source/facility is in
  sf_use_s2(FALSE) # switch off Spherical geometry
  spat_join <- st_join(facils$all, segs$sf) #riverseg column added, polygons in col geom
  coords <- st_coordinates(spat_join$geometry)
  colnames(coords) <- c("Longitude","Latitude")
  spat_join <- spat_join[ , !names(spat_join) == "geom"]
  spat_join <- st_drop_geometry(spat_join)
  facils$all <- spat_join
  facils$all <- cbind(facils$all, coords)
  colnames(facils$all) <- gsub("hydrocode", "rseg_hydrocode", colnames(facils$all))
}
```

```{r Filter Segs by Boundary, echo=FALSE}
#Filter segs/basins by boundary 
if (map_type == "basin") { #finding upstream riversegs for basin maps 
  for(i in rivseg){. #newly moved into this loop
    if(i==rivseg[1]){
    segs$basin <- fn_extract_basin(segs$all, i)
    }
    if(i!=rivseg[1]){
    segs$basin <- rbind(segs$basin, fn_extract_basin(segs$all, i))
    }
  }
} else if (map_type =="locality") {
  locality_sf <- counties$sf[counties$sf$name == locality, ] #if REST IS working
  segs_all <- segs$all[-which(segs$all$geom == ""), ] #need to remove rows with empty geometries 
  segs$sf <- st_as_sf(segs_all, wkt = "geom")
  st_crs(segs$sf) <- 4326
  sf_use_s2(FALSE)
  segs$basin <- st_filter(segs$sf, locality_sf) #filter basins by locality
} else if (map_type == "region") {
  region_list <- region_geom_list[names(region_geom_list) == region]
  region_sf <- st_sfc(region_list, crs = 4326) #create sf object from the region specified
  segs$region_sf <- st_as_sf(region_sf, crs = 4326) #for darker outline around region 
  region_sp <- as_Spatial(segs$region_sf, cast = FALSE)
  segs_all <- segs$all[-which(segs$all$geom == ""), ] #need to remove rows with empty geometries 
  segs$sp <- process_geom(segs_all, "geom") #takes a few seconds
  rm(segs_all)
  segs$sf <- st_as_sf(segs$sp, crs = 4326)
  st_crs(region_sf) <- 4326
  st_crs(segs$sf) <- 4326
  sf_use_s2(FALSE)
  segs$basin <- st_filter(segs$sf, region_sf) #filter basins by the region
}
```

```{r Filter Sources/Facils by Segs or Boundary, include=FALSE}
if (limit == "basins") {
  segs_basin <- st_drop_geometry(segs$basin) #will be sf object for locality and region, not usable for sqldf
  segs$basin_sf <- st_as_sf(segs$basin, wkt = "geom")
  st_crs(segs$basin_sf) <- 4326 
  facils_all <- st_drop_geometry(facils$all) #create temporary df for use in sqldf for ordering
  facils_all <- facils_all[,colSums(is.na(facils_all))<nrow(facils_all)]

  facils$within <- sqldf("SELECT facils_all.* 
                          FROM facils_all 
                          WHERE riverseg 
                          IN (select segs_basin.riverseg from segs_basin)") 
} else if (limit=="boundary") {
  facils$sf <- st_as_sf(facils$all, coords = c("Longitude","Latitude"))
  st_crs(facils$sf) <- 4326
  if (map_type=="locality") {
    facils$within <- st_filter(facils$sf, locality_sf)
  } else if (map_type=="region") {
    st_crs(segs$region_sf) <- 4326
    facils$within <- st_filter(facils$sf, segs$region_sf)
  }
}
#need to turn point geom into coords and region after geo drop
coords <- st_coordinates(facils$within$geometry)
colnames(coords) <- c('Longitude','Latitude')
facils$within <- st_drop_geometry(facils$within)
facils$within <- cbind(facils$within, coords)
```

```{r Process Basin Geom & Bbox, warning=FALSE, echo=FALSE}
segs$basin <- segs$basin[!duplicated(segs$basin$riverseg),] # don't duplicate riversegs for overlapping basins
if (map_type == "locality" || map_type == "region") {
   #segs$basin_sp <- process_geom(segs$basin, "geom")
  segs$basin_sf <- st_as_sf(segs$basin, wkt = "geom")
  st_crs(segs$basin_sf) <- 4326 #Set coord. reference syst.
}
segs$basin_sf <- centroid_coords(segs$basin_sf, "geom") # new colnames for centroids: lng, lat
#segs$basin_sp <- process_geom(segs$basin_sf, "geom") #sp object used in mapping
# Create bbox
sf_use_s2(FALSE) # switch off Spherical geometry
if (limit == "basins" | map_type == "basin") {
  bbox <- st_buffer(st_as_sfc(st_bbox(segs$basin_sf)), .02) #slightly past basin
} else if (limit == "boundary" & map_type == "locality") {
  bbox <- st_buffer(st_as_sfc(st_bbox(locality_sf)), .02)
} else if (limit == "boundary" & map_type == "region") {
  bbox <- st_buffer(st_as_sfc(st_bbox(st_as_sf(segs$region_sf))), .02)
}
bbox <- st_bbox(bbox)
```

```{r VAhydro bbox if Desired, include=FALSE}
## Retrieve bbox from vahydro property --- only run if this bbox is desired, otherwise skip 
# only operational for river segments/basins
if (bbox_type == "vahydro") {
  for (i in 1:nrow(segs$basin)) { 
  hid <- segs$basin$hydroid[i] 
  map <- RomProperty$new(ds, list(varkey="map", entity_type="dh_feature",featureid=hid),TRUE)
  extent <- RomProperty$new(ds, list(propname="extent", entity_type="dh_properties",featureid=map$pid),TRUE)
  extent_coords = ds$get_prop(config = list(featureid = extent$pid, entity_type='dh_properties'))
  extent_coords <- extent_coords[c('propname','propvalue')]
  extent_df <- data.frame(X = c(extent_coords[1,2], extent_coords[2,2]), Y = c(extent_coords[3,2], extent_coords[4,2]))
  bbox_ex <- st_buffer(st_as_sf(extent_df, coords = c("X","Y"), crs = 4326), .05)
  bbox_ex <- st_bbox(bbox_ex)
  assign("bbox", bbox_ex)
  }
}
```

```{r Get NHD Data in bbox, message=FALSE, echo=FALSE}
# NHD data within the bbox
nhd  <- plot_nhdplus(bbox = bbox, actually_plot = FALSE)
```

```{r Labeling & Mapping Prep, warning=FALSE, echo=FALSE, message=FALSE}
## All labeling now done in this chunk
#legend_title <- legend_titling(metric, runid_list) #use legend function
textcol <- colors$default$text #from mapping aesthetics function
label_fill <- colors$default$fill 
rm(maplabs)
maplabs <- fn_labelprep(data=list(counties$sf, cities, roads, nhd), classes=c("county","city","road","nhd"))
```

```{r Data into Bins & Map, echo=FALSE}
facils$within <- facils$within[,colSums(is.na(facils$within))<nrow(facils$within)] #for extra long & lat columns full of NAs
names(facils$within)[names(facils$within) == 'Longitude.1'] <- 'Longitude' #rename coord cols 
names(facils$within)[names(facils$within) == 'Latitude.1'] <- 'Latitude'
facils_within <- facils$within

wd_mgd = c(0, 0.5, 1.0, 2, 10, 25, 100, 1000) #set ranges for the bins 
wd_mgy = c(0, 1, 5, 10, 50, 250, 1000, 10000)

#modify to use map_by -- could be more than one value, with length of list = # of maps to generate 
  #meaning a mp_layer needs to be created and a map generated for each of map_by 

for (i in 1:length(map_by)) { #execute for each metric in map_by param 
  legend_title <- paste0(map_by[i])
  #Ordering & numbering data by the metric to be mapped 
  facils_within <- sqldf(paste0( #ordering the data using sqldf 
  "SELECT facils_within.*  
  FROM facils_within 
  ORDER BY", ' ', map_by[i], ' ', "DESC") #ordering by the metric of interest, descending 
  )
  facils_within$NUM <- seq(1, nrow(facils_within))
 if (i==1) { #data for table will be sorted by the first of map_by
   facils$within <- facils_within
 } 
  metric_unit <- substr(map_by[i], nchar(map_by[i]) - 2, nchar(map_by[i]))  #get metric unit from last 3 characters of metric name
  if (metric_unit == "mgd") { #different ranges for mgd and mgy
  div <- wd_mgd
  } else if (metric_unit == "mgy") {
  div <- wd_mgy
  }
  mp_layer_sql <- paste('SELECT *, ',map_by[i],' AS demand_metric
        FROM facils_within' , sep="")
  mp_layer <- sqldf(mp_layer_sql)
  bins = as.data.frame(div)
  bins$classid <- index(bins)
  names(bins) <- c("val", "bin")

  entity_classes <- sqldf(
      "select a.NUM, max(b.bin) as bin
      from mp_layer as a 
      left outer join bins as b 
      on (a.demand_metric >= b.val) 
      group by a.NUM" )
  mp_layer <- sqldf(
      "select a.*, b.bin 
      from mp_layer as a 
      left outer join entity_classes as b 
      on a.NUM = b.NUM " )

  mp_layer$bin[is.na(mp_layer$bin)] <- "X" # replacing NA values in bin column
  names(mp_layer)[names(mp_layer) == 'demand_metric'] <- map_by[i] #change column name back to the specific metric
  mp_layer <- mp_layer[, !duplicated(colnames(mp_layer))] #remove duplicated columns

##Mapping function
  # args/params have been kept separate during dev. so far, but will be consolidated & some removed once we're happy with maps 
  fn_mapgen(type, map_type, style, metric, rivseg, bbox, segs, counties, roads, 
          nhd, maplabs, locality, region, mp_layer, metric_unit)
  
  #assign map to unique var
  assign(paste0('map', i), map, envir = globalenv())
  }

## Mapping Errors:
  # Error in if (distance > 300) { : missing value where TRUE/FALSE needed
  # Solution: this indicates the bbox is not in the format needed by the function. Regenerate the bbox and make sure it is of class bbox and has names xmin, xmax, etc.

  # Error in rbind(deparse.level, ...) : numbers of columns of arguments do not match
  # Solution: maplabs object needs to be re-generated
```

```{r Save Map as PNG, echo=FALSE}
if (map_type == "basin") {
  map_name <- rivseg
} else if (map_type == "locality") {
  map_name <- locality
} else if (map_type == "region") {
  map_name <- region
}

if (type == "source") {
  map_name <- paste0(map_name, '_sources')
} else if (type == "facility") {
  map_name <- paste0(map_name, '_facils')
}

# Saving map(s) as a png
mapfilename <- character() #empty character var, not a list
for (i in 1:length(map_by)) {
  mapfilename[i] <- paste(export_path, map_name, "_", map_by[i], ".png", sep="")
  mapf <- get(paste0('map',i))
  ggsave(
    filename = mapfilename[i],
    plot = mapf,
    width = 25,
    height = 20)
}

# export_path set in config for analysts, set in console if nonexistent to location where map will be exported 
#knitr::include_graphics(mapfilename) #display map PNG -- for testing 
```



``` {r Create Table, include=FALSE, warning=FALSE, message=FALSE}
names(facils$within)[names(facils$within) == 'propname'] <- 'Facility' #if propname column exists rename to Facility
###New 7/13: 
table <- data.frame(
  Number= facils$within$NUM,
  Facility=facils$within$Facility
)
if (type=="source"){
  table$Source = facils$within$MP_Name  
  table$Source_Type = facils$within$Source_Type
}
table$Locality = facils$within$Locality 

# - - - - add rivseg names- - - - - -
for(i in 1:nrow(table)){ 
  loc_rivseg <- (segs$basin[grep(facils$within$riverseg[i], segs$basin$riverseg),])
  if (nrow(loc_rivseg) != 0) {
    table$rivsegName[i] <- loc_rivseg$name
  } else { # if no matching row was found for the riverseg ID, leave blank but don't break
    table$rivsegName[i] <- ""
    }
}

table$Rivseg= facils$within$riverseg

if (type=="facility"){
    for (i in 1:nrow(facils$within)){ #adding permitted capacity
      systemObj <- RomProperty$new(ds,list(
        featureid = facils$within$Facility_hydroid[i],
        propcode= "vahydro-1.0"), 
      TRUE)
        if (is.na(systemObj$pid) == TRUE) { #if no feature exists 
        table$vwp_max_mgy[i] <- "No Permit"
      } else {
      permCapac <- RomProperty$new(ds,list(
        featureid = systemObj$pid,
        propname = 'vwp_max_mgy'),
      TRUE)
      table$vwp_max_mgy[i] <- permCapac$propcode
      }
    } 
    table$vwp_max_mgy <-  replace(table$vwp_max_mgy, table$vwp_max_mgy==0, "No Permit") #Replace zeros with "no permit"
}

for (i in 1:length(table_col)){
  table[,table_col[i]] <- facils$within[,table_col[i]]
}
```

```{r Rename Table Columns & Process Flextable, include=FALSE, echo=FALSE}
#ordered before renaming, order by name not col #
names(table)[names(table) == 'rivsegName'] <- 'River Segment Name'
names(table)[names(table) == 'Rivseg'] <- 'River Segment ID'
names(table)[names(table) == 'vwp_max_mgy'] <- 'Permitted Capacity (mgy)'
names(table)[names(table) == 'Source_Type'] <- 'Source Type'
names(table)[names(table) == 'fiveyr_avg_mgy'] <- '5-yr Avg Use (mgy)'

#Rename modeled metrics if tied to common runid:
#colnames(table)[grepl('runid_11',colnames(table))] <- paste0('2020 ',metric)
#colnames(table)[grepl('runid_13',colnames(table))] <- paste0('2040 ',metric)

fn_tablegen(table) #flextable saved as var ft
```

# Display Map & Table

```{r View Map(s), echo=FALSE, out.width = '100%', out.height='100%'}
maps <- list()
for (i in 1:length(mapfilename)) {
  maps[[i]] <- rasterGrob(readPNG(mapfilename[i]))
  #assign(paste0('map',i,'png'), map_png)
}

do.call("grid.arrange", c(maps,  ncol = length(mapfilename))) #displays multiple maps side-by-side
```

```{r View Table, echo=FALSE}
ft #display flextable
```

```{r General Render, eval=FALSE, echo=FALSE, include=FALSE}
#Requires loading of export_path from config (setup chunk)
rmarkdown::render(paste0(getwd(),"/mapping_codeReview.Rmd"), 
                  output_file = paste0(export_path,"mappingRMD_knit"), 
                  params = list(
                    rivseg = "JL6_7430_7320", 
                    locality = "Culpeper", 
                    region = "Shenandoah_2", 
                    type = "facility", 
                    model_version = "vahydro-1.0", 
                    runid_list = c("runid_11","runid_13"), 
                    metric = "wd_mgd", 
                    map_type = "locality",
                    map_by = c("runid_11_wd_mgd","fiveyr_avg_mgy"),
                    limit = "boundary",
                    table_col = c("runid_11_wd_mgd","runid_13_wd_mgd","fiveyr_avg_mgy"),
                    bbox_type = "auto"))
```

