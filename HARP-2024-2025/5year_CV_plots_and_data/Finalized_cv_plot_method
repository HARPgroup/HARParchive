library(sf)
library(sqldf)
library(ggplot2)
library(dplyr)
library(cowplot)
library(units)
library(RCurl)




yearly_summary <- function(df,beginningyear,endyear){
  daily_summary <- 
    sqldf(
      "SELECT yr, mo, da, obs_date, SUM(precip_in) AS daily_precip
  FROM df
  GROUP BY yr, mo, da"
    )
  #creating a yearly summary with each year and its total precip
  yearly_summary <- 
    fn$sqldf(
      "SELECT COUNT(daily_precip) AS ndays_with_data, 
      SUM(CASE WHEN daily_precip IS NULL THEN 1 ELSE 0 END) AS ndays_missing, 
      MIN(yr) as start_year, MAX(yr) as end_year, SUM(daily_precip) AS total_precip
  FROM daily_summary
  where yr >= '$beginningyear'
  and yr <= '$endyear'"
    )
}
#hydrocode <- 'usgs_ws_02038000'
#beginningyear <- '2018'
#endyear <- '2018'
model_comparison <- function(hydrocode,beginningyear,endyear){
  default_dataframe <- data.frame(yr = numeric(),
                                 mo = numeric(),
                                 da = numeric(),
                                 obs_date = as.Date(character()),
                                 precip_in = numeric())
 if (url.exists(paste0("http://deq1.bse.vt.edu:81/met/PRISM/precip/",hydrocode,"_precip.csv"))){
   prism <- read.csv(paste0("http://deq1.bse.vt.edu:81/met/PRISM/precip/",hydrocode,"_precip.csv"))
 } else{
   prism <- default_dataframe
 }
  if (url.exists(paste0("http://deq1.bse.vt.edu:81/met/daymet/precip/",hydrocode,"_precip.csv"))){
    daymet <- read.csv(paste0("http://deq1.bse.vt.edu:81/met/daymet/precip/",hydrocode,"_precip.csv"))
  } else{
    daymet <- default_dataframe
  }
  if (url.exists(paste0("http://deq1.bse.vt.edu:81/met/nldas2/precip/",hydrocode,"_precip.csv"))){
    nldas2 <- read.csv(paste0("http://deq1.bse.vt.edu:81/met/nldas2/precip/",hydrocode,"_precip.csv"))
  } else{
    nldas2 <- default_dataframe
  }
  prism_sum <- yearly_summary(prism,beginningyear,endyear)
  daymet_sum <- yearly_summary(daymet,beginningyear,endyear)
  nldas_sum <- yearly_summary(nldas2,beginningyear,endyear)
  # A series of SQL joins and unions that produce a tidy, combined data frame
  ## joins prism and daymet
  j <- sqldf(
    "SELECT daymet_sum.start_year, daymet_sum.end_year, 
    daymet_sum.ndays_with_data as daymet_ndays_with_data, prism_sum.ndays_with_data as prism_ndays_with_data,
    prism_sum.total_precip AS prism_precip, daymet_sum.total_precip AS daymet_precip,
    daymet_sum.ndays_missing as daymet_missing, prism_sum.ndays_missing as prism_missing
  FROM prism_sum
  FULL OUTER JOIN daymet_sum ON prism_sum.start_year=daymet_sum.start_year"
  )
  ## joins nldas to prism&daymet data frame
  j2 <- sqldf(
    "SELECT j.start_year,j.end_year, 
    j.prism_precip , j.daymet_precip, nldas_sum.total_precip AS nldas_precip,
    j.daymet_ndays_with_data,j.prism_ndays_with_data,nldas_sum.ndays_with_data as nldas2_ndays_with_data,
    j.daymet_missing, j.prism_missing, nldas_sum.ndays_missing as nldas2_missing
  FROM j
  FULL OUTER JOIN nldas_sum on j.start_year=nldas_sum.start_year
    where j.start_year is not NULL"
  )
  ## tidies data -- pivot longer
  #j3 <- sqldf(
    #"SELECT start_year ,end_year, 'prism' AS model , prism_precip AS precip_in FROM j2
  #UNION ALL
  #SELECT start_year ,end_year, 'daymet' AS model , daymet_precip AS precip_in FROM j2
  #UNION ALL
  #SELECT start_year ,end_year, 'nldas' AS model , nldas_precip AS precip_in FROM j2"
  #)
  
  analytics <- j2|>
    mutate(var = var(c(prism_precip,daymet_precip,nldas_precip)))|>
    mutate(CV = sqrt(var)/mean(c(prism_precip,daymet_precip,nldas_precip))) |>
    mutate(nldas2_dif_from_mean = nldas_precip-mean(c(prism_precip,daymet_precip,nldas_precip))) |> 
    mutate(prism_dif_from_mean = prism_precip-mean(c(prism_precip,daymet_precip,nldas_precip))) |> 
    mutate(daymet_dif_from_mean = daymet_precip-mean(c(prism_precip,daymet_precip,nldas_precip))) |> 
    mutate(hydrocode = hydrocode)
}


create_SF <- function(){
  watershedGeo <- read.csv("http://deq1.bse.vt.edu:81/met/usgsGageWatershedGeofield.csv")
  gageWatershedSF <- watershedGeo
  gageWatershedSF$gage <- gsub(".*_(\\d+)","\\1",gageWatershedSF$hydrocode)
  gageWatershedSF <- st_as_sf(gageWatershedSF,wkt = 'wkt',crs = 4326)
  #Repair broken geometries
  gageWatershedSF <- st_make_valid(gageWatershedSF)
  #Add shape area in coordinate system units (likely meaningless in crs 4326)
  gageWatershedSF$area <- st_area(gageWatershedSF)
  return(gageWatershedSF)
}

CV_analysis <- function(beginningyear,endyear){
  for (i in  1:nrow(gageWatershedSF)){
    analytic_data <- model_comparison(gageWatershedSF$hydrocode[[i]],beginningyear,endyear)
    stat_data <- rbind(stat_data, analytic_data)
  }
  return(stat_data)
}
gageWatershedSF <- create_SF()
stat_data <- data.frame()
final_data <- data.frame()
stat_data <- CV_analysis(2018,2023)

gageWatershedSF <- st_drop_geometry(gageWatershedSF)
gageWatershedSF$area <- as.numeric(gageWatershedSF$area)

final_data <- sqldf(
  "select a.start_year, a.end_year,a.prism_precip, a.daymet_precip, a.nldas_precip, a.CV, a.var,
  b.hydrocode, b.gage, b.area
     from stat_data as a
     left join gageWatershedSF as b on
   (a.hydrocode = b.hydrocode)"
)

write.csv(final_data, "~/HarpData/Harp2025(correct)/2018_2023_final_data")
write.csv(stat_data, "~/HarpData/Harp2025(correct)/2018_2023_stat_data")

gageWatershedSF <- create_SF()
gageWatershedSF$CV <- final_data$CV[match(final_data$hydrocode, gageWatershedSF$hydrocode)]

#Plot SF polygons
ggplot(gageWatershedSF) + 
  geom_sf(aes(fill = CV))
